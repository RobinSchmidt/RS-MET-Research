Draft - Under construction

The goal is to produce a pair of FIR filter kernels u[m] and d[m] where u is used for upsampling and
d for downsampling such that an upsample -> downsample roundtrip is an identity operation. The 
setting is as follows: We get an input signal x[n] and we want to oversample it by a factor M. We 
first produce a signal y[m] by zero stuffing the original input signal. We will have y[m=n*M] = x[n]
and for all other values m that are not a multiple of M, y[m] is zero. To this y signal, we apply 
the upsampling filter which we represent by its impulse respone u[m] to obtain z[m]. z[m] shall be a
smoothed version of y[m]. The filter u[m] serves as anti-imaging lowpass. Then, we apply to z[m] the
downsampling filter represented by its impulse response (aka kernel) d[m] to obtain w[m]. What we 
want is:

  w[n*M] = y[n*M]

such that when decimating w[m] to extract every M-th value, we get our original signal x[n] back 
exactly. For values of m that are not a multiple of M, we do not yet have any conditions. For the 
time being, these values can be whatever they want to be. We will later use these as degrees of 
freedom to optimize our filters u[m],d[m] to some criteria.


...TBC...

----------------------------------------------------------------------------------------------------

As a first example, let's consider the case where an upsampling kernel u of length 3 is given and we
want to produce a fitting downsampling kernel d. For example, when upsamling by a factor of 2 using 
linear interpolation, we would indeed get a kernel of length 3 which would look like 
u = [1 2 1] / 2. It turns out that our d will have to be of length 5. 

...Why? What's the general formula? I think, it's because we need to shift the kernel u into the 
matrix rows until it disappears and the number of columns of the resulting matrix is our length for 
d?  I think, we need to produce a circulant matrix from u such that we can express the convolution 
of u and d as a matrix-vector product with an unknown vector d. The convolution result will become 
our right hand side vector r. Our prefect reconstruction constraints will become requirements on 
certain entries of this rhs vector r, namely: the middle sample must be one and we need to see zeros 
at all samples that are a distance of n*M, where n is an integer, away from the middle (verify!). 
All the other entries of the rhs vector are not yet determined by our perfect reconstruction 
constraints. They will be our degrees of freedom that we can use to optimize the frequency response 
of the decimation kernel d.

...

Let's denote r[m] the filter resulting from the convolution of u[m] and d[m]. For a 3rd order filter 
u and a 5th order filter d, we can express the convolution as the following matrix-vector equation:

  u0  0   0   0   0      d0     r0
  u1  u0  0   0   0      d1     r1  <--- = 0   Eq. 1
  u2  u1  u0  0   0   *  d2  =  r2
  0   u2  u1  u0  0      d3     r3  <--- = 1   Eq. 2
  0   0   u2  u1  u0     d4     r4
  0   0   0   u2  u1            r5  <--- = 0   Eq. 3
  0   0   0   0   u2            r6
							  
The perfect reconstruction conditions give us 3 equations from the marked 3 lines (verify!):

  u1*d0 + u0*d1                         = 0    Eq. 1
          u2*d1 + u1*d2 + u0*d3         = 1    Eq. 2
                          u2*d3 + u1*d4 = 0    Eq. 3

We have 5 unknowns d0,d1,d2,d3,d4 so to uniquely determine them, we need 2 more equations. Some 
possible additional conditions for d that could make sense are:

  Unit gain at DC:    d0 + d1 + d2 + d3 + d4 = 1   
  Zero gain at fs/2:  d0 - d1 + d2 - d3 + d4 = 0   (verify!)
  Odd symmetry:       d3 = d1   or   d3 - d1 = 0   
                      d4 = d0   or   d4 - d0 = 0   
  Even symmetry:      d3 = -d1  or   d3 + d1 = 0   
                      d4 = -d0  or   d4 + d0 = 0
  


Other ideas for conditions to satisfy:
-Symmetry around the midpoint like d3 = d1, d4 = d0? 
-Maybe we can also impose requirements of r such as: r1 + r2 + r3 + r4 + r5 + r6 = 1, etc.?
  
----------------------------------------------------------------------------------------------------

Let's take the case where we impose symmetry on the downsampling kernel by construction by defining 
d = [d0 d1 d2 d1 d0], etc.. With this, the 5x5 system would look like this:

  u0  0   0   0   0      d0     r0
  u1  u0  0   0   0      d1     r1  <--- = 0   Eq. 1
  u2  u1  u0  0   0   *  d2  =  r2
  0   u2  u1  u0  0      d1     r3  <--- = 1   Eq. 2
  0   0   u2  u1  u0     d0     r4
  0   0   0   u2  u1            r5  <--- = 0   Eq. 3
  0   0   0   0   u2            r6

It's basically the general case from above with all occurrences of d3,d4 replaced by d1,d0 
respectively and occurrences of r4,r5,r6 replaced by r2,r1,r0 respectively. Let's extract the 
relevant equations again:

  u1*d0 + u0*d1         = 0     Eq. 1
  u2*d1 + u1*d2 + u0*d1 = 1     Eq. 2
          u2*d1 + u1*d0 = 0     Eq. 3

But if we assume a symmetric upsampling kernel u, we would have u2 = u0 and Eq. 3 would become the 
same as Eq. 1. So, the system is actually linearly dependent and we have effectively only 2 
equations rather than 3. This gives us one degree of freedom just like in the case above. We can 
again treat the center value d[2] of the downsampling kernel d as our free parameter. So, we replace
Eq. 3 by: 

  d2 = p                        Eq. 4 

for some freely assignable parameter p that can be optimized according to producing the most 
desirable impulse response. What counts as "most desirable" in this context should probably viewed 
from a frequency response perspective. Interesting values for p are 3/4 and 5/7. 

ToDo: Explain why these values are interesting. I think, 3/4 produces a notch at the oversampled
Nyquist freq and minimizes roundoff errors due to having a power of 2 in the denominator and 5/7 
produces a perfectly triangular shape in the time domain, so it basically looks quite similar to the
upsampling kernel (which is also triangular because it's linear interpolation).

----------------------------------------------------------------------------------------------------

Let's take the case with a symmetric upsampling kernel u = [u0 u1 u2 u1 u0] of length 5 as it would 
arise, for example, when linearly upsampling by a factor of M = 3 or upsampling via a cubic 
interpolator by a factor of M = 2 (verify!). I think, we may need a length 7 decimator (verify!)
d = [d0 d1 d2 d3 d2 d1 d0] and get a length 5+7-1 = 11 resulting filter 
r = [r0 r1 r2 r3 r4 r5 r4 r3 r2 r1 r0]. The matrix-vector equation for the convolution of u and d 
looks like:

  u0  0   0   0   0   0   0          d0       r0
  u1  u0  0   0   0   0   0          d1       r1
  u2  u1  u0  0   0   0   0     *    d2   =   r2  <--- = 0    Eq. 1
  u1  u2  u1  u0  0   0   0          d3       r3
  u0  u1  u2  u1  u0  0   0          d2       r4
  0   u0  u1  u2  u1  u0  0          d1       r5  <--- = 1    Eq. 2
  0   0   u0  u1  u2  u1  u0         d0       r4
  0   0   0   u0  u1  u2  u1                  r3
  0   0   0   0   u0  u1  u2                  r2  <--- = 0    Eq. 3
  0   0   0   0   0   u0  u1                  r1
  0   0   0   0   0   0   u0                  r0

Let's extract the 3 equations:

  u2*d0 + u1*d1 + u0*d2                                 = 0   Eq. 1
          u0*d1 + u1*d2 + u2*d3 + u1*d2 + u0*d1         = 1   Eq. 2
                                  u0*d2 + u1*d1 + u2*d0 = 0   Eq. 3

We can again see that Eq. 3 is the same as Eq. 1 (just compare them term-wise reading Eq. 3 
backwards to see it) because we imposed symmetry by construction. So we effectively have only 2 
equations for our 4 unknowns d0..d3. Let's write equations 1,2 down in a form where we collect the 
coeffs in front of the unknowns, i.e. combine the two term u0*d1 and u0*d1 into 2*u0*d1 in Eq. 2, 
for example:

  u2*d0 +   u1*d1 +   u0*d2          = 0   Eq. 1
          2*u0*d1 + 2*u1*d2 + u2*d3  = 1   Eq. 2  

These are our two equations that we get from the roundtrip constraint. But we have 4 unknowns such 
that we now have 2 degrees of freedom that we can tweak to optimize the downsampling kernel in some 
way. Maybe let's again fix the middle sample (this time, it's d3) to some value p (which we will now 
call p1) and lets additionally fix its immediate neighbor d2 to a second parameter which we will 
call p2:

  d3 = p1    Eq. 4
  d2 = p2    Eq. 5
  
As an alternative to directly prescribing values to d3,d2, we could require that the kernel has a 
triangular shape by requiring the numerical derivatives d1-d0, d2-d1, d3-d2 to be all equal such 
that the shape ramps up at a constant slope. this leads to:

  d1 - d0 = d2 - d1  ->  d0 - 2*d1 + d2 = 0
  d2 - d1 = d3 - d2  ->  d1 - 2*d2 + d3 = 0

----------------------------------------------------------------------------------------------------

Let's now consider a case where we upsample by a factor of M = 2 and use for upsampling a kernel of
length 5 such that u = [u0 u1 u2 u1 u0] just as before. Therefore, the matrix-vector equation that
represents our convolution also looks like before. But the difference lies in which samples in the
r-vector we require to be zero. We need:

  u0  0   0   0   0   0   0          d0       r0
  u1  u0  0   0   0   0   0          d1       r1  <--- = 0    Eq. 1
  u2  u1  u0  0   0   0   0     *    d2   =   r2 
  u1  u2  u1  u0  0   0   0          d3       r3  <--- = 0    Eq. 2
  u0  u1  u2  u1  u0  0   0          d2       r4
  0   u0  u1  u2  u1  u0  0          d1       r5  <--- = 1    Eq. 3
  0   0   u0  u1  u2  u1  u0         d0       r4
  0   0   0   u0  u1  u2  u1                  r3  <--- = 0    Eq. 2 again
  0   0   0   0   u0  u1  u2                  r2
  0   0   0   0   0   u0  u1                  r1  <--- = 0    Eq. 1 again
  0   0   0   0   0   0   u0                  r0





----------------------------------------------------------------------------------------------------

ToDo: 

- Derive formulas/algorithms to produce a downsampling kernel d for a given upsampling kernel u (or
  vice versa)
  
- The general algorithm will probably have to formulated in terms of a constrained optimization 
  problem where the constraints are derived from the perfect roundtrip requirements and the 
  objective for the (numrical?) optimization should be the frequency response of the downsampling 
  kernel d. In this algorithm, we would treat the upsapling kernel as given. Maybe we can, in the 
  general case, produce it as a windowed sinc kernel.

- After having u and d in hand, where u was pre-assigned and d was found by the numerical 
  constrained optimization, we could take that pair as a starting point to drive u and d towards 
  each other such that we can use the same kernel for up- and downsampling. That would save memory 
  for the coeffs. I think, this would lead to a quadratic optimization problem rather than a linear 
  one because the products like u0*d2, u1*d1, u2*d0, etc. would become products of the form b0*b2,
  b1*b1, b2*b0, etc. when we call the coeffs of our common up/down kernel b[k].
  
- Maybe an optimized implementation could use SIMD processing to run upsampling and downsampling in 
  parallel. That might introduce one sample of additional delay into the roundtrip.
  

See also in RS-MET-Research/Prototypes/Cpp/Source/Main.cpp:

  testUpDownSample1D();
  testUpDownSample1D_2();
  
There are some implemetations of very small special cases of the general scheme that we want to 
derive here.



Resources:

https://www2.seas.gwu.edu/~ayoussef/papers/ImageDownUpSampling-CISST99.pdf