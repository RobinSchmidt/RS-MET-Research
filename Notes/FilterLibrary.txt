Proposal for a C++ library for the design and application of classic scientific IIR filters.

Features:

- Implementation goals and considerations:

  - Should be templatized and at least support float, double, SIMD-vectors and maybe multiprecision
    for the signals and coefficients. Would be nice, if it would also support more complicated types 
	like matrices. The type of the parameters/coeffs and signals should possibly be different 
	(example: scalar coeffs, multichannel signals realized by simd). SIMD coeffs can also be 
	useful (each channel can have different coeffs) but that may be difficult to achieve when 
	std::complex is used for the poles and zeros. We need a more flexible complex datatype that can 
	work with SIMD and multiprecision numbers. But it could be possible with std::complex now (check 
	that!).
	
  - Should be realtime capable: sample and block based processing functions shall never allocate 
    memory. Filter parameter updates (e.g. change of cutoff freq) should also work without 
	allocations. They also shall not acquire locks. Any thread-sync should be done on a higher level
	anyway and is not within the scope of the responsibility of this library. This library should 
	only care about crunching numbers.
	
  - Should be implemented as C++20 "module".
  
  - May define two C++20 "concepts": "Signal" and "Parameter" or "Coefficient". They must be numeric 
    and it must be possible to arithmetically combine coeffs and signals and the result of that 
	should be a signal. Example: coeff = float, signal = simd<float, 4>.
	
  - Maybe a library for dealing with polynomials and rational functions should be factored out. Such
    a library may be useful in its own right. There is already boost::polynomial. Look into that and
	see, if it's suitable. Hmm...problematic: has only a value_type used for values *and* coeffs.
	I'd like to see separate types for value_type and coeff_type. Maybe that class could be extended
	appropriately. There isn't very much functionality going on in that class anyway. I need much 
	more - including root-finding aka factorization. But actually, for the filter library, I think, 
	we could get away with one type for value *and* coeff.
	
  - The usual design pipeline for a digital filter is:  user-specification  ->  s-plane prototype 
    zeros/poles/gain  ->  s-plane freq trafo  ->  s-to-z trafo  ->  coeff calculation for 
    implementation structure (e.g. biquad chain, SVF-chain, etc.)
	
  - Its should be flexible, i.e. the user can choose, which sort of s-to-z trafo shall be used 
    (bilinear, impulse-invariant, MZTi, etc.)
	
  - When the user just changes a cutoff frequency on a filter plugin (think: in a DAW or 
    synthesizer), the prototype poles/zeros do not need to be recomputed. The prototype pole/zero 
	calculation is by far the most computationally expensive part so it should only be done when 
	really needed. A cutoff change only affects the "s-plane freq trafo" step (and everything 
	thereafter), so cached prototype zeros and poles shall be re-used in a realtime plugin context.
    

- Prototype Designs:

  - Butterworth, Chebychev 1/2 and Elliptic lowpass and low-shelving prototype poles and zeros are 
    computed via closed form formulas for the s-plane poles and zeros
	
  - Bessel, Papoulis, Halpern and Gaussian prototypes are designed via formulas for polynomial 
    coeffs and a polynomial root-finder. I already have code for all of these which could be 
	adapted. Maybe some other designs could be added. This book: 
	https://link.springer.com/book/10.1007/b100752 (which I have on my bookshelf) has some more 
	designs (Legendre, ultraspherical, transitional). Maybe these can be added as well. Maybe there 
	are even more types out there which could be added. I've once seen a paper talking about 
	"parabolic" filters, for example.


- Frequency transformations:

  - They work on the poles and zeros (and gain), i.e. on the zpk-representation.
  
  - s-plane to s-plane LP/LP, LP/HP, LP/BP, LP/BR, LP/LS (LS = low-shelv)
  
  - z-plane to z-plane LP/LP, ... (Constantinides formulas)
  
  - bilinear s-to-z and z-to-s transform
  
  - s-to-z via MZTi, Nyquist frequency match
  
  - Maybe some of these transformation could also be applied to other representations directly such 
    as to biquad-chain coeffs. Not sure yet - we'll see.


- Different implementation structures and conversion routines for the coeffs of the different 
  structures:
  
  - ZPK-form (zeros, poles, gain) - that's the form in which prototypes are designed.
  
  - Biquad cascade (called second order sections (SOS) in Matlab)
  
  - Lattice form 
  
  - Parallel biquads (good for parallelization and bidirectional application)
  
  - Direct form (not recommened to use but for the sake of completeness)
  
  - Biquads can be implemented in SVF (state variable) form and state-vector form and in all 4 
    direct forms.
  
  
- Implementations should be applicable to:

  - Realtime processing as in audio plugin, i.e. sample-by-sample processing should be possible.
  
  - Batch-processing on multi-dimensional arrays by using strides, i.e. we filter along a particular 
    dimension. Should ideally be compatible with std::mdspan - at least for strided layouts. 
	
  - We should be able to apply them bidirectionally using the exact formulas for the states after
    (ringout/warm-up)
 
 
- More feature ideas: 

  - Maybe compensation allpass designs
  
  - Maybe transitional filters can be provided, too
  
  - Maybe iterative design of arbitrary filters based on iterative optimization - but: maybe that 
    should be based on some library dedicated to iterative optimization. Maybe it should be and
	optional feature and if that feature is not needed, the rest of the library will work without
	having the optimization library installed.  
	
  - Maybe biquad designs based on magnitude samples 
  
  - Crossover designs with perfect reconstruction  
  
  - Filtering for non-uniformly sampled data. I have some code for that already here:
    https://github.com/RobinSchmidt/RS-MET/discussions/327
	It requires to decompose the filter into a parallel structure
  
  
- The design shall be inspired by:

  - https://github.com/vinniefalco/DSPFilters
  
  - https://github.com/RobinSchmidt/RS-MET/blob/master/Libraries/RobsJuceModules/rapt/Filters/Scientific/EngineersFilter.h
    This code behind EngineersFilter already implements most of the required mathematics and can 
	serve as a basis. My EngineersFilter plugin is based on this implementation

  
- Challenges:

  - The biggest challenge is perhaps the support for multiprecision (MP) types. It implies that all 
    the mathematical functions used (sin, cos, (complex) jacobi-elliptic, etc.) must work in MP. I'm
	not sure, if it's practical to try to achieve that. But on the other hand - it would *really* be
	a nice feature because especially very high order elliptic designs require that. With built-in
	double-precision, one can push elliptic filters up to (prototype) orders of around 20 before 
	roundoff errors	thwart these design attempts. That's usually more than enough in practice - but 
	wouldn't it be nice, if we could design elliptic filters of order 100 as well just because we 
	can?
	
  - For designing the interface of the class for polynomials, one of the challenges is that for 
    root-finders for real-valued polynomials, the roots may nevertheless be complex. My current 
	approach to this is not very elegant. Maybe that can be done better. Speaking more generally, 
	roots of a polynomial do not necessarily have the same data type as the coefficients. They lie 
	in the algebraic closure of the coefficient type. For example, the complex numbers are the 
	algebraic closure for the reals, the algebraic numbers for the rationals and it gets really wild 
	for finite fields - the algebraic closure of a finite field is an inifinite sequence of fields:
	https://en.wikipedia.org/wiki/Algebraic_closure
	But maybe these cosiderations fall into the category of the "speculative generality" code smell?
	...but a library should be as generally applicable as possible. Maybe one should somehow have a
	third template parameter "RootType" (along with "ValueType" and "CoeffType")
  


 
====================================================================================================  

Notes on composability of templates:


In an ideal world, we want all our types to be composable at will and when we do so, it will all 
just work, i.e. compile and(!!!) do the right thing. We want to be able to do things like:

  // A complex simd vector of 4 floats:
  complex<simd<float, 4>> csf;

  // A complex multiprecision number:
  using mp_number = boost::multiprecision::number<...>;  // shorthand for convenience
  complex<mp_number> cmpn;           
  
  // A matrix of complex floats:
  matrix<complex<float>> mcf;             
  
  // A rational function with complex double-precision coefficients:
  ratio<poly<complex<double>>> rpcd;
  
  // A matrix of rational functions with complex multiprecision numbers as coefficients:
  matrix<ratio<poly<complex<mp_number>>>> mrcpm;
 
 
Notes: 
 
- Last time I checked, things like std::complex<my_simd<float, 4>> were not (yet?) possible. 
  std::complex admitted only float, double and long double as underlying real data type. Maybe it 
  could be made more flexible in the future? This is indeed the reason, why I'm not using it as much 
  anymore. I formerly had my own class for complex numbers, at some time switched to use 
  std::complex until I tried to use it for simd, to discover that it's impossible and then partially 
  switched back to a homemade complex implementation. ...or did that chane recently? ...seems so! 
  That would be nice!
 
- As can be seen from ratio<poly<...>>, my idea to implement the idea of a rational function is to
  implement a generic class for ratios of things (think, rational numbers as first example, i.e. 
  ratios of ints) and then instantiate that on the polynomial class. A function like "reduce" should
  do the right thing in both cases. For rational numbers, it would just find the greatest common 
  divisor of numerator and denominator (by e.g. Euclid's algorithm) and divide both by it. For 
  polynomials, it should automatically invoke the polynomial variant of it. If the coeff-type is 
  real (e.g. float or double), we may need comparisons against zero with a (relative?) tolerance, 
  i.e. dont use if(x == 0)... but rather if( is_close_to_zero(x, tol) )... or something. This is 
  needed in Euclid's algo to check, if the remainder is zero, for example - for polynomials, 
  is_close_to_zero should compare each coeff to zero and return true only if *all* are close to 
  zero.
  
- For rational functions, there is this idea of a partial fraction expansion. There is no analog for
  rational numbers that I know of. Maybe there is? Maybe a sum of fractions with numerator 1? There
  is already std::ratio, but it's not (yet?) suitable for the purpose here because it is meant for
  compile-time ratios of ints.

  
Notes:

- If this is not all achievable at the same time, make a priority list for what compositions are 
  more important than others.
  
- Use doxgen with LaTeX expressions for the documentation for the math stuff. Or maybe use ASCII 
  art like here: 
  https://math.stackexchange.com/questions/149303/software-to-render-formulas-to-ascii-art
  https://arthursonzogni.com/Diagon/#Math
  

Multiprecision numbers:
https://www.boost.org/doc/libs/1_83_0/libs/multiprecision/doc/html/index.html

SIMD-vectors:
https://en.cppreference.com/w/cpp/experimental/simd/simd
https://github.com/VcDevel/std-simd

Polynomials:
https://live.boost.org/doc/libs/1_64_0/libs/math/doc/html/math_toolkit/roots/polynomials.html

Ratios:
https://en.cppreference.com/w/cpp/numeric/ratio/ratio
  
Complex:
https://en.cppreference.com/w/cpp/numeric/complex  

  
I'm not sure, if I'm using the term "composable" here correctly. This talk:

  https://www.youtube.com/watch?v=zclxRbh4AN0 
  https://cppcon.digital-medium.co.uk/wp-content/uploads/2021/10/Composable-C-Ben-Deane-CppCon-2021.pdf  

has other things in mind. It's mostly about function return values. In OOP, "composition" usually 
refers to one class having *members* of a type from another class. But I think, the term can be 
interpreted more generally. What I mean by "composable" here is the stuff above: being able to 
create, e.g. "matrices" of "ratios" of "polynomials" of "complex" numbers which themselves can be 
made of primitive types (like float or double) or "simd" vectors or "multiprecision" numbers or 
whatever - even "matrices" of something. Yep, that's right: we should be able to compose the types 
recursively, too.

For polynomials, it might make sense to distinguish between the coefficient type and the value type,
i.e. the type for (the powers of) x. The coeffs could be scalars and the values matrices, for 
example. We should probably not assume that the value multiplication is commutative - but we *may* 
assume that we have a_n * x^n == x^n * a_n. But maybe it's not necessary to assume that. Not sure 
yet. If we assume that, we may not be able to use matrices for coeffs and values. If we need to 
assume an argument order, the coeff is always the left and the value the right argument in a 
multiplication. Do we need to assume that coeff*coeff multiplication is commutative? That may depend
on the situation, i.e. on the way, the coeffs are produced. In a filter library, there's a lot going 
on for the coefficient calculation - some of which may assume such commutativity. But what would it 
mean, for example, for a Butterworth filter to have a matrix-valued coefficient anyway? Does that 
even make sense?


  
----------------------------------------------------------------------------------------------------

- For mdSpan, see:
  Https://www.youtube.com/watch?v=eD-ceG-oByA
  https://www.youtube.com/watch?v=aFCLmQEkPUw
  - mdarray is the owning version (like vector is to span)
  - rank (= number of dimensions) must be known at compile time


C++ Standard Parallelism - Bryce Adelstein Lelbach - CppNorth 2022
https://www.youtube.com/watch?v=r1COmv0CdW4&list=PLpGV-BujcAKFVCWOBj2548vuxJ1lV5w6-&index=15
43:10: could go into rsMatrix someday
49:33: standardized linear algebra is on the way! yay! :-O

Multidimensional C++ - Bryce Adelstein Lelbach - CppNorth 2022
https://www.youtube.com/watch?v=aFCLmQEkPUw&list=PLpGV-BujcAKFVCWOBj2548vuxJ1lV5w6-&index=23
34:30: talks about compiler hints for non-aliasing pointers

SIMD Libraries in C++ - Jeff Garland - CppNow 2023
https://www.youtube.com/watch?v=hlgCeWC9jxI
https://en.cppreference.com/w/cpp/experimental/simd/simd
https://en.cppreference.com/w/cpp/experimental/simd

STL std::span | Modern Cpp Series
https://www.youtube.com/watch?v=OQu2pZILjDo
-The length can be a runtime or compile-time variable. I guess that implies that for a typical
 convolution routine, the compiler could generate *many* versions for all sorts of different 
 compile-time constants for the length of the span? That might be bad. Although, it may inline such
 a small routine anyway.
 
 
Prototype Filter Design: 
https://www.researchgate.net/publication/251816527_On_the_characteristics_of_Monotonic_L_Halpern_and_parabolic_filters 
 
----------------------------------------------------------------------------------------------------
Ideas for follow up projects:
-FIR design
-Musical filters (ladder, etc.)
-Adaptive filters
-Realtime Quantile-Filtering 