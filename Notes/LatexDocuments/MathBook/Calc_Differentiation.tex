\section{Differentiation}

%\subsubsection{Differentiation}
Consider an arbitrary function $f(x)$ and imagine that we want to compute the slope of the graph at a given $x_0$. We could approximate it by considering the point $(x_0, f(x_0))$ and another point on the graph a small distance $h$ further to the right $(x_0+h, f(x_0+h))$ and compute the "rise over run" quotient $(f(x_0+h) - f(x_0)) / h$ which would give us the slope of a secant. For smaller and smaller $h$, the approximation would get better and better because the secant would approach the tangent. Now we consider the limit as $h$ approaches zero. If that limit exists, it actually \emph{is} our desired slope of the tangent. We denote that tangent slope at $x_0$ as $f'(x_0)$. This leads us to the following definition:
\begin{equation}
  f'(x_0) = \lim_{h \rightarrow 0} \frac{f(x_0 + h) - f(x_0)}{h}
\end{equation}
We note that we could compute this limit at any value of $x_0$ where that limit exists, so if the limit exists everywhere, we can actually replace $x_0$ by $x$ because $x_0$ just an arbitrary variable name anyway which we may choose any way we want, as long as the name doesn't collide with any other names in the equation. Then, this definition actually defines a whole new function $f'(x)$. This new function $f'$ ("f prime") is called the derivative of $f$.

\paragraph{Example} Let $f(x) = x^2$. Plugging it into the definition above, using $x$ in place of $x_0$ as explained, we get:
\begin{equation}
  f'(x) = \lim_{h \rightarrow 0} \frac{(x + h)^2 - x^2}{h}
        = \lim_{h \rightarrow 0} \frac{x^2 + 2 h x + h^2 - x^2}{h} 
        = \lim_{h \rightarrow 0} \frac{2 h x + h^2}{h} 
        = \lim_{h \rightarrow 0} 2 x + h
        = 2 x
\end{equation}
so the derivative of $f(x) = x^2$ is $f'(x) = 2 x$.

\paragraph{Leibniz Notation} ...
% also introduce the "evaluated at" notation with the vertical bar


\subsubsection{Differentiation Rules}
Fortunately, we don't have to go through this tedious procedure via the limit everytime we need to compute a derivative. Instead, we have a lookup list of derivatives of all important elementary functions that has been assembled once and for all by the technique above or otherwise and we have a couple of rules how to compute derivatives of more complicated functions that are created in various ways from the more basic functions (btw: Did I already say that a big theme in math is finding computational shortcuts? This is a nice example). These rules are for any two functions $f$ and $g$ and any constant $a$:

\medskip
\begin{tabular}{c c c l}
  $(a f)'$        &$=$& $ a f'$              & Homogeneity \\
  $(f + g)'$      &$=$& $f' + g'$            & Sum rule (aka Additivity) \\
  $(f \cdot g)'$  &$=$& $f' g + g' f$        & Product rule \\
  $(f / g)'$      &$=$& $(f' g - g' f)/g^2$  & Quotient rule \\
  $(f( g))'$      &$=$& $g' \cdot f'(g)$     & Chain rule \\
\end{tabular}
\medskip
% are there more rules? what about logarithmic differentiation and derivative of inverse?

The two first properties, homogeneity and additivity, taken together constitute the important property of linearity. We may state the linearity property also in a single formula: $(a f + b g)' = a f' + b g'$ where $b$ is another constant. It can easily be verified that this single formula is equivalent to the first two rules in the list above. One lesser known formula is [VERIFY!]:
\begin{equation}
\label{Eq:DerivativeViaH}
 \frac{d}{d x} f(x) 
 = \lim_{h \rightarrow 0} \frac{f(x + h) - f(x)}{h}
 = \frac{d}{d h} f(x + h) \bigg\rvert_{h=0}
\end{equation}
whose usefulness lies mostly in its generalizations to the directional derivative and Gateaux derivative which we will encounter later. There, we will see a similar definition via a limit and the RHS will tell us, how to actually evaluate the limit....but that's for later... 
% Where did I get this formula from? I think, I derived it myself? Maybe via a Taylor expansion of f? Or via specializing to 1D the directional derivative which itself is more easily to "see" intuitively? Or maybe we can define a bivariate function f(x,h) = f(x+h) and derive it from there using partial derivatives? Or maybe evaluate the limit directly from the bivariate function?

%todo: list derivatives of elementary functions

\subsubsection{Elementary Derivatives}
We'll now give a list of some of the most important derivatives of elementary functions. This list (or a more comprehensive version of it that can be found elsewhere), together with the differentiation rules above, will allow us to mechanically evaluate derivatives of all functions that can be constructed from these elementary functions by algebraic operations or composition (i.e. nesting).

...


