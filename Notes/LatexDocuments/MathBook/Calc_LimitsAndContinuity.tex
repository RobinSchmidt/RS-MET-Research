\section{Continuous Functions}

\subsubsection{Limits}
Consider the function $f(x) = \sin (x) / x$. As it stands, it is not defined at $x = 0$ because we would have a division by zero there. In fact, we have an indeterminate form of the form "zero divided by zero". We could just define the function to assume an arbitrary value at $x = 0$, say $f(0) = 0$. But it turns out that there is a more natural way to fill the gap. Imagine plugging ever smaller numbers into $f(x)$, like $0.1, 0.01, 0.001, $ etc. and observe what $f(x)$ does. It turns out that $f(x)$ will approach one. That may suggest to define $f(0) = 1$. But not so fast: What if we would approach zero from the left, using $-0.1, -0.01, -0.001,$ etc. as inputs instead? Good news: It turns out that $f(x)$ also approaches one in this case, so we are indeed justified to define $f(0)=1$ to fill the gap in a natural and meaningful way. The idea that a function approaches a certain value $f(x_0)$ when its input values approach a given value $x_0$ leads to the idea of a limit. We need to distinguish the limits approaching from the left and approaching from the right. Only when both of these are equal, we say that \emph{the} limit exists and we define it to be just that value. If the function $f$ has multiple inputs, we must actually consider all possible paths on which we could approach the point where $f$ is undefined. For the time being, we'll focus on the simpler 1D case where we can approach a point on the number line only from two directions.
TODO: introduce mathematical notation for limits and the epsilon-delta definition

% To define a limit mathematically, we consider a function $f(x)$

% https://en.wikipedia.org/wiki/Limit_(mathematics)
% https://en.wikipedia.org/wiki/Limit_of_a_function#(%CE%B5,_%CE%B4)-definition_of_limit


% https://www.youtube.com/watch?v=n2syaXR8y_k
% log-of-limit is limit-of-log - does that generalize to other functions?
% this is actually a good example:
% $\lim_{n \Rightarrow \infty} (\frac{\sqrt[n]{a} + \sqrt[n]{b}}{2})^n = \sqrt{a b} $

\subsubsection{Continuity}
If the limit of a function $f$ exists at a given $x_0$ and agrees with the actual function value $f(x_0)$, we say that the function $f$ is continuous at $x_0$. With that definition in place, we can now be more specific about what we have meant with "filling the gap in a natural way". We have filled it in such a way as to make the resulting function continuous at $x_0 = 0$. At all other values of $x_0$, it already has been continuous all along. If a function is continuous at \emph{all} values $x_0$, no matter what we choose as $x_0$, we say that the function is continuous without the qualification "at $x_0$". Intuitively, continuity means that the graph of the function has no sudden jumps (aka. discontinuities) and we can draw it without lifting the pencil or drawing vertical lines.

% Laws for limits:
% linearity: lim (f(x) + g(x)) = lim(f(x)) + lim (g(x)), lim(a*f(x)) = a * lim (f(x))
% l'Hospital's rule



% Maybe include this:
% https://en.wikipedia.org/wiki/Limit_inferior_and_limit_superior#limit_superior
% but it applies to sequences, so maybe include it there.

% See also:
% https://en.wikipedia.org/wiki/Uniform_continuity
% https://en.wikipedia.org/wiki/Lipschitz_continuity
% https://en.wikipedia.org/wiki/Absolute_continuity