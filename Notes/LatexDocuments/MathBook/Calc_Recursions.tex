\section{Infinite Anythings}
After having seen infinite sums and infinite products, we'll now do a thing that mathematicians love to do: Generalize. We have defined an infinite sum via a limit over the partial sums $s_n$. The computation of such an $s_n$ was a finite sum which we already knew how to do. There is, however, another way to look at it. The computation of $s_n$ can also be seen as a formula involving the previous sum $s_{n-1}$ plus some new "update" or "correction" term $a_n$, i.e. $s_n = s_{n-1} + a_n$. For this $a_n$ term, we typically had an explicit formula involving $n$, i.e. $a_n = f(n)$ for a given function $f(n)$. With infinite products, the situation was similar with the only difference that we had a sequence of (finite) products $p_n$ and the update rule was $p_{n+1} = p_n \cdot a_n$. The general pattern here is that we compute the next term in our sequence (of partial sums or products) via some rule that takes in one (or, more generally, more) previous values of the sequence and possibly the index $n$ and computes the next value in this sequence. That is: we are dealing with sequences that can be produced via some recursive rule of the general form:
\begin{equation}
a_{n+1} = f(n, a_n, a_{n-1}, a_{n-2}, \ldots, a_0)
\end{equation}
This form is very general and the actual rule will often be simpler than that in practical cases. Often, the dependency will only have a finite window of memory. For example, $a_{n+1}$ may depend only on $a_n, a_{n-1}$ but not on even "older" values of the $a$ sequence. But for greatest generality, we allow it to depend on all previous values of the sequence and we also allow an explicit dependency on the index $n$ to be able to include the infinite sums and products into this more general framework. In infinite sums and products, we usually do have such an explicit dependency on $n$. ...TBC...

% ToDo: 
%
% - Maybe in the explanation of the sums, don't introduce this intermediate sequence a_n as in
%   the formula $s_n = s_{n-1} + a_n$. Instead frame it as $s_n = s_{n-1} + f(n)$ directly. Give
%   an example for how an original sum can be transformed into such a recursive representation. We
%   just need to extract the formula f(n) and the initial value. Maybe take the example of the
%   sum $s = \sum_{n=1}^{\infty} \frac{1}{n^2}$. Here, we have $f(n) = \frac{1}{n^2}$ and the
%   initial value $s_1$ for $n=1$ is $a_1 = 1$
%
% - Or, maybe make a subsubsection in the "Recursively Defined Sequences" subsection for how to
%   transform infinite sums and products into this recursive form

%===================================================================================================
\subsection{Recursively Defined Sequences}

% Maybe start with the Babylonian algorithm applied to 2 as motivating example - without yet mentioning the name.

\paragraph{Computing Square Roots}
As a motivating example, consider the following rule to compute a new term in a sequence from a previous one:
\begin{equation}
a_{n+1} = \frac{1}{2} \left( a_n + \frac{c}{a_n}  \right)
\end{equation}
For some given constant number $c$ and some given initial value $a_0$. Here, $a_{n+1}$ only depends on the sequence value immediately before it, i.e. $a_n$, and there is no explicit dependency on $n$ in the formula. Let's see what this rule produces for $c = 2, a_0 = 3$ with SageMath:
\begin{center}
\begin{tabular}{ ccccc } 
\begin{lstlisting}
c = 2.0
a = 3.0
for i in range(1,8):
    a = (a + c/a) / 2
    print(a)
\end{lstlisting}
& & & &
\begin{lstlisting}
1.83333333333333
1.46212121212121
1.41499842989480
1.41421378004720
1.41421356237311
1.41421356237309
1.41421356237309
\end{lstlisting}
\end{tabular}
\end{center}
% See:
% https://stackoverflow.com/questions/3220121/verbatim-environment-inside-latex-cell
After the 6th iteration, the sequence has converged to a value that will thereafter remain the same in the first 15 decimal digits. The value that this sequence converges to is none other than the square root of two. More generally, for any given positive real number $c$, the sequence of numbers defined by this algorithm will converge to $\sqrt{c}$ regardless of the initial value $a_0$ as long as it is positive [VERIFY!]. Let's try to figure out why ...TBC...

% ToDo:

% The explanation why should be deferred to the discussion of Newton-Raphson iteration - or maybe provide a geometric explanation here. Start with a rectangle of sidelengths 1 and c...see Weitz' video

% Maybe mention that this can indeed be a practically useful algorithm for evaluating square roots - or for refining an existing estimate of the square root. Maybe mention the famous fast inverse square root algorithm from the Quake codebase.



%---------------------------------------------------------------------------------------------------
\subsubsection{Convergence}

%---------------------------------------------------------------------------------------------------
\subsubsection{Fibonacci Numbers}

% the sequence itself diverges but the sequence of ratios of successive terms converges to the golden ratio

% Maybe mention also Lucas numbers - they use the same ruel with different initial values.

\paragraph{The Golden Ratio}
Although the sequence of Fibonacci numbers itself diverges to infinity, we can construct a new sequence from it that does converge - and it does so to a rather interesting number. ...TBC...


%---------------------------------------------------------------------------------------------------
\subsubsection{Newton-Raphson Iteration}

%\paragraph{The Babylonian Algorithm}

% https://en.wikipedia.org/wiki/Square_root_algorithms#Heron's_method

% Use it to compute the Lambert-W function. Apply it to y = x e^x  ->  x e^x - y = 0 where y is
% just a constant in this context


%---------------------------------------------------------------------------------------------------
\subsubsection{The Arithmetic-Geometric Mean}
Consider the following recursive rule for a pair of numbers:
\begin{equation}
\begin{pmatrix} 
a_{n+1} \\ 
b_{n+1}
\end{pmatrix} 
= 
\begin{pmatrix} 
(a_n + b_n)/2 \\ 
\sqrt{a_n \cdot b_n}
\end{pmatrix} 
\end{equation}
That is, we have a recursive rule that produces a vector from a previous vector. The first component of the next vector is the arithmetic mean of the components of the current vector. The second component is the geometric mean. Let's see what this rule produces for the initial values $a_0 = 2, b_0 = 8$:
\begin{center}
\begin{tabular}{ ccccc } 
\begin{lstlisting}
a = 2.0
b = 8.0
for i in range(1,7):
    t = (a+b)/2
    b = sqrt(a*b)
    a = t
    print(a, b)
\end{lstlisting}
& & & &
\begin{lstlisting}
5.00000000000000 4.00000000000000
4.50000000000000 4.47213595499958
4.48606797749979 4.48604634366366
4.48605716058173 4.48605716056869
4.48605716057521 4.48605716057521
4.48605716057521 4.48605716057521
\end{lstlisting}
\end{tabular}
\end{center}
Apparently both vector components converge to the same value of around $4.486$. A value that is somewhere in between the arithmetic mean $5$ and geometric mean $4$ of the initial values $2$ and $8$. This common limit of both vector components is called the arithmetic-geometric mean. ...TBC...ToDo: explain applications, explain how the vector iteration can be embedded into the current framework of sequences by "zipping"

% Maybe move the print call into the 1st line of the loop such that we also print out the initial
% values. Do this also for the sqrt-algorithm

% Frame this in the following way: we start with a vector-valued recursion formula:
% (a_{n+1}, b_{n+1}) = ((a_n + b_n)/2, sqrt{a_n b_n})
% but this can be reformulated within a framework of scalar-valued sequences by just "zipping" the a_n, b_n sequences into a single sequence. The update rule may then be of the form a_{n+1} = ...for n even, ....for n odd - or something like that. It may be inconvenient but it can be done.

% What happens if we apply the same idea to other pairs of means? Try the arithmetic-harmonic mean.

% https://en.wikipedia.org/wiki/Geometric%E2%80%93harmonic_mean
% 


% https://en.wikipedia.org/wiki/Arithmetic%E2%80%93geometric_mean
% "The arithmetic–harmonic mean is equivalent to the geometric mean." (section of "Realted Concepts")
% ...is it generally true that for the generalized means G_m(x,y) and G_n(x,y), the mutual limit of
% the recursion is G_{(m+n)/2}(x,y). By generalized mean, I mean ((x^n + y^n)/2)^{1/n}. Try it numerically! The fact that the arithmetic-harmonic mean is equal to the geometric mean seems to suggest that. The arithmetic mean would be G_1(x,y), the harmonic mean G_{-1}(x,y) and the geometric mean G_0(x,y). If so, that would mean that the arithmetic-geometric mean would be G_{1.5}(x,y) = ((x^{3/2} + y^{3/2})/2)^{2/3}. That would be a closed form solution for the AGM which may be useful sometimes.

% https://mathworld.wolfram.com/Arithmetic-GeometricMean.html

%---------------------------------------------------------------------------------------------------
\subsubsection{Iterated Function Systems}

% https://en.wikipedia.org/wiki/Iterated_function_system

% Iterated Function Systems: A Comprehensive Survey
% https://arxiv.org/abs/2211.14661

% IMPLEMENTING ITERATED FUNCTION SYSTEMS IN PYTHON
% https://www.math.uni-rostock.de/~wj/projects/Fractals/160355141_Habib_Wahab_MTH6138_IFS.pdf

% Consider the equation  x = f(f(f(...f(x)))). Peeling off the outermost application of f in the 
% RHS, we note that, by the equation, we must have x = f(x). That means that the equation requires
% that x must be a fixed point of the function f. The is equivalent to requiring x - f(x) = 0 which
% is in the form suitable to hand over to a root finder ...tbc...


%===================================================================================================
\subsection{Continued Fractions}

% ...hmm...I'm not so sure if continued fractions and radicals fit in here because the upate rule actually is not so  imple. We have to evaluate the whole expression from the inside out implying that we must do a complete re-evalutation of everything for each new $n$. However, in the beginning we said that the update rule may involve more than one previous values, so maybe we can us that as justification? ..But hey! We are actually "outside" the recursion subsection here - so we do not need the content to fit in!


%===================================================================================================
\subsection{Infinite Radicals}






\begin{comment}

ToDo:
-Infinite tetration
-Infinite convolutions (central limit theorem), 
-Infinitely repeated integration
-Integrals over infinite sequences of functions:
 See https://www.youtube.com/watch?v=851U557j6HE  
     Researchers thought this was a bug (Borwein integrals)


Maybe make a section about continued fractions. See:

Die geheime Macht der Kettenbrüche für unmögliche Gleichungen
https://www.youtube.com/watch?v=2qTgi4nq9TA


...what about infinte radicals? Or generally infinitely nested functions? Maybe take the 
arithmetic/geometric mean as example. The general theme is to have some (possibly recursive) rule to
create an infinite sequence of numbers that converges to some specific number. In series and
products, the rule is defined via a summation or product respectively. Maybe make a section "Other Infinite Sequences" or "...Computations". Maybe explain also the Newton iteration there. Maybe first
frame sums and product in terms of recursion, i.e. S_{n+1} = S_n + f(n) or something like that and products similarly. Another example is the Fibonacci sequence - and the quotient of successive terms (which converges to the golden ratio) - it also domenostrates something lese: take an existing sequence (here the Fibonacci numbers) and create a new sequence from it (here the ratios of successive terms)

-we will come full circle back to sequences - an earlier section of calculus

But maybe that's a topic for discrete calc - in the theory of recurrence relations


\end{comment}