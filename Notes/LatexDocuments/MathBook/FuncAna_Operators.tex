\section{Operators}
Operators take a function as input and produce another function as output. Domain and range of input and output do not necessarily have to be the same, but often are. Some examples are taking derivatives and antiderivatives, computing the inverse function (assuming, it exists), multiplying the function by a fixed other function, composing the function with a fixed other function from the left or right, computing evolutes and involutes of curves, etc. Again, an important subset of all operators are the linear operators. We will denote operators by upper case letters and the function that is their argument in brackets. So, if the function $g$ is the result of applying an operator $T$ to a function $f$, we write $g = T[f]$. You may interpret the letter $T$ as "transformation". The operator $T$ transforms a function $f$ into another function $g$. In the literature, you will also find a notation where the brackets are omitted, e.g. $g = T f$. To avoid confusion with mutliplication, I'll use the bracket notation. Sometimes, we may want to evaluate the resulting function at a particular input argument $x$. For this, we'll write $T[f](x)$. There are two levels of evaluation here: first $T[f]$ is evaluated to given some function and then that function is evaluated at the argument $x$.

...tbc...



\subsection{Linear Operators}
The definition of linearity for operators is as always: for any two functions $f,g$ and any scalar $a$, an operator $L$ is said to be linear if satisfies the conditions of homogeneity: $L[a g] = a L[g]$ and additivity: $L[f+g] = L[f] + L[g]$. ...tbc...

% notes: could "homogeneity" also be called "multiplicativity"? i think, in number theory, multiplicative functions are defined exactly that way - oh - nope, it's not, it's defined as f(a*b) = f(a)*f(b)

\subsubsection{Eigenfunctions}
Just like matrices can have eigenvectors, i.e. vectors that are only scaled in length when the matrix is applied, linear operators can have eigenfunctions which are - in full analogy - functions that are only scaled by a factor, when the operator is applied, that is $T[f] = \lambda f$ for some scalar $\lambda$. In both cases, the scaling factor $\lambda$ is called the eigenvalue. The pairs of eigenvalues with their corresponding eigenfunctions are called eigenpairs.

\begin{comment}
examples: d/dx has eigenpairs (k, e^(kx)), d^2/dx^2 has eigenpairs (-k, sin(kx+p)) for any p

what about a generalization where we allow a scaling of the input, too, such as:
  T(f(x)) = k * f(m*x)
examples of such generalized eigenfunctions would be Gaussians when the operator is the Foruier trafo and we would have m = 1/k (i think)
https://www.facebook.com/groups/mathematikphysik/posts/3391564321076865

https://en.wikipedia.org/wiki/Fourier_transform#Eigenfunctions

\end{comment}


\begin{comment}

-linear operators: integral, differential, projection (best approximation from a subspace), multiply by fixed function, shift, rotate?, solutions to ODE as operator? driving-function goes in, solution comes out?
-eigenfunctions and eigenvalues
-adjoint operators - how to compute (see videos/notes/books by Nathan Kutz), something with integration by parts
-solving operator equations, Fredholm alternative
-seems like in inifinite dimensional spaces, linear operators can be unbounded (how so? - find example) and the bounded linear operators are precisely those that give rise to continuous mappings -> figure out, this seems to be an important theme

-Legendre Trafo: inverts a function y(x) = grad(f(x)) into x(y) = grad(g(y)) where f,g are scalar fields and x,y are vectors: g(y) = x(y) \cdot y - f(x(y)), see Ahrens add-on, pg 201, it maps a scalar-field to another scalar field
https://en.wikipedia.org/wiki/Legendre_transformation
https://math.stackexchange.com/questions/4208589/integral-kernel-of-the-legendre-transform

https://en.wikipedia.org/wiki/Operator_(mathematics)

https://en.wikipedia.org/wiki/Operator_algebra


interesting ones from here:
https://en.wikipedia.org/wiki/List_of_mathematic_operators
-geom/arith mean (sort of running mean, i guess - mean, so far)
-logarithmic derivative
-Schwarzian derivative
-Legendre transform
-dual curve?
-evolute, involute
-arc length
-inverse
-reflection: F[y] = y(-x)

-auto correlation? cross correlation with given function

https://en.wikipedia.org/wiki/Weierstrass_transform  (convolution with Gaussian -> smoothing)
...what about mollifiers?
https://en.wikipedia.org/wiki/Mollifier

don't onfuse these:
https://en.wikipedia.org/wiki/Legendre_transform_(integral_transform)
https://en.wikipedia.org/wiki/Legendre_transformation



Example operators:
https://en.wikipedia.org/wiki/Volterra_operator      just the integral
https://en.wikipedia.org/wiki/Composition_operator   
https://en.wikipedia.org/wiki/Sturm%E2%80%93Liouville_theory
https://en.wikipedia.org/wiki/Schwarzian_derivative


\end{comment} 