\section{Operators}
Operators take a function as input and produce another function as output. Domain and range of input and output do not necessarily have to be the same, but often are. Some examples are taking derivatives and antiderivatives, computing the inverse function (assuming, it exists), multiplying the function by a fixed other function, composing the function with a fixed other function from the left or right, computing evolutes and involutes of curves, etc. Again, an important subset of all operators are the linear operators. We will denote operators by upper case letters and the function that is their argument in brackets. So, if the function $g$ is the result of applying an operator $T$ to a function $f$, we write $g = T[f]$. You may interpret the letter $T$ as "transformation". The operator $T$ transforms a function $f$ into another function $g$. In the literature, you will also find a notation where the brackets are omitted, e.g. $g = T f$. To avoid confusion with mutliplication, I'll use the bracket notation. Sometimes, we may want to evaluate the resulting function at a particular input argument $x$. For this, we'll write $T[f](x)$. There are two levels of evaluation here: first $T[f]$ is evaluated to give some function and then that function is evaluated at the argument $x$.

...tbc...



\subsection{Linear Operators}
The definition of linearity for operators is as always: for any two functions $f,g$ and any scalar $a$, an operator $L$ is said to be linear if satisfies the conditions of homogeneity: $L[a g] = a L[g]$ and additivity: $L[f+g] = L[f] + L[g]$. ...tbc...

% notes: could "homogeneity" also be called "multiplicativity"? i think, in number theory, multiplicative functions are defined exactly that way - oh - nope, it's not, it's defined as f(a*b) = f(a)*f(b)

\subsubsection{Eigenfunctions}
Just like matrices can have eigenvectors, i.e. vectors that are only scaled in length when the matrix is applied, linear operators can have eigenfunctions which are - in full analogy - functions that are only scaled by a factor, when the operator is applied, that is $T[f] = \lambda f$ for some scalar $\lambda$. In both cases, the scaling factor $\lambda$ is called the eigenvalue. The pairs of eigenvalues with their corresponding eigenfunctions are called eigenpairs. For example, the exponential function is an eigenfunction of the derivative operator with eigenvalue 1.


\subsection{Functions of Operators}
We can define the $n$th power of an operator $T$, denoted as $T^n$, simply as the operator that results from applying $T$ to a function $n$ times. With that definition in place, we can use the power series expansions of all our well known functions (such as $\exp, \sin, \log$, etc.) to get a definition of these functions for operator-valued arguments. For example, the exponential function of an operator $T$ is defined as:
\begin{equation}
  e^T = \sum_{k=0}^{\infty} \frac{T^k}{k!}
\end{equation}
For this operator exponential, the familiar relation $e^A e^B = e^{A + B}$ holds only iff $A B = B A$, i.e. if the operators $A$ and $B$ commute. If they don't commute, the Baker-Campbell-Hausdorff formula applies which you may look up, if you need it. If we choose the operator $T$ to be taking the derivative with respect to the independent variable $x$, i.e. $T = \frac{d}{dx}$ and we form the operator $e^{a \frac{d}{dx}}$ for any given constant $a$, then the effect of the operator $e^{a \frac{d}{dx}}$ when applied to a function $f$ is to shift the function's graph horizontally. We have: 
\begin{equation}
  e^{a \frac{d}{dx}} [f(x)] = f(x-a)
\end{equation}
This formula can be derived by considering the Taylor series of an arbitrary function $f$ with respect to $a$ around a point $x$ and treating $a$ as the deviation from the expansion point (...tbc...).



%https://en.wikipedia.org/wiki/Baker%E2%80%93Campbell%E2%80%93Hausdorff_formula
%https://de.wikipedia.org/wiki/Baker-Campbell-Hausdorff-Formel
%http://webhome.phy.duke.edu/~mehen/760/ProblemSets/BCH.pdf
%maybe the sin/cos functions of operators can be constructed from the exp function like sin(T) = (exp(i T) - exp(-i T))/(2 i) etc.
% define T^{1/2}, T^{-1}, T^a, explain fractional derivatives

\begin{comment}
examples: d/dx has eigenpairs (k, e^(kx)), d^2/dx^2 has eigenpairs (-k, sin(kx+p)) for any p

what about a generalization where we allow a scaling of the input, too, such as:
  T(f(x)) = k * f(m*x)
examples of such generalized eigenfunctions would be Gaussians when the operator is the Foruier trafo and we would have m = 1/k (i think)
https://www.facebook.com/groups/mathematikphysik/posts/3391564321076865

https://en.wikipedia.org/wiki/Fourier_transform#Eigenfunctions

In a comment here:
https://www.facebook.com/MusicEngineer/posts/pfbid02EuMLifHEgAg68N2oEsxzneuJcnmoaL2u2a7CjEy3P5v19ecayL6RCjzDD3rXgL6Ml
I say:

ahaaa! jetzt verstehe ich auch, warum die delta-funktionen eigenfunktionen des operators "multipliziere-mit-x" sind (plural, weil ich die ganze familie meine - mit allen verschiebungen und skalierungen). die sind n채mlich die einzigen funktionen f(x), bei denen es so aussieht, als h채tte man 체berall mit der gleichen zahl multipliziert - weil sie ja bis auf an der einen stelle 체berall null sind und null mal irgendwas wieder null ergibt. dass man also "in wirklichkeit" an jeder stelle mit einer anderen zahl multipliziert hat, sieht man dem ergebnis nicht mehr an.

that should go into the scetion about eigenfunctions, if it is actually correct.

\end{comment}


\begin{comment}

-linear operators: integral, differential, projection (best approximation from a subspace), multiply by fixed function, shift, rotate?, solutions to ODE as operator? driving-function goes in, solution comes out?
-eigenfunctions and eigenvalues
-adjoint operators - how to compute (see videos/notes/books by Nathan Kutz), something with integration by parts
-solving operator equations, Fredholm alternative
-seems like in inifinite dimensional spaces, linear operators can be unbounded (how so? - find example) and the bounded linear operators are precisely those that give rise to continuous mappings -> figure out, this seems to be an important theme

-Legendre Trafo: inverts a function y(x) = grad(f(x)) into x(y) = grad(g(y)) where f,g are scalar fields and x,y are vectors: g(y) = x(y) \cdot y - f(x(y)), see Ahrens add-on, pg 201, it maps a scalar-field to another scalar field
https://en.wikipedia.org/wiki/Legendre_transformation
https://math.stackexchange.com/questions/4208589/integral-kernel-of-the-legendre-transform

https://en.wikipedia.org/wiki/Operator_(mathematics)

https://en.wikipedia.org/wiki/Operator_algebra


Functions of operators:
https://www.youtube.com/watch?v=nqLEbrzVsk4 Functions of operators in quantum mechanics
https://math.stackexchange.com/questions/204592/operator-exponential
https://www2.math.upenn.edu/~kirillov/MATH548-F07/Lect1.pdf
https://www.tcs.tifr.res.in/~pgdsen/pages/courses/2007/quantalgo/lectures/lec06.pdf
https://cpb-us-w2.wpmucdn.com/voices.uchicago.edu/dist/0/1830/files/2019/07/Exponential-Operators.pdf



https://www.youtube.com/watch?v=N8Rxlc-fGr0  The Abstract World of Operational Calculus


interesting ones from here:
https://en.wikipedia.org/wiki/List_of_mathematic_operators
-geom/arith mean (sort of running mean, i guess - mean, so far)
-logarithmic derivative
-Schwarzian derivative
-Legendre transform
-dual curve?
-evolute, involute
-arc length
-inverse
-reflection: F[y] = y(-x)

-auto correlation? cross correlation with given function

https://en.wikipedia.org/wiki/Weierstrass_transform  (convolution with Gaussian -> smoothing)
...what about mollifiers?
https://en.wikipedia.org/wiki/Mollifier

don't confuse these:
https://en.wikipedia.org/wiki/Legendre_transform_(integral_transform)
https://en.wikipedia.org/wiki/Legendre_transformation



Example operators:
https://en.wikipedia.org/wiki/Volterra_operator      just the integral
https://en.wikipedia.org/wiki/Composition_operator   
https://en.wikipedia.org/wiki/Sturm%E2%80%93Liouville_theory
https://en.wikipedia.org/wiki/Schwarzian_derivative


----------------------------------------------------------------------------------------------------
Very interesting stuff - some of it may go into this chapter, too:
https://www.youtube.com/watch?v=N8Rxlc-fGr0  The Abstract World of Operational Calculus

From the same creator, a sort of prequel:
https://www.youtube.com/watch?v=D0EUFP7-P1M  The Shadowy World of Umbral Calculus
-Maybe the phi-operator (which replaces powers with falling powers in power series) should be 
 mentioned here.
-But maybe it fits better into a Discrete Calculus chapter. Such a chapter could discuss difference-
 and summation calculus, Newton-Gregory formula and its relation to Taylor series, and the "umbral
 calculus" as a bridge between continuous and discrete calculus (converts between integrals and sums)
-Q: what would chain, product and quotient rule look like for phi? I think, in terms of series expansions, we need to look at Cauchy products of sequences and their inverses, i.e. "weighted" de/convolutions?
 
From Mathologer - relevant for Discrete Calculus:
https://www.youtube.com/watch?v=4AuV93LOPcE  Why don't they teach Newton's calculus of 'What comes next?' 
 
More about umbral calculus:
https://www.youtube.com/watch?v=ytZkmV-7EbM
at 12:25, he defines an "umbral addition" which looks like a "weighted convolution" with weight(n,k) = n-choose-k. Can this be generalized into a useful "weighted convolution" operation?...maybe with an inverse i.e. weighted deconvolution? Is it commutative? I guess, only when w[n,k] = w[k,n] which isn't the case for binomial coeffs (or is it?)

https://en.wikipedia.org/wiki/Umbral_calculus
https://de.wikipedia.org/wiki/Umbral-Kalk%C3%BCl

Based on these, I think, it really fits well into the discrete calculus chapter

Umbral Calculus serves as a bridge between discrete and continuosu calculus. What other bridges are there between these worlds? Generating functions. Fourier expansions? Sampling and interpolation? Z-Trafo?

https://en.wikipedia.org/wiki/Harmonic_analysis
https://mathworld.wolfram.com/q-Expansion.html

what are eigenfunctions of the shift-operator? periodic functions - with eigenvalue 1 and period equal to the shift? any others?

-What could be next after operators? Operators on operators? Opoperators? What could be examples 
 of that? How about "apply twice"? That would turn an n-th derivative int a 2n-th derivative, an
 inversion into an identity, etc. There could also be the "invert" opoperator


\end{comment} 