\section{Calculus of Variations} 

[TODO: this chapter needs thorough verification - i'm not so sure about many things]

In multivariable calculus, we were interested in finding minima and maxima of functions that had multiple inputs. The strategy was to compute an expression for the gradient and requiring it to be the zero vector. In the calculus of variations, aka variational calculus, we will take this a step further: We will minimize functionals with respect to their input function. That means we are interested in finding a function that minimizes a given functional. We may interpret this as minimizing something that depends on (uncountably) infinitely many inputs - not just 2 or 3 or 1000 as in multivariable calculus.


\subsection{The Problem: Minimize a Functional}
We want to find a stationary point (typically a minimum or maximum - in the following, we'll assume a minimum) of an integral of the form:
\begin{equation}
 I(y) = \int_a^b F(x,y(x),y'(x)) \; dx
\end{equation}
where $y = y(x)$ is an unknown function that we want to find which has $x$ as its argument. The function $y(x)$ should also satisfy some given boundary conditions $y(a) = y_a, y(b) = y_b$. That means we minimize the integral subject to the contraint that the function $y$ has to take specific prescribed values $y_a, y_b$ at the boundaries of the integration interval. The function $F$ is a function that may depend on 3 scalar inputs $x,y,y'$ where $y,y'$ are themselves dependent on $x$, so the only truly independent input to the integrand $F$ is actually just $x$. Let's assume that $y$ is indeed a function that makes the $I(y)$ stationary and let $v = v(x)$ be any function of $x$ that satisfies $v(a) = v(b) = 0$. Then, adding an infinitesemimally small amount $h$ of the function $v$ to the function $y$ should cause at most second order changes to $I$, i.e. at most of order $h^2$. $I$ should remain constant to first order. The boundary conditions $v(a) = v(b) = 0$ ensure that our modified function $\tilde{y} = y + h v$ satisfies the same boundary conditions as $y$ does: $\tilde{y}(a) = y_a, \tilde{y}(b) = y_b$.

\subsection{The Tool: The Gateaux Derivative}
We need to make more explicit what we mean by a statement like $I(y)$ should remain constant to first order when we wiggle $y$ a little bit by adding a small amount of another function $v$. We need to define some sort of derivative for functionals that we can then set to zero. Since a functional has an infinite dimensional input, it's perhaps advisable to draw ideas from notions of derivatives of multivariate functions because their input is at least multidimensional. The idea that we will pick up from multivariable calculus and extend to the infinite dimensional case is the idea of a directional derivative. Recall that in \ref{Eq:DirectionalDerivative}, the directional derivative of a multivariate function $f(\mathbf{x})$ into the direction of some arbitrary unit length vector $\mathbf{v}$ was defined as:
\begin{equation}
 \frac{\partial f(\mathbf{x}) }{\partial \mathbf{v}} 
 = \lim_{h \rightarrow 0} \frac{f(\mathbf{x} + h \mathbf{v} ) - f(\mathbf{x})}{h}
 = \frac{d}{d h} f(\mathbf{x} + h \mathbf{v}) \bigg\rvert_{h=0}
\end{equation}
Now, our function $y = y(x)$ plays the role of the input vector $\mathbf{x}$ and $v = v(x)$ plays the role of  the given direction vector $\mathbf{v}$, but now $v$ is a "direction" in our infinite dimensional function space, into which we perturb our given location $y$ in that space. The role of $f$ is taken by $I$, so we could write in full analogy:
\begin{equation}
 \frac{\partial I(y) }{\partial v} 
 = \lim_{h \rightarrow 0} \frac{I(y + h v ) - I(y)}{h}
 = \frac{d}{d h} I(y + h v) \bigg\rvert_{h=0}
\end{equation}
and call that expression the directional derivative of $I$ into the direction of $v$ at $y$. However, this is not the usual notation and terminology. Instead, the expression on the LHS is typically written as $\delta I(y;v)$ and called the "first variation" or  "Gateaux derivative" of the functional $I$ at $y$ into the direction $v$. There are also higher order variations of $I$ defined in the same way. In this context, the quantity $\delta y := h v$ is called the variation of $y$.  In standard notation, the first and second variations of the functional $I$ at $y$ into the direction of $v$ are given by:
\begin{equation}
 \delta   I(y; v) = \frac{d}  {d h  } I(y + h v) \bigg\rvert_{h=0}, \qquad
 \delta^2 I(y; v) = \frac{d^2}{d h^2} I(y + h v) \bigg\rvert_{h=0}
\end{equation}
In the literature, you will also find definitions of the so called "Frechet derivative" and "functional derivative", which are - as far as I understand it - basically the same thing, but maybe require stronger conditions on $I$.

% I think, the Frechet derivative might be some sort of more general umbrella term?:
% https://en.wikipedia.org/wiki/Generalizations_of_the_derivative

\paragraph{Side note:} For the analogy with the directional derivative to be complete and fully consistent, we should also require that the norm of $v$ has to be unity. However, in the literature, that is typically not done in the definition of the Gateaux derivative. %This is not such a big deal because in the typical applications, we will require this derivative be zero, so any scalar proportionality factor doesn't matter anyway. One could perhaps conceive of removing the unit-length requirement in the definition of the directional derivative as well - if the vector $\mathbf{v}$ would have some length other than unity, the first order change in $f$ due to that length factor would be given by just that length. Any non-unit scale factor in the input vector would just scale the output value of the directional derivative accordingly, which would make sense. Anyway...

%% what's the difference between these:
% https://en.wikipedia.org/wiki/Gateaux_derivative
% https://en.wikipedia.org/wiki/Functional_derivative
% is it that the Gateaux derivative apllied to any functional and the variation of functional derivative only to this specific functional that is used in calculus of variations, there's also:
% https://en.wikipedia.org/wiki/Fr%C3%A9chet_derivative

% see also:
% https://mathoverflow.net/questions/349057/question-about-functional-derivatives


\subsection{The Solution: The Euler-Lagrange Equation}
If $y = y(x)$ is a stationary "point" (function) of $I(y)$, then the Gateaux derivative of $I$ at $y$ into the "direction" of $v$ should vanish, regardless of the choice of $v$. Using this requirement, after a nontrivial derivation involving the multivariable chain rule and integration by parts, which I will skip here, the following result can be derived: If $y$ is a stationary point of the functional $I$, then $y$ must satisfy the following differential equation:
\begin{equation}
 \frac{d}{d x} \left(  \frac{\partial F}{\partial y'}  \right) = \frac{\partial F}{\partial y}
 \qquad \text{aka} \qquad
 \frac{d}{d x} F_{y'} = F_{y}
\end{equation}
It may look like a partial differential equation due to the occurrence of derivatives with respect to $x,y,y'$ but it actually boils down to an ordinary one because $y,y'$ are themselves functions of $x$ [verify!].

\medskip
In physics, the problem of minimizing such a functional is called the "princple of least action". In this application, the integral is taken over a time interval and the integrand is called the "Lagrangian" of the system, typically denoted by $L$, and given by the difference between kinetic and potential energy. The value of the integral itself is called the "action". The idea is so fundamental that almost all differential equations that occurr in physics can be derived from such a principle. Evaluating the Euler-Lagrange equation for such a problem, posed as minimization of a suitable, problem dependent action integral, will give the equation of motion for the given system as a differential equation.

\medskip
It's appropriate now to take a step back and appreciate the view from the lofty height we have reached:  Formerly, we used to consider differential equations as (hard) problems (which they still are) and here we now consider a differential equation to be the \emph{solution} of a problem that was posed on an even higher level. It's not even one particular differential equation but rather a recipe for deriving an infinite number of differential equations. Quite high-level stuff indeed. Time to pat ourselves on the back for having grasped one of the crown jewels of theoretical physics. 


\subsubsection{Special Cases and Generalizations}

% F does not depend explicitly on x, F does not depend explicitly on y, F does not depend explicitly on y' see Baerwollf, pg 796 for 1,2

\paragraph{Bivariate Functions} We want to find a bivariate function $z(x,y)$ that minimizes a functional $I(z)$ given by a double integral. The solution is a partial differential equation:
\begin{equation}
 I(z) = \int_a^b \int_c^d  F(x,y,z,z_x,z_y ) \; dx dy
 \quad \Rightarrow \quad
  F_z - \frac{\partial}{\partial x} F_{z_x} - \frac{\partial}{\partial x} F_{z_y} = 0
\end{equation}

\paragraph{Bivariate Functionals} Now we consider the case that the functional $I$ takes two univariate functions $y(x)$ and $z(x)$ as input. The solution is a system of two ordinary differential equations:
\begin{equation}
 I(y,z) = \int_a^b F(x,y,z,y',z' ) \; dx
 \quad \Rightarrow \quad
 \frac{d}{d x} F_{y'} = F_y, \;  \frac{d}{d x} F_{z'} = F_z,
\end{equation}
% maybe use the other notation - that index-of-index is too tiny, maybe also swap LHS and RHS and factor out the \partial / \partial x in the PDE ...do the same for the basic EL eq

%\paragraph{Bivariate Both} ...the books don't mention this case, but i guess, we would get a system of 2 PDEs? -> figure out

% see Baerwolff, pg 807
% todo: 
% -Bivariate Functions and Functionals - system of PDEs?
% -in Riley et al pg 782, there are more generalizations to functionals involving more derivatives
% -mention case for constrained optimization -> there are two functionals I,J and we minimize I + \lambda J
% -maybe also state the fully multivariate formulas
% -maybe try to write sage or mathematica code that takes F as input and spits out the diffeq, ready to
%  be passed to DSolve etc. - maybe they have such functional already onboard?

% see also: applied calculus of variations by komzsick - it has all the generalizations and also treats the inverse problems of finding a variational formulation for a given diffeq


\subsection{The Inverse Problem}
Sometimes, our starting point is a differential equation and we want to find a corresponding variational formulation. This may not be easy or even impossible, but for certain special cases, there is a formula to do this. If the (ordinary or partial) differential equation is given in the form $L y = f$ where $L$ is a linear, self-adjoint, positive definite operator and $f$ is some inhomogeneity, then the variational formulation of the problem is given by $I(y) = \langle L y, y \rangle + 2 \langle y, f \rangle $.
% see Komzsick
% Poisson 2D: Lap(z) = z_x^2 + z_y^2 = f(x,y)  ->  F = z_x^2 + z_y^2 + 2 z f


\subsection{Examples}






\begin{comment}

-i think, we need to have the operator chapter before this because in the inverse problem, we make use of operator terminology

maybe use J instead of I to denote the functional - it's used on wikipedia and in many other places

% I think, $F$ can be seen as the result of applying an operator to the function $u$? But it's not just any arbitrary operator - it is a function that can depend only on $x$ and its instantaneous values $u(x),u'(x)$ at that given $x$, not on any other function values of $u$, as the result of a general operator could

% Maybe present at least an outline of the derivation, maybe not all the details

%There's no integral anymore in this result, because the integral fell due the fact that the vanishing of the Gateaux derivative can be ensured for any arbitrary $v$ only if the integrand vanishes.

% why is the derivative with respect to x a normal derivative and the others are partial derivatives? is it because the result of \frac{\partial F}{\partial u'} is only a function of x? 

-after Euler-Lagrange Eq:





-derivatives of functionals: variation (as continuous analog of the total differential), Frechet- and Gateaux derivative

-can we interpret the functional derivative (i.e. the variation) as some continuous analog of the norm of the
 gradient vector? can the minimization problem be cast into setting this norm to zero?
 
-make derivation of the variation similar to the one in Susskind's theorectical minimum, volume 1

-minimization of functionals 
 -applications: 
  -math: minimal surfaces, catenary, straight line as minimization problem
  -physics: principle of least action and least time, Lagrangian mechanics, 

-connection between variational problems and differential equations: a diffeq is the solution to a variational problem - how can we go the other way around and find the variationl problem when given a diffeq?


https://en.wikipedia.org/wiki/Gateaux_derivative

https://www.youtube.com/watch?v=V0wx0JBEgZc
https://www.youtube.com/watch?v=VCHFCXgYdvY
https://www.youtube.com/watch?v=vqDHO2eKXcs

https://www.youtube.com/watch?v=MXXrAxBu3lo

https://www.youtube.com/watch?v=bvUyYv_x2Gs 
Vid 1 Calculus of Variations Derivation of the Euler Lagrange Equation and the Beltrami Identity

\end{comment} 