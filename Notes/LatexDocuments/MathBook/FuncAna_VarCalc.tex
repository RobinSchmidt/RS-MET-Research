\section{Calculus of Variations} 

[TODO: this chapter needs thorough verification - i'm not so sure about many things]

In multivariable calculus, we were interested in finding minima and maxima of functions that had multiple inputs. The strategy was to compute an expression for the gradient and requiring it to be the zero vector. In the calculus of variations, aka variational calculus, we will take this a step further: We will minimize functionals with respect to their input function. That means we are interested in finding a function that minimizes a given functional. We may interpret this as minimizing something that depends on (uncountably) infinitely many inputs - not just 2 or 3 or 1000 as in multivariable calculus.


\subsection{The Problem: Minimize a Functional}
We want to find a stationary point (typically a minimum or maximum - in the following, we'll assume a minimum) of an integral of the form:
\begin{equation}
 I(y) = \int_a^b F(x,y(x),y'(x)) \; dx
\end{equation}
where $y = y(x)$ is an unknown function that we want to find which has $x$ as its argument. The function $y(x)$ should also satisfy some given boundary conditions $y(a) = y_a, y(b) = y_b$. That means we minimize the integral subject to the contraint that the function $y$ has to take specific prescribed values $y_a, y_b$ at the boundaries of the integration interval. The function $F$ is a function that may depend on 3 scalar inputs $x,y,y'$ where $y,y'$ are themselves dependent on $x$, so the only truly independent input to the integrand $F$ is actually just $x$. Let's assume that $y$ is indeed a function that makes the $I(y)$ stationary and let $v = v(x)$ be any function of $x$ that satisfies $v(a) = v(b) = 0$. Then, adding a small amount $h$ of the function $v$ to the function $y$ should cause at most second order changes to $I$, i.e. $I$ should remain constant to first order. The boundary conditions $v(a) = v(b) = 0$ ensure that our modified function $\tilde{y} = y + h v$ satisfies the same boundary conditions as $y$ does: $\tilde{y}(a) = y_a, \tilde{y}(b) = y_b$.

\subsection{The Tool: The Gateaux Derivative}
We need to make more explicit what we mean by a statement like $I(y)$ should remain constant to first order when we wiggle $y$ a little bit by adding a small amount of another function $v$. We need to define some sort of derivative for functionals that we can then set to zero. Since a functional has an infinite dimensional input, it's perhaps advisable to draw ideas from notions of derivatives of multivariate functions because their input is at least multidimensional. The idea that we will pick up from multivariable calculus and extend to the infinite dimensional case is the idea of a directional derivative. Recall that the directional derivative of a multivariate function $f(\mathbf{x})$ into the direction of some arbitrary unit length vector $\mathbf{v}$ was defined as:
\begin{equation}
 \frac{\partial f(\mathbf{x}) }{\partial \mathbf{v}} 
 = \lim_{h \rightarrow 0} \frac{f(\mathbf{x} + h \mathbf{v} ) - f(\mathbf{x})}{h}
\end{equation}
Now, our function $y = y(x)$ plays the role of the input vector $\mathbf{x}$ and $v = v(x)$ plays the role of  the given dircetion vector $\mathbf{v}$, but now $v$ is a "direction" in our infinite dimensional function space, into which we perturb our given location $y$ in that space. The role of $f$ is taken by $I$, so we could write in full analogy:
\begin{equation}
 \frac{\partial I(y) }{\partial v} 
 = \lim_{h \rightarrow 0} \frac{I(y + h v ) - I(y)}{h}
\end{equation}
and call that expression the directional derivative of $I$ into the direction of $v$ at $y$. However, this is not the usual notation and terminology. Instead, the f


% $ h v$ is called the variation of $y$


% Side note: For the analogy to be complete and fully consistent, we should also require that the norm of $v$ has to be unity. However, in the literature, that is typically not done in the definition of the Gateaux derivative. This is not such a big deal because in the typical applications, we will require this derivative be zero, so any scalar proportionality factor doesn't matter anyway. One could perhaps conceive of removing the unit-length requirement in the definition of the directional derivative as well - if the vector $\mathbf{v}$ would have some length other than unity, the first order change in $f$ due to that length factor would be given by just that length. Any non-unit scale factor in the input vector would just scale the output value of the directional derivative accordingly, which would make sense. Anyway...

...tbc...










% I think, $F$ can be seen as the result of applying an operator to the function $u$? But it's not just any arbitrary operator - it is a function that can depend only on $x$ and its instantaneous values $u(x),u'(x)$ at that given $x$, not on any other function values of $u$, as the result of a general operator could


\subsection{The Solution: The Euler-Lagrange Equation}

%The Gateaux derivative of $I$ at $u$ into the "direction" of $v$ should vanish, i.e....

% ... Because $v$ was assumed to be arbitrary, the only way that this integral can vanish is when the integrand vanishes, so we may actually get rid of the integral and arrive at the simpler condition...


\begin{equation}
 \frac{d}{d x} \left(  \frac{\partial F}{\partial y'}  \right) = \frac{\partial F}{\partial y}
 \qquad \text{aka} \qquad
 \frac{d}{d x} F_y = F_{y'}
\end{equation}
% why is the derivative with respect a normal derivative and the others are partial derivatives? is it because the result of \frac{\partial F}{\partial u'} is only a function of x? 

\subsubsection{Special Cases and Generalizations}

\subsection{Examples}

\begin{comment}

-after Euler-Lagrange Eq:
In physics, the problem of minimizing such a functional is called the "princple of least action" and the idea is so fundamental that almost all differential equations that occurr in physics can be derived from such a principle. In this context, the function under the integral is called the "Lagrangian" of the system, typically denoted by $L$, and the Euler-Lagrange equation gives the solution of the problem.

It's appropriate now to take a step back and appreciate the view from the lofty height we have reached: we now consider a differential equation to be the *solution* of a problem that was posed on an even higher level. It may look like a partial differential equation due to the occurrence of derivatives with respect to $x,u,u'$ but it's actually an ordinary one because $u,u'$ are themselves functions of $x$ (verify!)

It's not even one particular differential equation but rather a recipe for deriving an infinite number of differential equations. Time to pat ourselves on the back for having understood one of the crown jewels of theoretical physics. 


-derivatives of functionals: variation (as continuous analog of the total differential), Frechet- and Gateaux derivative

-can we interpret the functional derivative (i.e. the variation) as some continuous analog of the norm of the
 gradient vector? can the minimization problem be cast into setting this norm to zero?
 
-make derivation of the variation similar to the one in Susskind's theorectical minimum, volume 1

-minimization of functionals 
 -applications: 
  -math: minimal surfaces, catenary, straight line as minimization problem
  -physics: principle of least action and least time, Lagrangian mechanics, 

-connection between variational problems and differential equations: a diffeq is the solution to a variational problem - how can we go the other way around and find the variationl problem when given a diffeq?


https://en.wikipedia.org/wiki/Gateaux_derivative

https://www.youtube.com/watch?v=V0wx0JBEgZc
https://www.youtube.com/watch?v=VCHFCXgYdvY
https://www.youtube.com/watch?v=vqDHO2eKXcs

https://www.youtube.com/watch?v=MXXrAxBu3lo

\end{comment} 