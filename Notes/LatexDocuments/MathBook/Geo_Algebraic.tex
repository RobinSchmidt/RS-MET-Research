\section{Algebraic Geometry}
Algebraic geometry investigates the sets of zeros of multivariate polynomials and the geometrical shapes that are defined by these zero sets. Consider as example the bivariate polynomial $f(x,y) = x^2 + y^2 - r^2$ for some given constant $r$. Those points $(x,y)$ in the $xy$-plane for which this function produces zero as output define a geometric shape - in this case, a circle of radius $r$ centered at the origin. You can have multiple simultaneous equations that must be equal to zero and of course, you can also have more than two input variables. It's also possible to consider complex solutions, in fact, that's the more typical setting. In general, these sets of solutions to polynomial equations are called "algebraic varieties" and these are the main subject of interest in algebraic geometry.

\medskip
It is also possible to work in the field of rational numbers $\mathbb{Q}$ rather than in the field of complex numbers $\mathbb{C}$ or even in finite fields such as $\mathbb{Z}_p$ for a given prime number $p$. ...TBC..

\medskip
Fun fact: algebraic geometry and geometric algebra are two fields of mathematics that have nothing to do with each other. Isn't that weird? I really wonder, how connections between these fields could look like. Maybe we could start by interpreting the variables in the equations as multivectors instead of real or complex numbers? I have no idea but I think there just \emph{should} be some connection!

% Maybe take the general hypersphere equation v^2 - 1 = 0 where v is a vector and the v^2 is interpreted as scalar product of the vector v with itself and replace the scalar product by the geometric product. All the vectors that make up the hypersphere will still be solutions - but could there be other multivectors that satisfy the equation? Same thing for the hyperhyperbola v^2 + 1 = 0.


%===================================================================================================
\subsection{Algebraic Varieties}  % and Schemes
An \emph{algebraic variety} is the set of solutions to a system of polynomial equations $f_1(\mathbf{x}) = 0, \ldots, f_m(\mathbf{x}) = 0$ where $\mathbf{x} = (x_1, \ldots, x_n)$ and the $f_i$ are multivariate polynomials in these variables, i.e. polynomials with $n$ input variables that we may collect into an $n$-dimensional input vector $\mathbf{x}$ whenever this is notationally convenient. In general, this set of solutions is a set of points in an $n$-dimensional space. The dimensionality of the variety will typically be given by $n-m$ where $n$ is the number of variables and $m$ the number of equations [VERIFY!]. We may also collect the collection $(f_1, \ldots , f_m)$ of functions into a vector such that we write $\mathbf{f(x) = 0}$ for the whole system of $m$ equations. If there is only one single function $f$ and a single equation, we will write $f(\mathbf{x}) = 0$. In this case, the variety will be a curve. 


%A \emph{scheme} is similar to a variety but it takes into account multiplicities. Some part of a curve may belong to the set multiple times like when you take $(x^2 + y^2 - 1)^2 = 0$, you would get the unit circle two times because every solution of the circle equation $x^2 + y^2 - 1 = 0$ turns into two solutions when you square the polynomial on the left hand side. Varieties cannot model that because they are defined as sets - and sets do not distinguish between $\{1,2,2\}$ and $\{1,2\}$. Multisets do....
% Nah - that's wrong - schemes are not multisets

 ...TBC...

% ACRS uses multisets to define varieties. This is done to deal with repeated components of the curve or variety. The book doesn't use the term "variety" and instead talks about "hypersurfaces". Funny enough, it nonetheless uses the letter V for the "hypersurface" without explaining for what that V is supposed to stand. I have a hunch. Seems like the "hypersurfaces" in ACRS are more like "schemes":

% https://en.wikipedia.org/wiki/Algebraic_curve
% https://en.wikipedia.org/wiki/Algebraic_surface

% https://en.wikipedia.org/wiki/Scheme_(mathematics)
% is basically like a variety but takes into account multiplicities and the underlying number system is not necessarily the familiar real or complex numbers but any commutative ring.

% Explain that extended notion here, too

% Explain potential multiplicity of components. A component of the variety may be included twice or thrice etc.

%---------------------------------------------------------------------------------------------------
\subsubsection{Parameterizations}
Defining a shape as the solution set of a system of equations is also called an \emph{implicit definition}. Sometimes it is more convenient to have a more explicit representation of the set of points. A fully explicit representation would be, if we could isolate one variable and express it explicitly as function of all the others. But requiring such a functional representation is often too restrictive - there are some shapes that simply cannot be represented that way. For example, we could try to represent the circle explicitly as $y = \sqrt{r^2 - x^2}$ but that would give us only the upper half the circle unless we interpret the square-root as multi-valued function, which is already inconvenient in this very simple toy example and in more complicated cases, things may get out of hand even more. If a fully explicit representation is not possible or practical, i.e. if we can't express one coordinate as function of the others, the second best thing is to let \emph{all} the coordinates be functions of a set of some \emph{auxiliary} variables which we call parameters. In the case of a circle, that could look like $x(t) = \cos(t), y(t) = \sin(t)$ for $t \in [0, 2 \pi]$. In such a representation we call $t$ the parameter. A surface, such as a sphere, would require two parameters which are often named $u$ and $v$. Such parametric representations are actually more common in differential geometry. Here, in algebraic geometry, we more often work with the implicit definitions and have some constraints for what kind of functions are allowed, namely polynomials. Sine and cosine, by virtue of being transcendental functions, do not really seem to belong in a field carrying the name "algebraic". Actually, the constraint to use only polynomials applies only to the implicit definitions and not necessarily to parameterizations, but still.

% - but it might be nicer and cleaner if we could at least restrict those parameterizations to algebraic functions as well.

\paragraph{Finding Rational Parameterizations}
The parameterization of the circle via the cosine and sine functions given above is not the only possible way to parameterize the circle. It will probably be the most common one in most practical contexts (such as computer graphics) but from an algebraic point of view, it has a flaw: it requires usage of transcendental functions. Wouldn't it be much nicer in an algebraic context if we could also use purely algebraic functions to parameterize it? We can and in fact, we need only rational functions - not even roots are needed. I will give a recipe to find a rational parameterization of the unit circle that can sometimes be used for other curves as well. We proceed as follows:

%To find a rational parameterization of an implicitly given curve, we sometimes can proceed as follows:

...TBC...drag in text from the file RationalParametrization.txt

% https://en.wikipedia.org/wiki/Circle#Parametric_form

% https://people.reed.edu/~jerry/131/conics.pdf
% explains how the rational parameterization of the unit circle is related to the standard substitution t = tan(x/2) in intergrals of rational functions in sin(x), cos(x), etc.

% this too:
% https://en.wikipedia.org/wiki/Tangent_half-angle_substitution

\paragraph{From Parametrization to Equation}
Now we look at the inverse problem: We assume that we have a rational parameterization given and we ask what the corresponding implicit equation is. ...TBC...

% circle: ACRS, pg 2, general: 68 - has also algorithm for the inverse problem

% important questions: find a (rational) parameterization, is the zero set a manifold? what topological invariants does it have?

% Bezout's Theorem


% https://en.wikipedia.org/wiki/Algebraic_variety
% https://mathworld.wolfram.com/AlgebraicVariety.html



%---------------------------------------------------------------------------------------------------
\subsubsection{Examples}

\paragraph{Circles, Spheres and Hyperspheres}
As a simple example, consider 2D space and the single equation $x^2 + y^2 - 25 = 0$. This equation defines a circle of radius $5$ centered at the origin of the $xy$-plane. If we look at 3D space, we could define a sphere of radius $r$ via the polynomial equation in 3 variables $x^2 + y^2 + z^2 - r^2 = 0$. Note that the set of points that satisfies this equation is only the surface of the sphere, not the full ball. So, the dimensionality of the set of points that satisfies this equation is 2, not 3. 

\paragraph{Conic Sections}
A circle is defined by a bivariate polynomial of degree 2, i.e. a quadratic polynomial. The circle is therefore also called a curve of degree 2 or quadratic curve. Besides the circle, all conic sections, i.e. sets of solutions of equations of the form $0 = A x^2 + B y^2 + C x y + D x + E y + F$, fall into this category. They are called conic sections because these shapes also arise from intersecting a cone with a plane.

\paragraph{Elliptic Curves}
The set of solutions of $y^2 = x^3 + a x + b$ for some given values $a,b$ is called an "elliptic curve". These are not to be confused with actual ellipses, which are special cases of conic sections. Rather, elliptic curves represent a canonical form of the generalization of conic sections up to degree 3 (verify!).



\paragraph{Torus}

%simple examples: cassini curves, lemniskate, torus

% ACRS, pg 72: 
% -Nodal cubic curve: y^2 = x^2 + x^3
% -Folium of Descartes: x^3 + y^3 = 3 x y

% https://en.wikipedia.org/wiki/Lemniscate
% https://de.wikipedia.org/wiki/Lemniskate
% https://en.wikipedia.org/wiki/Polynomial_lemniscate
% https://en.wikipedia.org/wiki/Fermat_curve   x^n + y^n = z^n
% https://en.wikipedia.org/wiki/Ruled_surface

% -Give implicit equation and parametrization(s) whereever possible and if possible also an explicit
%  formula




%---------------------------------------------------------------------------------------------------
\subsubsection{Problematic Intersection Points}
Consider the situation where we have two polynomial equations $f(x,y) = 0$ and $g(x,y) = 0$ in 2D and we want to find all the intersection points of the two curves that are defined by the two polynomial equations respectively. Such intersection points can be found by parameterizing both curves with a parameter $t$ and then solving the equation $f(x(t),y(t)) = g(x(t),y(t))$ for values of $t$ such that the equation is satisfied. For simplicity, let's assume that $g(x,y) = ax + by + c$, i.e. $g$ is only of degree one such that defines a straight line. In an ideal world, we would like to see exactly $n$ intersection points between the curve $f$ and the line $g$ if the polynomial $f$ has degree $n$. We can indeed make that (and more) work by tweaking the problem setting appropriately whenever we encounter a problematic situation in our current setting.

% What would it mean to just set $f(x,y) = g(x,y)$ and solvig for pairs $(x,y)$ that satisfy the equation?

\paragraph{Intersections at Complex Coordinates}
At first, we assume that our "current setting" takes place in the usual Euclidean $xy$-plane which we also call $\mathbb{R}^2$. If we take $f(x,y) = x^2 + y^2 + 1$ and $g(x,y) = 0$, we can easily convince ourselves that no pair $(x,y)$ of real numbers will ever satisfy the equation $f(x,y) = g(x,y)$ which becomes $x^2 + y^2 + 1 = 0$. How can we find a parameter $t$ for the parameterized curves when even the desired situation that our $t$ should give rise to is impossible in the first place? Well, it is not impossible when we allow $x$ and $y$ to be complex valued. In that case $x = 0, y = \i$ would work, for example. Therefore we will also allow our parameter $t$ to be complex valued [VERIFY!]. So, our first tweak to the problem setting setting is that we move it from $\mathbb{R}^2$ to $\mathbb{C}^2$. This will not solve all of our problems but it gets us some way into the right direction. ...TBC...

% -solution: use the field of complex numbers

\paragraph{Intersections at Infinity}
A second problem that we may run into is exemplified by the following situation: let $f(x,y) = 2 x - y + 1$ and $g(x,y) = 2 x - y + 2$. These define two parallel lines that obviously intersect nowhere - not even when $x$ and $y$ are allowed to be complex. The solution to this problem is, informally, that we "add points at infinity" and say that two parallel lines intersect at such a point at infinity ...TBC...

% -Explain vanishing points

% -solution: consider also intersections at infinity

% another problem is that (components of) curves could coincide. Weitz in his video (Satz von Bezout) just says that this situation is disallowed but I think, it can be handled via the multisets. Parts of curves can indeed be in the set multiple times. Ah - but I think what Weitz means at 47:13 is the case when f(x,y) and g(x,y) have common components - not when f and/or g have some of their own components multiple times. Then we would get infinitely many "intersections" - actually a continuum of overlap. I think, it can be ruled out by saying that f and g should have no common polynomial factors. Weitz mentions irreducibility

\paragraph{Multiplicities of Intersections}
Consider $f(x,y) = x^2 - y$ and $g(x,y) = y$. If we draw the curves defined by setting each equation individually to zero, we will draw the parabola $y = x^2$ for $f$ and the horizontal line $y = 0$, i.e. the $x$-axis, for $g$. These two curves do not intersect but rather touch at $(x,y) = (0,0)$. The horizontal straight line $g$ is tangential to the parabola $f$ at this point. Such points of tangency highlight yet another problem that we might run into. In a sense, such a point of tangency counts as two intersections. That can be justified by considering what happens when we perturb $g$ slightly by moving it a bit up. The single point of tangency turns into a pair of points of intersection. When we move $g$ down instead, there will no real (i.e. visible) intersection at all anymore. However, looking at the algebra, we will discover that there will again be two intersections - just this time, they will be at complex valued coordinates. The point of tangency is just the edge case when two complex intersections transition into two real intersections. It's two intersections all along that move around continuously in the complex plane as we tweak $g$. For some specific setting of $g$, they happen to coincide but they still count as two. That is a very informal geometric justification for counting the point twice - but the algebraic justification is more compelling: When we try to find the parameter values $t$ for the points of intersection, we are effectively searching for roots of a polynomial in $t$. Such roots naturally come with a multiplicity. ...TBC...

% perturb g a bit - shift it a bit up - the point of tangency turns into two points of intersection. In general, in teh complex domain, we will see higher order saddles so we will get more intersection points by such a perturbation when there is a higher "order of tangency" (verify!)

% -tangency, tangetial intersections or rather touching points
% -solution: count intersections with multiplicity

%===================================================================================================
\subsection{Projective Space}
What we informally and vaguely called "adding points at infinity" will now be fleshed out for real. The idea is to go from the normal $n$-dimensional vector space to a so called \emph{projective space}. This is a space with $n+1$ dimensions and the vectors in this space do not represent points in the $(n+1)$-dimensional space but rather lines through the origin. Each vector in the projective $(n+1)$-space is interpreted as being just a representative of a whole equivalence class of vectors consisting of all scalar multiples of that vector. Vectors or points in the original $n$-dimensional space are recovered by considering the intersections of these lines with a specific (hyper-) plane - namely the one for which the extra dimension has a value of one. 

% https://en.wikipedia.org/wiki/Projective_space
% https://en.wikipedia.org/wiki/Projection_(mathematics)#Central_projection

\subsubsection{Homogeneous Coordinates}
The way to realize this projective space is to switch to so called \emph{homogeneous coordinates}. To get a feeling for how that works, let's start with our usual Euclidean plane $\mathbb{R}^2$. We'll actually eventually apply the idea to $\mathbb{C}^n$, but imagining to start with $\mathbb{R}^2$ is okay for intuition building and this intuition happens to be also practically relevant for computer graphics. The points in our original space $\mathbb{R}^2$ are given as pairs $(x,y)$. What we now do is to add an extra coordinate which we call $w$ such that our points are now given as triples $(x, y, w)$. If $w \neq 0$, then these triples will encode the point $(x/w, y/w)$ in our original space [VERIFY!]. If $w=0$, they kind of still do represent $(x/w, y/w)$ but since $w = 0$, these points will be "at infinity" - and it's not just any infinity but an infinity that lies ahead in a specific direction, namely into the direction of the vector $(x,y)$. In some sense, we have added directional infinities to our space. We can envision these points as lying on a perimeter of a circle with infinite radius such that this perimeter is infinitely far away. But there's a catch: diametrically opposite points on this infinite circle are identified with one another - the infinity to the right is the same as the one to the left (and may just be called the horizontal point at infinity). The mental picture is that we "wrap-around" at the (directional) infinities. This is the 2D version of the way we think of the projectively extended real number line (see \cite{WK_ProjExtReals}) with its single added point at infinity. The fact that we encode a 2D vector $(x,y)$ by a triple $(x,y,w)$ by saying that we get our 2D vector back via $(x/w, y/w)$ implies that the "encoding" of a given finite $(x,y)$ vector is not unique. For example, the triple $(15,12,3)$ encodes the same 2D vector as the triple $(5,4,1)$, namely the 2D vector $(5,4)$. It turns out that for $w \neq 0$, we can always normalize our triple in such a way that $w=1$: We simply divide all 3 components by whatever $w$ currently is. The subset of $\mathbb{R}^3$ for which $w = 1$ is the horizontal plane, parallel to the $xy$-plane at a $w$-height of $1$. Our $(x,y,w)$ triples really represent lines through the origin of $\mathbb{R}^3$ and the intersection points of these 3D lines with the $w=1$ plane in 3D space determine the $(x,y)$ coordinates of our point in the original 2D space. To distinguish coordinate tuples in the projective space from those in an ordinary vector space, some authors denote the vectors using colons instead of commas as in $(x : y : z)$ instead of $(x, y, z)$. We will adopt this practice along with the convention of using the letter $w$ for the extra coordinate which we will always put last into the extended coordinate tuple as in $(x : y : w)$ or $(x : y : z : w)$. Some authors put the extra ("$w$") coordinate first. The colon is supposed to hint at a division by $w$ which is what we will have to do to recover our coordinates in the original $n$-space as we will see. That makes me think that $(x,y,z : w)$ might be an even better notation - but I'll stick to the established one. There is another caveat: We have said that the homogeneous coordinate vector $(x : y : w)$ stands for the vector $(x/w, y/w)$ in ordinary coordinates and we have said that if $w=0$ and $x$ and $y$ are nonzero, it stands for the point at infinity into the $(x,y)$ directions (both ways - forward/backward). But what if $x$ and/or $y$ are also zero? Actually, the case that they are both also zero is disallowed: the triple $(0:0:0)$ is not a valid homogeneous coordinate vector. But something $(0:3:0)$ is allowed and it seems to indicate that we need to compute $0/0$ for the $x$-coordinate of the ordinary vector. But we do not really need to compute an $x$-coordinate because we are dealing with a point at infinity which has no $x$-coordinate. Points at infinity do not really have coordinates in the usual sense - they only have directions. Our vector could only potentially have a direction component into the $x$-direction. But this particular infinite point hasn't one. The triple $(0:3:0)$ represents the two points at infinity into the purely vertical directions. The general rule is: whenever $w=0$, the represented point is at infinity and remaining components give the direction of the infinite point - except when they are all zero, which is not allowed. [VERIFY!]

% -Explain that the homogeneous tuple $(0:0:0)$ is not allowed.
% -Explain what happens in a case $(0,y,0)$ (which is allowed) to the 0/0 expression for recovering the x-coordinate in 2D space

% explain the notation (x : y : w)

%give a sort of 2D projection
%...TBC... 


% https://en.wikipedia.org/wiki/Homogeneous_coordinates
% https://en.wikipedia.org/wiki/Extended_real_number_line
% https://en.wikipedia.org/wiki/Projectively_extended_real_line


% Explain why the space is called "projective". When w != 0, we may normalize the triple wo w=1. We can interpret the w=1 plane as a slice of xyw-space and if we cut out this slice, we get our original xy-plane back. ACRS gives a "projection function" pi - but this is *not* a function that projects 3D vector onto a 2D plane. To the contrary: it "projects" 3D vectors (i.e. points) onto the embedding 3D lines in the sense of turning the points into these lines. This is a different use of the word "projection". Normally, when we "project" something, we lose one or more dimensions. We usually "project" a 3D point onto a 2D plane or similar. But here we "project" a 3D point onto/into a 3D line. Figure out how other authors use the term projection in this context! This is confusing!

% Explain how the projective space is really the space of all lines through the origin in a space one dimension higher than the original space. The *normalized* (n+1) tuples can be identified with the w=1 plane and the coordinates in R^n space are obtained by intersecting the lines with that plane.

\subsubsection{Homogeneous Polynomials}
When we are working with homogeneous coordinates, we give the space one extra coordinate. We use $(n+1)$ dimensional space but we still want to use polynomials to describe shapes in $n$-dimensional space by way of zero-sets of polynomial equations. That puts some constraints on the kinds of polynomials that we can use for this purpose. In 2D, if $(x : y : 1)$ is a point such that $p(x,y,1) = 0$, we'd better make sure that this occurs if and only if $p(x/w, y/w, w) = 0$ for any $w$ we may choose. Otherwise the shape would not be well defined. The way we ensure this is called homgenization. We take our original polynomial in $x,y$ and multiply each monomial in it by an appropriate power of $w$ such that each monomial has the same total degree. A polynomial with that property is called homogeneous and being homogeneous is indeed the property that we need to satisfy our constraint. If a multivariate polynomial $f(\mathbf{x})$ is homogeneous of degree $n$, then we have $f(k \mathbf{x}) = k^n f(\mathbf{x})$ for any input multiplier $k$, so in particular, $f(k \mathbf{x}) = 0$ whenever $f(\mathbf{x}) = 0$ [VERIFY!].

...TBC...

%If a polyno


%\subsubsection{Principle of Duality}
% In the usual Euclidean space, we can say things like: "For every pair of points, there is a unique line that passes thorugh them". The "dual" to this statement would be: "Every pair of non-parallel lines intersect in a unique point". In a projective space, we can even remove the somewhat unelegenat qualifier "non-parallel" [VERIFY!]

% https://en.wikipedia.org/wiki/Duality_(projective_geometry)
% https://en.wikipedia.org/wiki/Duality_(projective_geometry)#Principle_of_duality

% https://www.youtube.com/watch?v=QP4_uUS6RiU

%===================================================================================================
\subsection{Elliptic Curves}

\subsubsection{Elliptic Curves} 
% asterisk means: can be skipped on first reading
Here, we will consider a certain subset of bivariate polynomial equations that turned out to be in the sweet spot between being enough to actually tackle them and complex enough to allow for some interesting features. I'm talking about the so called elliptic curves. But didn't we already talk about ellipses as one particular type of conic section? Yeah - an \emph{elliptic curve} is actually \emph{not an ellipse} but rather the set of solutions of a bivariate polynomial equation of degree 3. ToDo: explain etymology if the term

\paragraph{$\star$ Group Structure} % star means: can be skipped on first reading
The set of rational points on such an elliptic has an interesting property: together with a suitably defined binary operation between these points, they form an algebraic structure known as commutative group. That basically means that we can plug two rational points into our operation and the operation will produce another rational point on the curve. In the context of elliptic curve theory, this operation is usually denoted  with $+$ and called addition - but it is \emph{not} just the regular vector addition. ...TBC...
% see Elliptic Tales, pg 116
% mention that i works also when we don't work over Q but over a finite field
% The points on the elliptic curve




\subsection{$\star$ The Abstract Perspective}
This section can be skipped on a first reading of the book. It references rather advanced ideas that are properly introduced only (much) later - specifically \emph{ring theory} from abstract algebra.




\subsubsection{Polynomial Rings}
Algebraic geometry, when viewed as the business of trying to find the set of solutions of multivariate polynomial equations, is actually about quite intuitive ideas. However, when you open a textbook on algebraic geometry written for real mathematicians, you will discover that it will talk about very abstract ideas that sound like they have nothing to do with geometry. In the abstract algebra perspective of algebraic geometry, we consider quotient rings of polynomial rings. For example, in 2D, when we have a bivariate polynomial like $p(x,y) = x^2 + y^2 - 1$, we will consider the ring $R = \mathbb{R}[x,y] \setminus (x^2 + y^2 - 1)$ and analyze its properties with the arcane machinery of ring theory. ...TBC...

% Is this the ring of all polynomials that are zero on p? Or is it the ring of all polynomials
% but we are allowed only to plug in values for which p(x,y) = 0 i.e. only points on the unit
% circle?
% Our ring $R$ is the ring of all polynomials $q(x,y)$ that

% What is algebraic geometry?
% https://www.youtube.com/watch?v=MflpyJwhMhQ
%
% -Maybe this chapter should have a last section: Ring Theoretic Perspective or similar which 
%  can be skipped on a first reading
%
% -Maybe bring a 1D example: take a polynomial like p(x) = (x+2)*(x-3) = x^2 - x - 6 with 
%  roots at {-2,3}
% -Consider the ring R[x] \ p(x)
% -It is the ring of all polynomils that has zeros at -2,3. The set of all these polynomials
%  is considered to form an eqivalence class.
% -Any polynomial that is zero at -2 and 3 must have p(x) as factor, so any polynomial with p
%  as factor is considered to be equivalent...right...or wrong?

%
% -Or is it like we we consider the ring of all polynomials but we allow only to plug in 
%  points (x,y) for which the polynomial is zero?



% The shocking connection between complex numbers and geometry.
% https://www.youtube.com/watch?v=5RHSS-zMaAQ
% -about Riemann surfaces

% What is algebraic geometry?
% https://www.youtube.com/watch?v=MflpyJwhMhQ

\begin{comment}



https://de.wikipedia.org/wiki/Algebraische_Geometrie
https://de.wikipedia.org/wiki/Algebraische_Variet%C3%A4t
https://de.wikipedia.org/wiki/Hilbertscher_Basissatz
https://de.wikipedia.org/wiki/Gr%C3%B6bnerbasis

https://en.wikipedia.org/wiki/Algebraic_geometry
https://en.wikipedia.org/wiki/Algebraic_variety

https://en.wikipedia.org/wiki/Zero_of_a_function#Zero_set
https://en.wikipedia.org/wiki/Projective_plane

https://en.wikipedia.org/wiki/Rational_mapping

https://en.wikipedia.org/wiki/Elliptic_curve

https://en.wikipedia.org/wiki/Weierstrass_elliptic_function


https://en.wikipedia.org/wiki/K3_surface
https://en.wikipedia.org/wiki/Calabi%E2%80%93Yau_manifold

https://en.wikipedia.org/wiki/Duality_(projective_geometry)

https://en.wikipedia.org/wiki/Implicit_surface

https://en.wikipedia.org/wiki/Weil_conjectures

https://en.wikipedia.org/wiki/Sheaf_(mathematics)
A sheaf is a tool for tracking data (such as sets, abelian groups, rings) attached to the open sets of a topological space. For example, for each open set, the data could be the ring of continuous functions defined on that open set.


-conic sections in 2D and 3D, classification
-elliptic curves
-lemniskate, contour plots
-polynomials with integer/rational coeffs -> integer and rational solutions -> elliptic curve cryptography
-what about allowing more general classes of functions?
-what about multiple simultaneous equations - what does that imply for the dimensionality of the solution set?
-what are important features of the solution sets? connectedness?

-seems like differential geometry deals with parameteric representations and algebraic geometry with implicit representations of geometric shapes (manifolds?)
-is there a way to convert between these representations? ..yeah...this seems to be actually a difficult research area

Tikz:
https://texample.net/tikz/examples/feature/angles/
https://texample.net/tikz/examples/feature/foreach/

https://pbelmans.ncag.info/blog/2010/11/11/howto-draw-algebraic-curves-using-pgftikz/

-write a c++ function that takes in an implicit function f(x,y) = 0 and spits out a vector of vectors of 2D points (the outer vector is because we may have multiple curves), this can then be converted into svg or tikz code (via suitable code-generators that take as input the coordinate vectors)
-with this code, generate tikz figures for elliptic curves, maybe x^2 + y^3 + k = 0 for different values of k

Fun fact

Wie muss man fragen, um "sch√∂ne" Antworten zu bekommen? (Der Satz von Bezout):
https://www.youtube.com/watch?v=dyehHqozzqE


ALGEBRAIC CURVES - An Introduction to Algebraic Geometry
WILLIAM FULTON
https://dept.math.lsa.umich.edu/~wfulton/CurveBook.pdf

https://www.youtube.com/watch?v=o-xwmTODTUI
Quick Understanding of Homogeneous Coordinates for Computer Graphics

Putting Algebraic Curves in Perspective
https://www.youtube.com/watch?v=XXzhqStLG-4



What is...Schubert calculus?
https://www.youtube.com/watch?v=S4oFiCKzWlo


\end{comment}