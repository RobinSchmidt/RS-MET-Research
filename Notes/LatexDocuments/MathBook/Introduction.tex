\chapter{Introduction} 
[TODO: this is not yet well structured - fix this!]

\section{Foundations} 

This book is about applied math, so we will not go deeply into the foundations of math. However, a brief and very superficial look into this topic is a good idea to set the stage for the material that follows. It also establishes the basics of the language which we will need to talk about mathematical concepts.

\subsection{Logic}
Math is the pursuit of finding truths, so it makes sense to have a framework, within which we can say that something is true or false. In mathematics, that framework is mathematical logic, more specifically propositional logic (sometimes called zeroth order logic) and predicate logic (a.k.a. first order logic). 

\paragraph{Propositional logic} A \emph{proposition} is a statement that can be either true or false. You also have ways of combining given propositions $A,B$ to make new, more complex propositions. For example, you can combine two propositions with a logical "and" (usually denoted as $\wedge$). The resulting new proposition $A \wedge B$ ("A and B") is true, if and only if both of the input propositions $A,B$ are true, otherwise it's false. You also have a logical "or" (denoted as $\vee$), which in this context is taken to be an inclusive or: the combined proposition $A \vee B$ ("A or B") is true, if any one of the input propositions or both are true. You also have a logical "not" (denoted as $\neg$) which takes a single proposition as input and the result $\neg A$ ("not A") is true, if the the input $A$ is false and vice versa. These operators that take in one or two propositions to produce a new proposition are called logical \emph{connectives}. In this context, the basic propositions like $A,B$ are sometimes called \emph{atomic}. Logic also provides the tools that are required to figure out whether a given proposition is true, given that some other propositions are true. That process of drawing conclusions from given (true) propositions is called deduction. In this process of deduction, yet another logical connective, called the \emph{implication} and denoted by $\then$, plays a central role. A proposition like $A \then B$ means: "$A$ implies $B$" which you may also interpret and read as "$B$ follows from $A$" or as "if $A$, then $B$". The combined proposition $A \then B$ evaluates to "true" if, whenever $A$ is true, then $B$ is also true. It makes no statement about situations when $A$ is false, i.e. when $A$ is false, it doesn't matter, if $B$ is true or false - $A \then B$ still evaluates to true. The only way that $A \then B$ can evaluate to false is when $A$ is true and $B$ is false. Logical equivalence of two propositions $A,B$ is also sometimes important and denoted as $A \mequiv B$ and it can be decomposed into two implications that are "and"ed together: $(A \then B) \wedge (B \then A)$, i.e. into a mutual implication. The parentheses are actually optional due to suitably defined operator precedence rules: $\then$ precedes $\wedge$. You can read the statement $A \mequiv B$ as "$B$ if and only if $A$", "$A$ if and only if $B$" or "$A$ is logically equivalent to $B$". To build up mathematics, propositional logic is not quite expressive enough, so...TODO: I think, the last part is wrong - there's a difference between logical and material equivalence - figure out!
% https://en.wikipedia.org/wiki/Propositional_calculus
%https://en.wikipedia.org/wiki/Logical_connective
% explain redundancy of the set of connectors - pick the topic up at where we see that the equivalence can be expressed as "and"ing two implications
% explain logical implications and the equivalent ways to express them: (A -> B)  <->  (~B -> ~A)  <->  (~A or B)  <->  (~(~B and A))  ...this is used later in the section about category theory
% read it as: "A implies B", "B follows from A", "A is logically equivalent to B"

% explain logical equivalences (A <-> B)  <-> (A -> B and B -> A)
% read it as "B iff A", "A iff B" where "iff" is short for "if and only if"

%introduce truth tables


\paragraph{Predicate Logic} builds up on propositional logic and a bit of set theory to let you talk about objects and relations between them. There, you have so called quantifiers like the symbol for "there exists an object such that..." (denoted as $\exists$) or a symbol for "for all objects it is true that..." (denoted as $\forall$). There are yet other levels and kinds of logic, but these two are enough for the moment. ...TBC...
%introduce the $\exists ! x$ quantor meaning "there is exactly one x, such that"

\subsection{Proofs} % find better title
%\subsection{Finding Truths} % find better title

\subsubsection{Axioms}
One has to start somewhere. That starting point is typically a set of \emph{axioms} together with the rules of logic. An axiom is a proposition that is just assumed to be true without further justification. Axioms should state things that are "obviously true". An example are the Peano axioms, some of which are: zero is a natural number, each natural number has a successor, any number is equal to itself, etc. If you really want to build up the whole tower of mathematics axiomatically, you have to \emph{choose} a set of axioms and from there, using only the rules of logic, i.e. deduction, find new propositions that are also true.
% Mention Peano Axioms, Zermelo-Frenkel(-Choice) ZFC, etc.

\subsubsection{Theorems and Proofs}
If you want to prove a proposition, the tools that you have in hand are all the propositions that are already known to be true together with the rules of logic. A proposition is known to be true if it is either an axiom or it has been previously proven by the same technique. A \emph{proof} for a proposition is a sequence of true propositions in which each one follows from known or previous ones by applying the rules of logic and the last of which is the one you actually wanted to prove in the first place. If a proposition of some degree of importance has been proven to be true, it becomes a \emph{theorem}. The idea of a theorem is a fundamentally important concept in math - math is all about finding theorems. You may have observed a pattern by looking at a bunch of examples and you may \emph{conjecture} that the pattern is generally true. What you then have to do is to find a proof for your conjecture. If you have succeeded in this highly creative endeavor, i.e. your proof is determined to be correct by the mathematical community, then your conjecture is elevated to the venerable status of a theorem. And if the theorem is important enough and you were the first to prove it, you will typically achieve immortality by having your name attached to the theorem for the rest of eternity. Thousands of years later, still everybody knows the name of Pythagoras today - although, it wasn't actually him who proved "Pythagoras' Theorem" - sometimes the world is a little unfair, too :'-(. Along the way of finding a proof, you may generate a whole bunch of proven propositions, some of which are only instrumental to your final goal, some of which are spinoffs, etc. There are some other terms for such "lesser theorems" such as "lemma", "corollary", etc. A theorem is usually a result with a certain level of importance, generality and usefulness. You wouldn't call something like $3+5=8$ a theorem, for example - although it manifestly is a true proposition (and can actually be proven).

\subsubsection{Definitions}
OK - this is kind of meta. We now have to \emph{define} what \emph{a definition} is. A definition is actually just an agreement about certain conventions to be used in the following material, in particular about what a given term or symbol is supposed to mean. Definitions often stand at the beginning of the introduction of a new subject. Definitions cannot be right or wrong. They can just be more or less useful. For a definition to be useful, it should clearly encapsulate a concept that is important in the development of all the things further down the line. The so defined term or symbol shall be used a lot in the material to be developed and will be referred to often. It makes sense to pick definitions in such a way that theorems can be stated succinctly. What the most useful definitions for a particular (new) mathematical subject are is often not clear from the get go but instead crystallizes out over time as experience with the new subject grows and when a bit of hindsight is available. As users of math, we may take definitions for granted because smart mathematicians have already figured (and fought) them out for us (and for themselves, of course). But we should keep in mind that they are fundamentally just conventions to make it possible (and ideally convenient and easy) to talk about a given subject. They are not fundamental truths. They just establish the language that we will use. That's why sometimes different authors use different definitions. Sometimes there is just no universal consensus (yet or ever) about which definitions are the most useful ones. Which ones are more or less useful may also differ from field to field. So, care has to be taken when reading mathematical material from different sources - the definitions in use may not always agree.

% Maybe everything up to here should go into an "Introduction"
% Maybe: preface - toc - introduction ...Part 1...is better

% Formulas
% -Explain why mathematicians use formulas.
% -Express the law ofd cosine in words to make the point
%  https://en.wikipedia.org/wiki/Law_of_cosines
%  The square of one side is equal to the sum of the squares of the two other sides reduced by
%  twice their product multiplied by the cosine of the angle opposite to the one side. ..or something