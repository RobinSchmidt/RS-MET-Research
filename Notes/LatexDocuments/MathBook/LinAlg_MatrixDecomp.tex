\section{Matrix Decomposition}



% https://en.wikipedia.org/wiki/Matrix_decomposition

%---------------------------------------------------------------------------------------------------
\subsection{LU Decomposition}
The LU-decomposition decomposes the matrix into a product $\mathbf{A = L U}$ where $\mathbf{L}$ is a lower triangular matrix and $\mathbf{U}$ is an upper triangular matrix. The LU-decomposition is algorithmically basically Gaussian elimination with some modifications. If you have an LU decomposition of a matrix $\mathbf{A}$ available, then it is straightforward to solve an equation $\mathbf{Ax = b}$. In practice, one often computes a decomposition of the form 

..TBC...explain details of algorithms for the decomposition and the solution of linear systems.
% Lower Triangular, Upper Triangular

% https://en.wikipedia.org/wiki/LU_decomposition

%---------------------------------------------------------------------------------------------------
\subsection{QR Decomposition}
% Orthonormal, Upper Triangular
% I think, the R stands for right-triangular?

%https://en.wikipedia.org/wiki/QR_decomposition

%---------------------------------------------------------------------------------------------------
\subsection{Eigendecomposition aka Diagonalization}
The most convenient decomposition of a matrix in terms of ease of solving equations involving the matrix and in terms of geometric interpretability of what the matrix actually does is the so called diagonalization of the matrix. ...TBC...

% it's also called Eigendecomposition or Spectral Decomposition




\begin{comment}
	
Dear linear algebra students, This is what matrices (and matrix manipulation) really look like	
https://www.youtube.com/watch?v=4csuTO7UTMo	

Interpretation of matrices:

-in the context of solving linear systems of equations
 -each row gives a left-hand-side of one equation the system
 -each row defines a hyperplane, the solution of the system is the point where all
  hyperplanes intersect
 -each column represents a vector and we are looking for the coeffs to scale the 
  cols by to obtain agiven target vector on the RHS

-In the context of linear transformations:
 -the j-th column tells us where the j-th unit basis vector is mapped to
	
\end{comment}