\chapter{Multivariable Calculus}
Multivariable calculus is the calculus of continuous functions that may depend on several input variables and/or produce several output variables. We usually interpret these functions as taking a vector valued input, i.e. their input is seen as a vector  $\mathbf{x} = (x_1,x_2,\ldots,x_n)^T$ where $n$ is the number of inputs and write the function as $f(\mathbf{x})$. When the symbol $f$ is not written in boldface, we mean that the output of the function is just a scalar. When there's only a small number of inputs, such as 2, we may also write things like $f(x,y)$. If the output is also vector valued, we write $\mathbf{f(x)}$. Functions that take a vector as input and produce a scalar as output are called \emph{scalar fields}. When both, input and output, are vectors of the same dimensionality, we may also call the function a \emph{vector field}.

\medskip
As with single variable calculus, one may find minima and maxima of a function with multiple inputs using derivatives by requiring them to be zero (yes: derivatives in plural!). This is important in optimization. Because we now have several input variables, we may take derivatives with respect to any of them which is why they are called \emph{partial derivatives} in this context. We can collect them in a vector which we then call the \emph{gradient}. The tool to compute areas under functions - the integral - generalizes to compute other aggregate quantities such as lengths of curves, volumes and surface areas of 3D objects, the amount of a fluid flowing through a surface, the work done by a force field on an object moving through that field, etc. This is where calculus really comes to life as we compute actual real-world quantities. The multivariable version of a differential equation is a \emph{partial differential equation}, named like that because it involves partial derivatives. So, despite its name, a "partial" differential equation is actually a (much) more complicated thing than an ordinary differential equation. 

\medskip
A subfield of multivariable calculus, called \emph{vector calculus}, is mainly concerned with functions that live in the same 3-dimensional space that we do, making it suitable to describe many physical phenomena. The 3D vector calculus uses some special notations that are specific to 3D and do not readily generalize to an arbitrary number of dimensions. Most notably among them is the \emph{curl} which is defined by a certain cross product which itself makes only sense in 3D. Sometimes the equations are boiled down to just two dimensions, which you can easily embed in 3 dimensions, so some concepts of the 3D vector calculus  work in 2D, too - but it's a bit hacky (in particular, the curl becomes a scalar). In physical applications, the equations also often involve time which is then treated separately from the spatial dimensions. Time being treated as "something else" than space coincides with our daily experience but makes vector calculus less than ideal in the context of relativity where time is treated on equal footing, which is why you often see different formalisms used there. 
%such as "four-vectors"

\medskip
Alternatives to vector calculus that do generalize to higher dimensional spaces are \emph{exterior calculus} (aka calculus of \emph{differential forms}), \emph{tensor calculus} and \emph{geometric calculus}. All these calculi are based on their respective algebras each of which defines a particular product. The problematic cross product from 3D vector algebra is not a thing anymore in these algebras and the vector calculus (cross product based) idea of curl is replaced in these calculi by more general ideas.

% What about matrix calculus?

%\paragraph{Multivariate Functions}
% m inputs/variables, n outputs/functions
% special cases:
% m = 1, n > 1: parametric curves in nD space
% m = 2, n = 3: parametric surfaces in 3D space
% m = 3, n < 3: implicit curves (n=2) or surfaces (n=1) - the dimensionality of the
%               manifold is 3-n, I think. Each eq gives a constraint.
%
% Implicit curves/surfaces/manifolds


\begin{comment}

%\subsection{Basics} \include{MultivariateCalculusBasics} 
% multivariate functions, partial derivatives & gradient, Hessian, Jacobian, directional derivative, multiple integrals, (constrained) optimization (also numerical), parametrized curves/surfaces
%\subsection{Vector Calculus} \include{VectorCalculus} 
% scalar and vector fields, curl, div, line/surface/volume integrals, Green/Gauss/Stokes theorem,

%\subsection{Partial Differential Equations}
% transport, heat, wave, laplace/poisson, schrÃ¶dinger, maxwell, navier-stokes, Einstein, Dirac
%give them all in all possible formalisms (vector, exterior, tensor, geometric)...or maybe make a separate chapter "Phyiscs", give Maxwell's equations in the following formalisms: (1) original form in terms of partial derivatives, (2) vector calculus (div, curl, etc.), (3) integral form, (4) differential forms, (5) tensors, (6) geometric calculus
% sections: vector calculus, exterior calculus, geometric calculus, tensor calculus (ascending generality)
% scalar fields, vector fields, partial differentiation (grad, Jacobian, Hessian, Laplacian, divergence, curl), integral theorems (Green, Gauss, Stokes), differential forms, generalized Stokes theorem, Tensor fields



Maybe before Differentiation, Integration, etc. place a section "Mutivariable Functions" where the different kinds of functions are explained (scalar functions of multiple variables, curves, surfaces, etc.). Maybe call it "Functions in Higher Dimensions"


Matrix calc:

derivative of x to a matrix power.
https://www.youtube.com/watch?v=RyrOjRlLPvg

https://en.wikipedia.org/wiki/Jacobi%27s_formula

- Introduce functions of matrices like the matrix square-root, exponential, logarithm, sine, etc.
  The input and output to these functions should be a matrix

- Figure out what it could mean to raise a matrix A to the power of another matrix B, i.e. make
  sense of the expression A^B with A,B being matrices. We should try to retain some important
  properties like A^B * A^C = A^(B+C), (A^B)^C = A^(B*C). Definitely, we would like to have
  log(exp(A)) = A. The principle of permanence should be the guide.



Tensor Calc, Geometric Calc




\end{comment} 