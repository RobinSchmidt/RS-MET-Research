\section{Differentiation}

%===================================================================================================
\subsection{Partial Derivatives}
Let's assume we have a bivariate function $f$, i.e. a function with two inputs $x,y$, that produces one output $z$: $z = f(x,y)$. We can visualize this as a landscape above an $(x,y)$-plane where the height is given by the function value. We can take derivatives of $f$ with respect to $x$ and with respect to $y$. In the former case, $y$ is just treated as a constant and in the latter case $x$ is treated as a constant. These two derivatives of $f$ are called \emph{partial derivatives} and we denote them as $\frac{\partial f}{\partial x}$ and $\frac{\partial f}{\partial y}$, where the curly d symbol $\partial$ is a special math symbol that we read as "partial" - it's not a greek delta. The formal definition is:
\begin{equation}
 \frac{\partial f(x,y)}{\partial x} = \lim_{h \rightarrow 0} \frac{f(x+h,y) - f(x,y)}{h}, \qquad
 \frac{\partial f(x,y)}{\partial y} = \lim_{h \rightarrow 0} \frac{f(x,y+h) - f(x,y)}{h}
\end{equation}
In the text above, we wrote $\frac{\partial f}{\partial x}$ whereas in the definition, we wrote  $\frac{\partial f(x,y)}{\partial x}$. The former notation with suppressed input arguments $x,y$ is just an abbreviation of the more verbose latter notation. This abbreviation makes sense when it is understood from the context that $f$ is a function of $x,y$. Another, even shorter, notation for the partial derivatives is $f_x, f_y$. For a general multivariate function with scalar output $f(\mathbf{x})$ where $\mathbf{x} = (x_1,x_2,\ldots,x_n)^T$ where $n$ is the number of inputs, we can compute partial derivatives with respect to each input dimension. We denote these as $\frac{\partial f}{\partial x_i}$ where $i = 1,\ldots,n$. We could also write $f_{x_i}$ but we will rarely use this notation because an index with an index is typographically less than ideal. The formal definition of $\frac{\partial f}{\partial x_i}$ is given by:
\begin{equation}
 \frac{\partial f(\mathbf{x}) }{\partial x_i} 
 = \lim_{h \rightarrow 0} \frac{f(\mathbf{x} + h \mathbf{e}_i ) - f(\mathbf{x})}{h}
\end{equation}
where $\mathbf{e}_i$ is the unit vector in the $i$-th coordinate direction, i.e. it has a one at position $i$ and zeros everywhere else. As said: the computation of such partial derivatives is purely mechanic and we don't need to refer to our definitions for that. Instead, we just treat the function as if it would depend only on the variable with respect to which we differentiate and treat all other variables as constants.

%===================================================================================================
\subsection{Directional Derivatives}
Now let's assume we are given an arbitrary vector $\mathbf{v}$ of unit length. We define the \emph{directional derivative} of $f$ into the direction of  $\mathbf{v}$ as:
\begin{equation}
\label{Eq:DirectionalDerivative}
 \frac{\partial f(\mathbf{x}) }{\partial \mathbf{v}} 
 = \lim_{h \rightarrow 0} \frac{f(\mathbf{x} + h \mathbf{v} ) - f(\mathbf{x})}{h}
 = \frac{d}{d h} f(\mathbf{x} + h \mathbf{v}) \bigg\rvert_{h=0}
\end{equation}
where the RHS is a generalization of \ref{Eq:DerivativeViaH} which tells us how we could evaluate the limit (but we'll soon learn a simpler way to evaluate it). Note that the directional derivative into any of the coordinate directions $\mathbf{e}_i$ just reduces to the partial derivative with respect to coordinate $i$, so partial derivatives can also be seen as directional derivatives into very specific directions: namely, into the directions of our coordinate axes. [TODO: verify that the RHS is actually correct - the formula is not from a book - i found it myself by analogy to the evaluation formula for the Gateaux derivative in Baerwolff, pg. 792]

%===================================================================================================
\subsection{Higher Order Partial Derivatives}
Just like we could define the second derivative of a univariate function as the derivative of the derivative, we can define second order partial derivatives of a multivariate scalar function. Due to the fact that we now have $n$ input variables, we can form $n^2$ different second partial derivatives. If we first find the derivative of $f$ with respect to some $x_i$ and then take the result and find its derivative with respect to $x_j$, we obtain such a second order partial derivative. We write this as $\frac{\partial^2 f}{\partial x_i \partial x_j}$. If the function $f$ is twice continuously differentiable, then, according to \emph{Schwarz's theorem}\footnote{aka Clairaut's theorem or Young's theorem}, we will actually have the following symmetry:
\begin{equation}
	\frac{\partial^2 f}{\partial x_i \partial x_j} 
	=
	\frac{\partial^2 f}{\partial x_j \partial x_i} 
\end{equation}
which means the order of the differentiations makes no difference. We can first take the derivative with respect to $x_i$ and then with respect to $x_j$ or the other way around. The end result will be the same. We may also use the abbreviated notation $f_{xy}$ for $\frac{\partial^2 f}{\partial x \partial y}$ for a function that depends on $x$ and $y$, i.e. a low-dimensional function for which we assign different letters to the different input variables instead of using index notation. Note that the notation $f_{xy}$ does not imply that $f$ is a bivariate function that depends \emph{only} on the two input variables $x,y$. We could also find $f_{xy}$ of a trivariate function $f = f(x,y,z)$, for example.

\medskip
In the same way, we can find third order partial derivatives and there will be $n^3$ of them. For example  $f_{xyz} = \frac{\partial^3 f}{\partial x \partial y \partial z}$. There will be symmetries, too: whatever order we choose for the 3 differentiations, the result will be the same if the function is 3 times continuously differentiable. And so on.

% % https://en.wikipedia.org/wiki/Symmetry_of_second_derivatives
% https://de.wikipedia.org/wiki/Satz_von_Schwarz

%===================================================================================================
\subsection{The Gradient Vector}
For a function $f$ with $n$ input variables (or one single $n$-dimensional input vector) and a single output, we can compute $n$ different partial derivatives. We can collect these partial derivatives into another $n$-dimensional vector. This vector is called the \emph{gradient} of the function. It is usually taken to be a column vector. The gradient always points into the direction in which the function increases most steeply and the length of this gradient vector tells us, how steep that steepest increase is. Note that this is a direction in the input space, not in the combined input/output space. So, if the input is 2D, such that $z = f(x,y)$ gives a height over an $(x,y)$-plane of input values, the gradient of $f$ at a particular input location $(x_0,y_0)$ in the plane gives the direction in the $(x,y)$-plane in which we need to move the input to get the steepest increase in the height value $z$. But it's \emph{not} a direction in the 3D space of $(x,y,z)$.
%[Q: what is the direction in x,y,z space? is it just x,y taken from the gradient, augmented by a z-value for which we can take the length of the gradient? that seems plausible -> make some plots! the vector should be tangential to the surface, i think]

\medskip
There are different notations for the gradient. One of them is to write $\grad f$. You may also see it in non boldface, but I want to consistently use boldface for vectors and the gradient is a vector, so boldface is appropriate. Another notation for the gradient of $f$ is $\nabla f$, where the symbol $\nabla$ is the so called "nabla" operator (a nabla is an ancient greek harp-like instrument with a triangular shape), sometimes also called "del". The nabla or del operator is defined as a symbolic vector of partial derivative symbols, for example in 2D as $\nabla = (\partial / \partial x, \partial / \partial y)^T$, so when $\nabla$ is "applied" to a function $f$ as in $\nabla f$, this expression "evaluates to" $(\partial f / \partial x, \partial f / \partial y)^T$. I use quotes here because this "application" is to be understood in a purely formal and symbolic sense.

\medskip
The gradient helps us to compute the directional derivative: It's just the scalar product between the given (unit length) direction vector $\mathbf{v}$ and the gradient vector:
\begin{equation}
 \frac{\partial f}{\partial \mathbf{v}} = \mathbf{v} \cdot \grad f
\end{equation}
TODO: Figure out, if it's better (i.e. more consistent wrt generalizations) to write it as $\grad f \cdot \mathbf{v}$.
%i.e. with factors in reversed order? The order doesn't matter in the this case, but may for generalization to situations where the order matters, we should do it the other way around?

%===================================================================================================
\subsection{The Jacobian Matrix}
So far, we assumed that $f$ has only a single output, i.e. defines a scalar field. Now we will have a look at vector valued functions $\mathbf{f}: \mathbb{R}^n \rightarrow \mathbb{R}^m$ with $\mathbf{f(x)} = (f_1(\mathbf{x}), \ldots, f_m(\mathbf{x}))^T$ where $\mathbf{x} = (x_1,\ldots,x_n)^T$. So, our function has $n$ inputs and $m$ outputs. The $m \times n$ matrix
\begin{equation}
 \mathbf{J_f}(\mathbf{x}) = 
 \mathbf{f'}(\mathbf{x}) = 
 \begin{pmatrix}
  \frac{\partial f_1}{\partial x_1} (\mathbf{x}) & \hdots & \frac{\partial f_1}{\partial x_n} (\mathbf{x}) \\
  \vdots & \ddots & \vdots \\
  \frac{\partial f_m}{\partial x_1} (\mathbf{x}) & \hdots & \frac{\partial f_m}{\partial x_n} (\mathbf{x})
 \end{pmatrix}
\end{equation}	
is called the \emph{Jacobian matrix} of $\mathbf{f}$ at $\mathbf{x}$. It's a generalization of the derivative. We see that in this generalization, the derivative of a vector-valued function is a matrix-valued function. The $k$th row of the matrix is the transpose of the gradient of the $k$th component function $f_k$. In a more terse notation, you can also suppress the index $\mathbf{f}$ and the argument $\mathbf{x}$ and just write $\mathbf{J}$ instead of $\mathbf{J_f}(\mathbf{x})$, if it's clear from the context about which $\mathbf{f}$ we are talking and that $\mathbf{f}$ is a function of $\mathbf{x}$. Just like 1D derivatives do, it defines a linear approximation to $\mathbf{f}$ at a given $\mathbf{x}$ in the sense that for a small vector  $\mathbf{h}$, we have:
\begin{equation}
\label{Eq:JacobianApproximation}
 \mathbf{f}(\mathbf{x + h}) \approx 
 \mathbf{f}(\mathbf{x}) + \mathbf{J  h} \qquad \text{in the sense of:}  \qquad
 \lim_{\mathbf{h \rightarrow 0}} 
 \frac{ | \mathbf{f(x+h) - (f(x) + J h)}| }{ |\mathbf{h}| } = 0 
% \frac{\lVert \mathbf{f(x+h) - (f(x) + J h)} \rVert}
%       {\lVert \mathbf{h} \rVert} = 0
\end{equation}	
when $\mathbf{J} = \mathbf{J_f}(\mathbf{x})$ is the Jacobian of  $\mathbf{f}$ at $\mathbf{x}$. The limit can be understood in the following sense: the difference between $\mathbf{f(x+h)}$ and its approximation $\mathbf{f(x) + J h}$ approaches the zero vector faster than $\mathbf{h}$ itself when $\mathbf{h}$ approaches $\mathbf{0}$. Or stated in another way: when the denominator approaches zero linearly, the numerator will approach zero superlinearly, i.e. faster than linear (namely quadratically, I think. [VERIFY!]). Having the individual gradients of the component functions in the rows rather than in the columns ensures that we can formulate the linear approximation by left multiplication of the matrix with some small delta vector. The Jacobian matrix of a scalar valued function is actually the transpose of its gradient vector and I'm not sure, why the definition of the gradient has been chosen to be a column vector rather than a row vector. Maybe because in pure vector algebra (i.e. before matrices enter the stage), there's no notion of "row-" and "column" vectors. There are just vectors. We should perhaps more properly have said row- and column \emph{matrices} anyway. The determinant of the Jacobian matrix will play an important role in the change of variables formula for multiple integrals which we will see later. The approximation property of the Jacobian stated in \ref{Eq:JacobianApproximation} can also be seen as the definition of the derivative of $\mathbf{f}$ in the following way: we say that $\mathbf{f}$ is differentiable at $\mathbf{x}$, iff a matrix $\mathbf{J}$ exists, such that this equation holds true for any (small) direction vector $\mathbf{h}$. In this case, we call the matrix $\mathbf{J}$ the derivative of $\mathbf{f}$ at $\mathbf{x}$.

% Weitz, DiffGeo, pg 114

% maybe put the babbling about row- and column-vectors into a footnote

% https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant
% Bärwolff, pg 392

%When we change from one coordinate system to another by a change of variables, then we will have to compensate
%If we multiply the matrix
%also mention the importance of its determinant in case of equal input and output dimensionalities - it's a generalized area/volume/hypervolume scale factor

%===================================================================================================
\subsection{The Hessian Matrix}
The gradient vector and the Jacobian matrix are collections of first partial derivatives of scalar- and vector valued functions respectively. The \emph{Hessian matrix} is a collection of second partial derivatives of a scalar valued function $f: \mathbb{R}^n \rightarrow \mathbb{R}$ with $f = f(\mathbf{x})$ and $\mathbf{x} = (x_1, \ldots, x_n)$. It is defined as:
\begin{equation}
 \mathbf{H}_f(\mathbf{x}) = 
	\begin{pmatrix}
		  \frac{\partial^2 f}{\partial x_1 \partial x_1} (\mathbf{x}) 
		& \hdots 
		& \frac{\partial^2 f}{\partial x_1 \partial x_n} (\mathbf{x}) 
		\\
		\vdots & \ddots & \vdots 
		\\
	      \frac{\partial^2 f}{\partial x_n \partial x_1} (\mathbf{x}) 
		& \hdots 
		& \frac{\partial^2 f}{\partial x_n \partial x_n} (\mathbf{x})
	\end{pmatrix}
\end{equation}	
Due to the symmetry of the partial derivatives when $f$ is twice continuously differentiable, the Hessian matrix is a symmetric matrix in this (typical) case. The Hessian of a function $f$ can also be formed as the Jacobian of its gradient. As usual, if things are clear from the context, we may suppress the index and argument and just write $\mathbf{H}$ for the Hessian. The Hessian can be used to formulate a quadratic (i.e. second order) approximation of a function $f$ as follows: Let $\mathbf{g}$ be the gradient and $\mathbf{H}$ be the Hessian of $f$ evaluated at $\mathbf{x}$. Then:
\begin{equation}
\label{Eq:TaylorMultivariate2ndOrder}
 f(\mathbf{x + h}) \approx f(\mathbf{x}) + \mathbf{g^T h} + \frac{1}{2} \mathbf{h^T H h}
\end{equation}	
for some small deviation vector $\mathbf{h}$. If the input to $f$ is 2D, then this quadratic approximation function will be the locally (at $\mathbf{x}$) best fitting paraboloid. Such second order approximations of a multivariate scalar function play an important role in numerical optimization algorithms, i.e. algorithms that try to locate minima or maxima of such functions. The simpler of such algorithms use only the gradient, the more advanced ones may also use (an approximation of) the Hessian.

% https://en.wikipedia.org/wiki/Hessian_matrix#Generalization_to_the_complex_case

%===================================================================================================
\subsection{Multivariable Taylor Series} 
The approximation given in equation (\ref{Eq:TaylorMultivariate2ndOrder}) can be interpreted as a quadratic (i.e. 2nd order) approximation to our function $f$. To see where we are going, let's rewrite it in the following form:
\begin{equation}
 f(\mathbf{x + h}) \approx
 f(\mathbf{x}) + 
 \frac{1}{1!} \sum_{i=1}^{n} \frac{\partial f}{\partial x_i} h_i + 
 \frac{1}{2!} \sum_{i=1}^{n} \sum_{j=1}^{n}  \frac{\partial f^2}{\partial x_i x_j} h_i h_j
\end{equation}
Writing it like this may help us to recognize a pattern that we are familiar with from the one dimensional Taylor series formula. A general multivariate Taylor polynomial would look like this:
\begin{equation}
 f(\mathbf{x + h}) \approx
 f(\mathbf{x}) + 
 \frac{1}{1!} \sum_{i=1}^{n} \frac{\partial f}{\partial x_i} h_i + 
 \frac{1}{2!} \sum_{i=1}^{n} \sum_{j=1}^{n}  \frac{\partial f^2}{\partial x_i x_j} h_i h_j +
 \frac{1}{3!} \sum_{i=1}^{n} \sum_{j=1}^{n}  \sum_{k=1}^{n} 
              \frac{\partial f^3}{\partial x_i x_j x_k} h_i h_j h_k + 
 \frac{1}{4!}  \ldots              
\end{equation}
This notation becomes very verbose rather quickly which is why more compact notations have been invented for writing down formulas of that kind. First of all, one can use the convention to use a single summation sign also for multiple sums:
\begin{equation}
 f(\mathbf{x + h}) \approx
 f(\mathbf{x}) + 
 \frac{1}{1!} \sum_{i=1}^{n}     \frac{\partial f}{\partial x_i} h_i + 
 \frac{1}{2!} \sum_{i,j=1}^{n}   \frac{\partial f^2}{\partial x_i x_j} h_i h_j +
 \frac{1}{3!} \sum_{i,j,k=1}^{n} \frac{\partial f^3}{\partial x_i x_j x_k} h_i h_j h_k + 
 \frac{1}{4!}  \ldots              
\end{equation}

%There are more fancy way of writing it down - some use tensor notation with Einstein summation convention, some use (powers of) the nabla operator, some use custom definitions of the multiple sums that occur above, some use multi-indices, etc. These ways of writing it down may appear daunting when one isn't familiar with the particular notation used. It's important to realize that they all just boil down to the formula above. TODO: give the formula in these other notations and explain how they translate back into the formula above.

%ToDo: explain how to write it tensor notation with Einstein summation convention. There are various way to write it down - some of them quite fancy using powers of the nabla-operator, etc.

% https://sites.millersville.edu/bikenaga/calculus3/taylor-series-several-variables/taylor-series-several-variables.pdf

% https://math.stackexchange.com/questions/1586997/taylor-series-for-multivariable-functions

% https://en.wikipedia.org/wiki/Fr%C3%A9chet_derivative#Higher_derivatives

%Multivariable Taylor Series Derivation
%https://www.youtube.com/watch?v=zxafRk45vtE

% https://math.libretexts.org/Bookshelves/Calculus/Supplemental_Modules_(Calculus)/Multivariable_Calculus/3%3A_Topics_in_Partial_Derivatives/Taylor__Polynomials_of_Functions_of_Two_Variables

% https://en.wikipedia.org/wiki/Taylor%27s_theorem#Taylor's_theorem_for_multivariate_functions

% https://en.wikipedia.org/wiki/Taylor_series#Taylor_series_in_several_variables

% https://math.stackexchange.com/questions/4020865/how-to-expand-this-tensorial-taylor-expansion-to-the-nth-term

% 

%===================================================================================================
\subsection{Multi-index Notation}
The notation is still quite verbose and the usage of "$\ldots$" requires the reader to recognize and extrapolate the pattern. There are more advanced ways of writing down the multivariable Taylor expansion but they require the introduction of a new concept: the \emph{multi-index}. A multi-index is, so to speak, a vector of indices. ...TBC... TODO: explain the concept, give some important formulas and definitions for multi-indices and then re-state the Taylor-expansion in multi-index notation.


%ToDo: introduce multi-index notation and give Taylor formula in that notation

% https://en.wikipedia.org/wiki/Multi-index_notation
% https://de.wikipedia.org/wiki/Multiindex

% Karpfinger, pg 515
% Arens, pg 888


% Tensor notation?
% https://en.wikipedia.org/wiki/Four-gradient
% https://en.wikipedia.org/wiki/Ricci_calculus#Differentiation
% https://en.wikipedia.org/wiki/Tensor_calculus#Gradient_vector

%===================================================================================================
\subsection{More Notation Terminology} 
% Maybe move this section to somewhere else, i.e. below the "Composition" section



\subsubsection{Differentials} Imagine we have a function $f(x,y)$ in two variables, for example $f(x,y) = x^y$. We can compute the partial derivatives of $f$ with respect to $x$ and $y$ as $f_x = \partial f / \partial x = y x^{y-1}$ and $f_y = \partial f / \partial y = x^y \ln x$. Consider a particular point $(x_0, y_0) = (2,3)$. We can evaluate $f$ and its partial derivatives $f_x, f_y$ at that point to get $f = 2^3 = 8, f_x = 3 \cdot 2^2 = 12, f_y = 2^3 \cdot \ln 2 \approx 5.545178$. With these three values, we can approximate our function $f$ near the point $(3,2)$ linearly as $f \approx 8 + 12 dx + 5.545178 dy$. For example, at $(2.02,3.01)$, we get $f \approx 8 + 12 \cdot 0.02 + 5.545178 \cdot 0.01 \approx 8.2955$ which is an approximation to the true value of around $8.3006$. What we did here was to define a linear function in two variables $dx,dy$ which we envision as small offsets from our given point $(x_0,y_0) = (2,3)$. These were given as $(dx,dy) = (0.02,0.01)$ in our example. These two offsets in the input variables lead to a resulting offset $df$ in the output variable $df = 12 \cdot 0.02 + 5.545178 \cdot 0.01$. This linear function in the two offset variables $dx, dy$ is called the \emph{total differential} of the function $f$ at the point $(x_0, y_0)$.

...TBC...VERIFY, explain the terminology, explain how it is used, explain relation to total derivative, total differential

% 0.69315 
% 0.6931 4718  05599453094172321214581765680755001343602552541206800094...
% 5.545177 4444795624753378569716654125446040010748820420329654400759...
% % 5.545178 7 4444795624753378569716654125446040010748820420329654400759...

% Bärwolff, pg 402


%The partial differential $f$ with respect to $x$ is a linear function in a variable $dx$

%At some given point $(x_0, y_0)$

% https://en.wikipedia.org/wiki/Differential_of_a_function#Differentials_in_several_variables
% https://en.wikipedia.org/wiki/Differential_of_a_function
% https://de.wikipedia.org/wiki/Differential_(Mathematik)


% https://en.wikipedia.org/wiki/Differential_(mathematics)


% https://en.wikipedia.org/wiki/Total_derivative

% This is also a useful view:
% https://en.wikipedia.org/wiki/Differential_of_a_function#General_formulation

% todo: explain how it can be used in a second order (quadratic) approximation of f

% Bärwolff, pg 393
%-https://en.wikipedia.org/wiki/Hessian_matrix#Vector-valued_functions

% Exakte & Inexakte Differentiale - Einfache Erklärung, Beispiele, Thermodynamik (Physik & Chemie)
% https://www.youtube.com/watch?v=MeDIv6HOkeE
%
% ...ist Teil der Playlist:
% https://www.youtube.com/watch?v=IcYB7cWLurI&list=PLdTL21qNWp2YKtHlyM7u_AOaQaBcvqdrO&index=6

\subsubsection{The Total Derivative}

% https://en.wikipedia.org/wiki/Total_derivative

% https://www.youtube.com/watch?v=QFHSHhpbo00
% They Use ∂ Differently in Math and Physics. Which is Better?


%\subsubsection{The Total Derivative}

\subsubsection{Derivatives With Respect to Vectors}  [very preliminary]
Let $f = f(\mathbf{x})$ be a scalar valued function that has a vector $\mathbf{x}$ as its argument. We want to make sense of an expression like $\frac{d f}{d \mathbf{x}}$. Recall that:
\begin{equation}
f(\mathbf{x + h}) \approx 
f(\mathbf{x}) + \sum_{i=1}^{n} \frac{\partial f}{\partial x_i} h_i =
f(\mathbf{x}) + \mathbf{g}^T \mathbf{h}
\end{equation}
where $\mathbf{x} = (x_1,\ldots,x_n)$, $\mathbf{h} = (h_1,\ldots,h_n)$ and $\mathbf{g} = (\frac{\partial f}{\partial x_1},\ldots,\frac{\partial f}{\partial x_n})|_{\mathbf{x}}$, i.e. the gradient of $f$ evaluated at $\mathbf{x}$. ...TBC...


% https://physics.stackexchange.com/questions/88935/derivative-with-respect-to-a-vector-is-a-gradient
% https://onlinelibrary.wiley.com/doi/pdf/10.1002/0471705195.app3
% https://en.wikipedia.org/wiki/Matrix_calculus#Derivatives_with_vectors

\subsubsection{Derivatives With Respect to Matrices}  [very preliminary]
Let $f = f(\mathbf{X})$ be a scalar valued function that has a matrix $\mathbf{X}$ as its argument. We want to make sense of an expression like $\frac{d f}{d \mathbf{X}}$. In analogy with the with the derivative with respect to a vector, we can write:
\begin{equation}
f(\mathbf{X + H}) \approx 
f(\mathbf{X}) + \sum_{i=1}^{n} \sum_{j=1}^{n} \frac{\partial f}{\partial x_{ij}} h_{ij} =
f(\mathbf{X}) + \vectorize(\mathbf{D})^T \vectorize(\mathbf{H}) =
f(\mathbf{X}) + \tr(\mathbf{D}^T \mathbf{H})
\end{equation}
where $\mathbf{D}$ is the matrix with entries $d_{ij} = \frac{\partial f}{\partial x_{ij}}$. ...TBC...

%Differentiating functions of vectors and matrices
%https://www.youtube.com/watch?v=k5OFFevtGDg
%-at 30:30:




%===================================================================================================
\subsection{Composition of Multivariable Functions}

\subsubsection{The Multivariable Chain Rule}

\subsubsection{Ambiguity of the Notation}

% https://www.youtube.com/watch?v=mICbKwwHziI
% Ambiguity With Partial ∂ Notation, and How to Resolve It

% https://www.youtube.com/watch?v=QFHSHhpbo00
% They Use ∂ Differently in Math and Physics. Which is Better?







% ...convective derivative, material derivative, explicit vs complete partial derivative, ...
% https://en.wikipedia.org/wiki/Material_derivative




%https://en.wikipedia.org/wiki/Generalizations_of_the_derivative



\begin{comment}

\subsection{TODO Notes}
It seems to be generally true that for any function $f(x)$ we have
\begin{equation}
 \frac{d}{d x} f(x) = \frac{d}{d h} f(x + h) \bigg\rvert_{h=0}
\end{equation}
which seems to generalize to the directional derivative of multivariate functions as:
\begin{equation}
 \frac{\partial f(\mathbf{x}) }{\partial \mathbf{v}} 
 = \lim_{h \rightarrow 0} \frac{f(\mathbf{x} + h \mathbf{v} ) - f(\mathbf{x})}{h}
 = \frac{d}{d h} f(\mathbf{x} + h \mathbf{v}) \bigg\rvert_{h=0}
\end{equation}
which could be used to actually evaluate the directional derivative without using the formula with the scalar product with the gradient. ...verify this! This seems to be the important observation in evaluating the Gateaux derivative by analogy later...



-maybe divergence, but maybe defer that to vector calculus
https://en.wikipedia.org/wiki/Del


For the "Composition" section:

- Explain compostion of multivariable functions in terms of a "functional dependency graph" FDG.
  That's a term that I made up myself. It means something like the directed graphs in this video:
  https://www.youtube.com/watch?v=mICbKwwHziI

- In case of univariate functions, this graph is trivial. It's juts a linear chain. For example
  z -> y -> x means: z depends on y and y depends on x. In the multivariable setting, the graph 
  can be arbitrarily complicated.
  
- Leaf nodes, i.e. nodes that have only incoming arrows, are called independent variables.
  
- For a function to be called explicit, the FDG must be acyclic (I guess). If it has at least one
  cycle, we are deling with an implicitly defined function.

- What about functions like f(x,x') where x = x(t) and x' = dx/dt? Does x' count as dependent on x
  or only dependent on t? I guess, the latter - because if we really write down x'(t), then it has
  indeed only t appearing as independent variable.
  
- Give some examples that are not too contrived, i.e. have some practical interpretation

- Suggest to draw such a "functional dependency graph" for the given problem to clarify what is
  going on

Example 1:
z = z(x,y) = sqrt(x^2 + y^2)
x = x(t)   = sin(2t)
y = y(t)   = sin(3t)
x,y is the parametric description of a Lissajous figure. z is the distance of the point from the
origin. Maybe let t = f(s) where s is an arc-length parameter, i.e. a natural parametrization of the curve. That introduces another r level of nesting. Start with just z = f(x,y) and its partial derivatives. Then let x,y themselves be given by the parametric eqaution with parameter t. The let t be a function of s. 

Example 2:
Then introduce an explicit dependency of z on t. Maybe z = z(t,x,y) = sqrt(x^2 + y^2 - t^2). This
example has some special relativity vibes. On that function, we can explain concepts like partial and total derivative of z with respect to t. The partial derivtaive would treat x and y as constants even though they are functions of t (I think)

Example 3:
Use something like spherical coordinates for
x = x(u,v), y = y(u,v), z = z(u,v) where u,v are angles. Define a vector field on the sphere - maybe representing wind velocity with northward and eastward components as function of latitude u and longitude v. Maybe introduce time as additional parameter - the wind may change. Maybe exaplain covariant derivativesas preview





\end{comment} 