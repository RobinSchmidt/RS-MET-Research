\section{Differentiation}

%===================================================================================================
\subsection{Partial Derivatives}
Let's assume we have a bivariate function $f$, i.e. a function with two inputs $x,y$, that produces one output $z$: $z = f(x,y)$. We can visualize this as a landscape above an $(x,y)$-plane where the height is given by the function value. We can take derivatives of $f$ with respect to $x$ and with respect to $y$. In the former case, $y$ is just treated as a constant and in the latter case $x$ is treated as a constant. These two derivatives of $f$ are called \emph{partial derivatives} and we denote them as $\frac{\partial f}{\partial x}$ and $\frac{\partial f}{\partial y}$, where the curly d symbol $\partial$ is a special math symbol that we read as "partial" - it's not a greek delta. The formal definition is:
\begin{equation}
 \frac{\partial f(x,y)}{\partial x} = \lim_{h \rightarrow 0} \frac{f(x+h,y) - f(x,y)}{h}, \qquad
 \frac{\partial f(x,y)}{\partial y} = \lim_{h \rightarrow 0} \frac{f(x,y+h) - f(x,y)}{h}
\end{equation}
In the text above, we wrote $\frac{\partial f}{\partial x}$ whereas in the definition, we wrote  $\frac{\partial f(x,y)}{\partial x}$. The former notation with suppressed input arguments $x,y$ is just an abbreviation of the more verbose latter notation. This abbreviation makes sense when it is understood from the context that $f$ is a function of $x,y$. Another, even shorter, notation for the partial derivatives is $f_x, f_y$. This notation is used a lot in the context of partial differential equations. You may also see things like $\partial_x f$ and $\partial_y f$. It's yet another notation for the same thing. This one used a lot in tensor calculus. For a general multivariate function with scalar output $f(\mathbf{x})$ where $\mathbf{x} = (x_1,x_2,\ldots,x_n)^T$ where $n$ is the number of inputs, we can compute partial derivatives with respect to each input dimension. We denote these as $\frac{\partial f}{\partial x_i}$ where $i = 1,\ldots,n$. We could also write $f_{x_i}$ but we will rarely use this notation because an index with an index is typographically less than ideal. The formal definition of $\frac{\partial f}{\partial x_i}$ is given by:
\begin{equation}
 \frac{\partial f(\mathbf{x}) }{\partial x_i} 
 = \lim_{h \rightarrow 0} \frac{f(\mathbf{x} + h \mathbf{e}_i ) - f(\mathbf{x})}{h}
\end{equation}
where $\mathbf{e}_i$ is the unit vector in the $i$-th coordinate direction, i.e. it has a one at position $i$ and zeros everywhere else. As said: the computation of such partial derivatives is purely mechanic and we don't need to refer to our definitions for that. Instead, we just treat the function as if it would depend only on the variable with respect to which we differentiate and treat all other variables as constants.

%===================================================================================================
\subsection{Directional Derivatives}
Now let's assume we are given an arbitrary vector $\mathbf{v}$ of unit length. We define the \emph{directional derivative} of $f$ into the direction of  $\mathbf{v}$ as:
\begin{equation}
\label{Eq:DirectionalDerivative}
 \frac{\partial f(\mathbf{x}) }{\partial \mathbf{v}} 
 = \lim_{h \rightarrow 0} \frac{f(\mathbf{x} + h \mathbf{v} ) - f(\mathbf{x})}{h}
 = \frac{d}{d h} f(\mathbf{x} + h \mathbf{v}) \bigg\rvert_{h=0}
\end{equation}
where the RHS is a generalization of \ref{Eq:DerivativeViaH} which tells us how we could evaluate the limit (but we'll soon learn a simpler way to evaluate it). Note that the directional derivative into any of the coordinate directions $\mathbf{e}_i$ just reduces to the partial derivative with respect to coordinate $i$, so partial derivatives can also be seen as directional derivatives into very specific directions: namely, into the directions of our coordinate axes. [TODO: verify that the RHS is actually correct, give notations for the directional derivative] 

% The formula is not from a book - i found it myself by analogy to the evaluation formula for the Gateaux derivative in Baerwolff, pg. 792]

% Notations:
% $D_{\mathbf{v}} f(\mathbf{x})$, $\nabla_{\mathbf{v}} f(\mathbf{x})$

%===================================================================================================
\subsection{Higher Order Partial Derivatives}
Just like we could define the second derivative of a univariate function as the derivative of the derivative, we can define second order partial derivatives of a multivariate scalar function. Due to the fact that we now have $n$ input variables, we can form $n^2$ different second partial derivatives. If we first find the derivative of $f$ with respect to some $x_i$ and then take the result and find its derivative with respect to $x_j$, we obtain such a second order partial derivative. We write this as $\frac{\partial^2 f}{\partial x_i \partial x_j}$. If the function $f$ is twice continuously differentiable, then, according to \emph{Schwarz's theorem}\footnote{aka Clairaut's theorem or Young's theorem}, we will actually have the following symmetry:
\begin{equation}
	\frac{\partial^2 f}{\partial x_i \partial x_j} 
	=
	\frac{\partial^2 f}{\partial x_j \partial x_i} 
\end{equation}
which means the order of the differentiations makes no difference. We can first take the derivative with respect to $x_i$ and then with respect to $x_j$ or the other way around. The end result will be the same. We may also use the abbreviated notation $f_{xy}$ for $\frac{\partial^2 f}{\partial x \partial y}$ for a function that depends on $x$ and $y$, i.e. a low-dimensional function for which we assign different letters to the different input variables instead of using index notation. Note that the notation $f_{xy}$ does not imply that $f$ is a bivariate function that depends \emph{only} on the two input variables $x,y$. We could also find $f_{xy}$ of a trivariate function $f = f(x,y,z)$, for example. If we differentiate twice with respect to the same input variable, say $x$, we write this as $f_{xx}$.

\medskip
In the same way, we can find third order partial derivatives and there will be $n^3$ of them. For example  $f_{xyz} = \frac{\partial^3 f}{\partial x \partial y \partial z}$. There will be symmetries, too: whatever order we choose for the 3 differentiations, the result will be the same if the function is 3 times continuously differentiable. And so on. The notation with multiple subscripts for partial derivatives may be more or less reasonably used for derivatives up to 4th order, which is usually enough for practical work with partial differential equations (which is the field where this notation is predominantly used).



% % https://en.wikipedia.org/wiki/Symmetry_of_second_derivatives
% https://de.wikipedia.org/wiki/Satz_von_Schwarz

%===================================================================================================
\subsection{The Gradient Vector}
For a function $f$ with $n$ input variables (or one single $n$-dimensional input vector) and a single output, we can compute $n$ different partial derivatives. We can collect these partial derivatives into another $n$-dimensional vector. This vector is called the \emph{gradient} of the function. It is usually taken to be a column vector. The gradient always points into the direction in which the function increases most steeply and the length of this gradient vector tells us, how steep that steepest increase is. Note that this is a direction in the input space, not in the combined input/output space. So, if the input is 2D, such that $z = f(x,y)$ gives a height over an $xy$-plane of input values, the gradient of $f$ at a particular input location $(x_0,y_0)$ in the plane gives the direction in the $xy$-plane in which we need to move the input to get the steepest increase in the height value $z$. But it's \emph{not} the uphill direction in the 3D $xyz$-space. This is a common misconception. They are closely related, though. If we take the uphill direction of 3D space and then project it down to the 2D $xy$-plane, \emph{then} we obtain the gradient (or at least a vector that points into the same direction as the gradient - I'm not quite sure about the length. Figure out!)

%It's just the projection of the uphill direction onto the 2D $xy$-plane. [VERIFY - Does it have the right length?]
%[Q: what is the direction in x,y,z space? is it just x,y taken from the gradient, augmented by a z-value for which we can take the length of the gradient? that seems plausible -> make some plots! the vector should be tangential to the surface, i think]

\medskip
There are different notations for the gradient. One of them is to write $\grad f$. You may also see it in non boldface, but I want to consistently use boldface for vectors and the gradient is a vector, so boldface is appropriate. Another notation for the gradient of $f$ is $\nabla f$, where the symbol $\nabla$ is the so called "nabla" operator (a nabla is an ancient greek harp-like instrument with a triangular shape), sometimes also called "del". The nabla or del operator is defined as a symbolic vector of partial derivative symbols, for example in 2D as $\nabla = (\partial / \partial x, \partial / \partial y)^T$, so when $\nabla$ is "applied" to a function $f$ as in $\nabla f$, this expression "evaluates to" $(\partial f / \partial x, \partial f / \partial y)^T$. I use quotes here because this "application" is to be understood in a purely formal and symbolic sense.

\medskip
The gradient helps us to compute the directional derivative: It's just the scalar product between the given (unit length) direction vector $\mathbf{v}$ and the gradient vector:
\begin{equation}
 \frac{\partial f}{\partial \mathbf{v}} = \mathbf{v} \cdot \grad f
\end{equation}
It is this formula that we usually use to actually evaluate a directional derivative in practice. The definition in (\ref{Eq:DirectionalDerivative}) is not really meant as an evaluation algorithm. TODO: Figure out, if it's better (i.e. more consistent wrt generalizations) to write it as $\grad f \cdot \mathbf{v}$.
%i.e. with factors in reversed order? The order doesn't matter in the this case, but may for generalization to situations where the order matters, we should do it the other way around?

%===================================================================================================
\subsection{The Jacobian Matrix}
So far, we assumed that $f$ has only a single output, i.e. defines a scalar field. Now we will have a look at vector valued functions $\mathbf{f}: \mathbb{R}^n \rightarrow \mathbb{R}^m$ with $\mathbf{f(x)} = (f_1(\mathbf{x}), \ldots, f_m(\mathbf{x}))^T$ where $\mathbf{x} = (x_1,\ldots,x_n)^T$. So, our function has $n$ inputs and $m$ outputs. The $m \times n$ matrix
\begin{equation}
 \mathbf{J_f}(\mathbf{x}) = 
 \mathbf{f'}(\mathbf{x}) = 
 \begin{pmatrix}
  \frac{\partial f_1}{\partial x_1} (\mathbf{x}) & \hdots & \frac{\partial f_1}{\partial x_n} (\mathbf{x}) \\
  \vdots & \ddots & \vdots \\
  \frac{\partial f_m}{\partial x_1} (\mathbf{x}) & \hdots & \frac{\partial f_m}{\partial x_n} (\mathbf{x})
 \end{pmatrix}
\end{equation}	
is called the \emph{Jacobian matrix} of $\mathbf{f}$ at $\mathbf{x}$. It's a generalization of the derivative. We see that in this generalization, the derivative of a vector-valued function is a matrix-valued function. The $k$th row of the matrix is the transpose of the gradient of the $k$th component function $f_k$. In a more terse notation, you can also suppress the index $\mathbf{f}$ and the argument $\mathbf{x}$ and just write $\mathbf{J}$ instead of $\mathbf{J_f}(\mathbf{x})$, if it's clear from the context about which $\mathbf{f}$ we are talking and that $\mathbf{f}$ is a function of $\mathbf{x}$. Just like 1D derivatives do, it defines a linear approximation to $\mathbf{f}$ at a given $\mathbf{x}$ in the sense that for a small vector  $\mathbf{h}$, we have:
\begin{equation}
\label{Eq:JacobianApproximation}
 \mathbf{f}(\mathbf{x + h}) \approx 
 \mathbf{f}(\mathbf{x}) + \mathbf{J  h} \qquad \text{in the sense of:}  \qquad
 \lim_{\mathbf{h \rightarrow 0}} 
 \frac{ | \mathbf{f(x+h) - (f(x) + J h)}| }{ |\mathbf{h}| } = 0 
% \frac{\lVert \mathbf{f(x+h) - (f(x) + J h)} \rVert}
%       {\lVert \mathbf{h} \rVert} = 0
\end{equation}	
when $\mathbf{J} = \mathbf{J_f}(\mathbf{x})$ is the Jacobian of  $\mathbf{f}$ at $\mathbf{x}$. The limit can be understood in the following sense: the difference between $\mathbf{f(x+h)}$ and its approximation $\mathbf{f(x) + J h}$ approaches the zero vector faster than $\mathbf{h}$ itself when $\mathbf{h}$ approaches $\mathbf{0}$. Or stated in another way: when the denominator approaches zero linearly, the numerator will approach zero superlinearly, i.e. faster than linear (namely quadratically, I think. [VERIFY!]). Having the individual gradients of the component functions in the rows rather than in the columns ensures that we can formulate the linear approximation by left multiplication of the matrix with some small delta vector. The Jacobian matrix of a scalar valued function is actually the transpose of its gradient vector and I'm not sure, why the definition of the gradient has been chosen to be a column vector rather than a row vector. Maybe because in pure vector algebra (i.e. before matrices enter the stage), there's no notion of "row-" and "column" vectors. There are just vectors. We should perhaps more properly have said row- and column \emph{matrices} anyway. The determinant of the Jacobian matrix will play an important role in the change of variables formula for multiple integrals which we will see later. The approximation property of the Jacobian stated in (\ref{Eq:JacobianApproximation}) can also be seen as the definition of the derivative of $\mathbf{f}$ in the following way: we say that $\mathbf{f}$ is differentiable at $\mathbf{x}$, iff a matrix $\mathbf{J}$ exists, such that this equation holds true for any (small) direction vector $\mathbf{h}$. In this case, we call the matrix $\mathbf{J}$ the derivative of $\mathbf{f}$ at $\mathbf{x}$.

% Weitz, DiffGeo, pg 114

% maybe put the babbling about row- and column-vectors into a footnote

% https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant
% Bärwolff, pg 392

%When we change from one coordinate system to another by a change of variables, then we will have to compensate
%If we multiply the matrix
%also mention the importance of its determinant in case of equal input and output dimensionalities - it's a generalized area/volume/hypervolume scale factor


% Your Understanding of Jacobians Might Be Wrong
% https://www.youtube.com/watch?v=zx-eJ-K-z6g

%===================================================================================================
\subsection{The Hessian Matrix}
The gradient vector and the Jacobian matrix are collections of first partial derivatives of scalar- and vector valued functions respectively. The \emph{Hessian matrix} is a collection of second partial derivatives of a scalar valued function $f: \mathbb{R}^n \rightarrow \mathbb{R}$ with $f = f(\mathbf{x})$ and $\mathbf{x} = (x_1, \ldots, x_n)$. It is defined as:
\begin{equation}
 \mathbf{H}_f(\mathbf{x}) = 
	\begin{pmatrix}
		  \frac{\partial^2 f}{\partial x_1 \partial x_1} (\mathbf{x}) 
		& \hdots 
		& \frac{\partial^2 f}{\partial x_1 \partial x_n} (\mathbf{x}) 
		\\
		\vdots & \ddots & \vdots 
		\\
	      \frac{\partial^2 f}{\partial x_n \partial x_1} (\mathbf{x}) 
		& \hdots 
		& \frac{\partial^2 f}{\partial x_n \partial x_n} (\mathbf{x})
	\end{pmatrix}
\end{equation}	
Due to the symmetry of the partial derivatives when $f$ is twice continuously differentiable, the Hessian matrix is a symmetric matrix in this (typical) case. The Hessian of a function $f$ can also be formed as the Jacobian of its gradient. As usual, if things are clear from the context, we may suppress the index and argument and just write $\mathbf{H}$ for the Hessian. The Hessian can be used to formulate a quadratic (i.e. second order) approximation of a function $f$ as follows: Let $\mathbf{g}$ be the gradient and $\mathbf{H}$ be the Hessian of $f$ evaluated at $\mathbf{x}$. Then:
\begin{equation}
\label{Eq:TaylorMultivariate2ndOrder}
 f(\mathbf{x + h}) \approx f(\mathbf{x}) + \mathbf{g^T h} + \frac{1}{2} \mathbf{h^T H h}
\end{equation}	
for some small deviation vector $\mathbf{h}$. If the input to $f$ is 2D, then this quadratic approximation function will be the locally (at $\mathbf{x}$) best fitting paraboloid. Such second order approximations of a multivariate scalar function play an important role in numerical optimization algorithms, i.e. algorithms that try to locate minima or maxima of such functions. The simpler of such algorithms use only the gradient, the more advanced ones may also use (an approximation of) the Hessian.

% https://en.wikipedia.org/wiki/Hessian_matrix#Generalization_to_the_complex_case

%===================================================================================================
\subsection{Multivariable Taylor Series} 
The approximation given in equation (\ref{Eq:TaylorMultivariate2ndOrder}) can be interpreted as a quadratic (i.e. 2nd order) approximation to our function $f$. To see where we are going, let's rewrite it in the following form:
\begin{equation}
 f(\mathbf{x + h}) \approx
 f(\mathbf{x}) + 
 \frac{1}{1!} \sum_{i=1}^{n} \frac{\partial f}{\partial x_i} h_i + 
 \frac{1}{2!} \sum_{i=1}^{n} \sum_{j=1}^{n}  \frac{\partial f^2}{\partial x_i x_j} h_i h_j
\end{equation}
Writing it like this may help us to recognize a pattern that we are familiar with from the one dimensional Taylor series formula. A general multivariate Taylor polynomial would look like this:
\begin{equation}
\label{Eq:TaylorSeriesMultiDim}
 f(\mathbf{x + h}) \approx
 f(\mathbf{x}) + 
 \frac{1}{1!} \sum_{i=1}^{n} 
              \frac{\partial f} {\partial x_i} h_i + 
 \frac{1}{2!} \sum_{i=1}^{n} \sum_{j=1}^{n}  
              \frac{\partial f^2}{\partial x_i x_j} h_i h_j +
 \frac{1}{3!} \sum_{i=1}^{n} \sum_{j=1}^{n}  \sum_{k=1}^{n} 
              \frac{\partial f^3}{\partial x_i x_j x_k} h_i h_j h_k + 
 \frac{1}{4!}  \ldots              
\end{equation}
This notation requires the reader to extrapolate the pattern and is already quite verbose. One could use the convention to use single summation signs for the multiple sums to make it a bit terser, but still.

%https://en.wikipedia.org/wiki/Taylor_series#Taylor_series_in_several_variables

\subsubsection{Other Notations}

\paragraph{Operator Notation}
There are a couple of other ways of writing down the multivariate Taylor expansion that you may encounter. Let's define:
\begin{equation}
 \mathbf{h} \cdot \nabla    = \sum_{i=1}^{n} h_i \frac{\partial}{\partial x_i}, \quad
(\mathbf{h} \cdot \nabla)^2 = \sum_{i,j=1}^{n} h_i h_j \frac{\partial^2}{\partial x_i x_j}, \quad
(\mathbf{h} \cdot \nabla)^k 
= \sum_{i_1,\ldots,i_k=1}^{n} 
  h_{i_1} \ldots h_{i_k} \frac{\partial^k}{\partial x_{i_1} \ldots \partial x_{i_k}}
\end{equation}
as abbreviations for the expressions $\frac{\partial f}{\partial x_i} h_i$, $\frac{\partial f^2}{\partial x_i x_j} h_i h_j$, etc. in equation (\ref{Eq:TaylorSeriesMultiDim}). The object $\mathbf{h} \cdot \nabla$ is a differential operator. An operator takes a function $f$ as input and returns another function as output. When we evaluate the resulting function at a particular input $\mathbf{x}$, we'll get out an actual number. We write this as:
\begin{equation}
(\mathbf{h} \cdot \nabla)^k f(\mathbf{x})
= \sum_{i_1,\ldots,i_k=1}^{n} 
  h_{i_1} \ldots h_{i_k} \frac{\partial^k}{\partial x_{i_1} \ldots \partial x_{i_k}}
  f(\mathbf{x})
%= \sum_{i_1,\ldots,i_k=1}^{n} 
%  h_{i_1} \ldots h_{i_k} \frac{\partial^k f}{\partial x_{i_1} \ldots \partial x_{i_k}} 
%  \bigg\rvert_{\mathbf{x}}
\end{equation}
With the definition of this operator in place, we can write the $m$th order Taylor approximation as:
\begin{equation}
 f(\mathbf{x + h}) \approx
 \sum_{k=0}^{m} \frac{1}{k!} (\mathbf{h} \cdot \nabla)^k f(\mathbf{x}) =
 f(\mathbf{x}) +  
              (\mathbf{h} \cdot \nabla)   f(\mathbf{x}) + 
 \frac{1}{2!} (\mathbf{h} \cdot \nabla)^2 f(\mathbf{x}) + \ldots +
 \frac{1}{m!} (\mathbf{h} \cdot \nabla)^m f(\mathbf{x})  
\end{equation}

%But, to be honest, I tend to think that this notation obfuscates more than it helps. I prefer the notation in (\ref{Eq:TaylorSeriesMultiDim}). I wanted to mention it such that you can translate it back to the form of (\ref{Eq:TaylorSeriesMultiDim}) if you encounter it in the wild.

%..TBC...

% See Karpfinger, pg 517

\paragraph{Flattened Notation}
We could also write the $m$-th order Taylor polynomial of some function $f$ with $n$-dimensional input vector $\mathbf{x} = (x_1, \ldots, x_n)$ a point $\mathbf{a} = (a_1, \ldots, a_n)$ as:
\begin{equation}
\label{Eq:TaylorSeriesMultiDimFlat}
 f(\mathbf{x}) \approx
 \sum_{k_1+\ldots+k_n \leq m} c_{k_1 \ldots k_n} (x_1 - a_1)^{k_1} \ldots (x_n - a_n)^{k_n}, 
 \quad \text{where} \quad
 c_{k_1 \ldots k_n} = \frac{1}{k_1 ! \ldots k_n!} 
                      \frac{ \partial^{k_1+\ldots+k_n} }
                           { \partial x_1 ^{k_1} \ldots \partial x_n ^ {k_n}} f(\mathbf{a})
\end{equation}
It involves only a single summation sign which is why I call it "flattened" (this is not an official term - I made that up). But don't be fooled: This "single sum" is actually a single-sum, double-sum, triple-sum, $\ldots$, $m$-fold sum in one go. One could de-structure the sum a bit like so:
\begin{equation}
 f(\mathbf{x}) \approx
 \sum_{p=0}^{m}
 \sum_{k_1+\ldots+k_n = p} c_{k_1 \ldots k_n} (x_1 - a_1)^{k_1} \ldots (x_n - a_n)^{k_n}, 
\end{equation}
Now the inner sum requires the $k_i$ to add up to exactly $p$ and $p$ ranges from $0$ to $m$ in an outer sum. The "flattened" notation isn't really much better in terms of verbosity but at least, it doesn't require pattern extrapolation. It needs more explanation though. Things like $c_{k_1 \ldots k_n}$ or $\partial^{k_1+\ldots+k_n}$ may be less familiar notational concoctions. First of all, we note that this formula here gives us $f(\mathbf{x})$ directly in terms of the components of $\mathbf{x}$ rather than $f(\mathbf{x + h})$ in terms of the components $\mathbf{h}$. In this case here, our expansion center is given by another vector $\mathbf{a} = (a_1, \ldots, a_n)$, so the setting is a bit different. That's why we see things like $(x_i - a_i)$ appear instead of $h_i$. Second, we need to clarify the range of the sum. For each combination of these $k_i$ that satisfies $k_1+\ldots+k_n \leq m$, there will be one summand. This summand involves a product of powers of $(x_i - a_i)^{k_i}$. Each of these products is weighted by a coefficient $c_{k_1 \ldots k_n}$. This coefficient has also $n$ indices. The computation formula for these coefficients is given on the right. It is a (possibly mixed) partial derivative of $f$ evaluated at the expansion point $\mathbf{a}$ divided by the product of the factorials of the $k_i$. The order of the partial derivative is given by the sum over the $k_i$. 











\paragraph{Multi-index Notation}
The formula (\ref{Eq:TaylorSeriesMultiDimFlat}) can be condensed when we introduce the concept of a multi-index. A multi-index is, so to speak, a vector of indices. I have said that each of the $c$-coefficients has $n$ indices $k_i$ where $i = 1,\ldots,n$. We can collect these $n$ indices into a vector $\mathbf{k} = (k_1,\ldots,k_n)$. That vector $\mathbf{k}$ of indices is what we call a multi-index. With that definition in place, we can write:
\begin{equation}
 f(\mathbf{x}) \approx
 \sum_{|\mathbf{k}| \leq m} c_{\mathbf{k}} (\mathbf{x-a})^{\mathbf{k}} 
 \quad \text{where} \quad
 c_{\mathbf{k}} = \frac{1}{\mathbf{k!} } 
                      \frac{ \partial^{|\mathbf{k}|}}
                           { \partial x_1 ^{k_1} \ldots \partial x_n ^ {k_n}} f(\mathbf{a})
\end{equation}
For that too make sense, we need to define the following operations for multi-indices $\mathbf{k}$ and between a multi-index $\mathbf{k}$ and a vector $\mathbf{v}$:
\begin{equation}
|\mathbf{k}| = k_1 + k_3 + \ldots + k_n, \quad
\mathbf{v}^{\mathbf{k}} = v_1^{k_1} v_2^{k_2} \ldots v_n^{k_n}, \quad
\mathbf{k}! = k_1! k_2! \ldots k_n!
\end{equation}
The meaning of $c_{\mathbf{k}}$ is that $c$ is a quantity that is indexed by an $n$-dimensional set of indices. For example, if $n=2$, each $c$ would be indexed by two indices - it would be a $c_{ij}$ like an element of an $n \times n$ matrix. TODO: maybe move general explanation of multi-indices into the chapter about multilinear algebra



\paragraph{Operator Notation with Multi-indices}
Of course, it's also possible to combine the ideas of operator- and multi-index notation. For this, we define:
\begin{equation}
\nabla ^ {\mathbf{k}} = \frac{\partial^{|\mathbf{k}|}}{\partial x_1^{k_1} \ldots \partial x_n^{k_n}}
\end{equation}
Now we can write down the $m$-th order Taylor approximation rather neatly as:
\begin{equation}
f(\mathbf{x}) \approx \sum_{|\mathbf{k}| \leq m} \frac{1}{\mathbf{k}!} 
                      (\nabla ^ {\mathbf{k}} f)(\mathbf{a})  (\mathbf{x - a})^{\mathbf{k}}
\end{equation}
Whether such a condensed notation is really useful - I don't know. It requires us to be able to dissect it in our heads. I can't do that easily. I mean - really - what the hell is going on here? We are raising a differential operator to the power of a multi-index! Knowing what that is even supposed to mean legitimately qualifies as rather advanced stuff - at least in my book. In practice, I really prefer equation (\ref{Eq:TaylorSeriesMultiDim}). It may be verbose but at least, it's a straightforward generalization of the 1D case. I have given the other notations here not to show off but in order to enable the reader to translate them into the more elementary notation when they come across the more advanced notation somewhere in the wild, i.e. when reading a math-heavy paper or something. Some authors tend to just throw these fancy equations around\footnote{Preferably with intimidating remarks like "recall that" or "as everybody knows" or "obviously", etc..}, expecting the reader to just know, what they are supposed to mean. So now you know. TODO: figure out if there's a common way to write it in tensor notation (maybe using Einstein summation convention) - if so, give that too. %Maybe express the coeffs also in terms of multinomial coefficients.

% See Arens, pg 891

% https://0fps.net/2011/08/30/multidimensional-taylor-series-and-symmetric-tensors/


%ToDo: explain how to write it tensor notation with Einstein summation convention. There are various way to write it down - some of them quite fancy using powers of the nabla-operator, etc.

% https://sites.millersville.edu/bikenaga/calculus3/taylor-series-several-variables/taylor-series-several-variables.pdf

% https://math.stackexchange.com/questions/1586997/taylor-series-for-multivariable-functions

% https://en.wikipedia.org/wiki/Fr%C3%A9chet_derivative#Higher_derivatives

%Multivariable Taylor Series Derivation
%https://www.youtube.com/watch?v=zxafRk45vtE

% https://math.libretexts.org/Bookshelves/Calculus/Supplemental_Modules_(Calculus)/Multivariable_Calculus/3%3A_Topics_in_Partial_Derivatives/Taylor__Polynomials_of_Functions_of_Two_Variables

% https://en.wikipedia.org/wiki/Taylor%27s_theorem#Taylor's_theorem_for_multivariate_functions

% https://en.wikipedia.org/wiki/Taylor_series#Taylor_series_in_several_variables

% https://math.stackexchange.com/questions/4020865/how-to-expand-this-tensorial-taylor-expansion-to-the-nth-term

% https://en.wikipedia.org/wiki/Multi-index_notation
% https://de.wikipedia.org/wiki/Multiindex

% Karpfinger, pg 515

% Tensor notation?
% https://en.wikipedia.org/wiki/Four-gradient
% https://en.wikipedia.org/wiki/Ricci_calculus#Differentiation
% https://en.wikipedia.org/wiki/Tensor_calculus#Gradient_vector

%===================================================================================================
\subsection{More Notation Terminology} 
% Maybe move this section to somewhere else, i.e. below the "Composition" section



\subsubsection{Differentials} Imagine we have a function $f(x,y)$ in two variables, for example $f(x,y) = x^y$. We can compute the partial derivatives of $f$ with respect to $x$ and $y$ as $f_x = \partial f / \partial x = y x^{y-1}$ and $f_y = \partial f / \partial y = x^y \ln x$. Consider a particular point $(x_0, y_0) = (2,3)$. We can evaluate $f$ and its partial derivatives $f_x, f_y$ at that point to get $f = 2^3 = 8, f_x = 3 \cdot 2^2 = 12, f_y = 2^3 \cdot \ln 2 \approx 5.545178$. With these three values, we can approximate our function $f$ near the point $(3,2)$ linearly as $f \approx 8 + 12 dx + 5.545178 dy$. For example, at $(2.02,3.01)$, we get $f \approx 8 + 12 \cdot 0.02 + 5.545178 \cdot 0.01 \approx 8.2955$ which is an approximation to the true value of around $8.3006$. What we did here was to define a linear function in two variables $dx,dy$ which we envision as small offsets from our given point $(x_0,y_0) = (2,3)$. These were given as $(dx,dy) = (0.02,0.01)$ in our example. These two offsets in the input variables lead to a resulting offset $df$ in the output variable $df = 12 \cdot 0.02 + 5.545178 \cdot 0.01$. This linear function in the two offset variables $dx, dy$ is called the \emph{total differential} of the function $f$ at the point $(x_0, y_0)$.

...TBC...VERIFY, explain the terminology, explain how it is used, explain relation to total derivative, total differential

% 0.69315 
% 0.6931 4718  05599453094172321214581765680755001343602552541206800094...
% 5.545177 4444795624753378569716654125446040010748820420329654400759...
% % 5.545178 7 4444795624753378569716654125446040010748820420329654400759...

% Bärwolff, pg 402


%The partial differential $f$ with respect to $x$ is a linear function in a variable $dx$

%At some given point $(x_0, y_0)$

% https://en.wikipedia.org/wiki/Differential_of_a_function#Differentials_in_several_variables
% https://en.wikipedia.org/wiki/Differential_of_a_function
% https://de.wikipedia.org/wiki/Differential_(Mathematik)


% https://en.wikipedia.org/wiki/Differential_(mathematics)


% https://en.wikipedia.org/wiki/Total_derivative

% This is also a useful view:
% https://en.wikipedia.org/wiki/Differential_of_a_function#General_formulation

% todo: explain how it can be used in a second order (quadratic) approximation of f

% Bärwolff, pg 393
%-https://en.wikipedia.org/wiki/Hessian_matrix#Vector-valued_functions

% Exakte & Inexakte Differentiale - Einfache Erklärung, Beispiele, Thermodynamik (Physik & Chemie)
% https://www.youtube.com/watch?v=MeDIv6HOkeE
%
% ...ist Teil der Playlist:
% https://www.youtube.com/watch?v=IcYB7cWLurI&list=PLdTL21qNWp2YKtHlyM7u_AOaQaBcvqdrO&index=6

\subsubsection{The Total Derivative}

% https://en.wikipedia.org/wiki/Total_derivative

% https://www.youtube.com/watch?v=QFHSHhpbo00
% They Use ∂ Differently in Math and Physics. Which is Better?


% Difference Between Partial and Total Derivative
% https://www.youtube.com/watch?v=Kp7sSp5Kn7o
% -In a function f(x,y), we use partial derivatives like $\partial f / \partial x$ when y is 
%  independent of x. But when y = y(x) is itself a function of x, we can also take the total 
%  derivative of f wrt x

%\subsubsection{The Total Derivative}

\subsubsection{Derivatives With Respect to Vectors}  [very preliminary]
Let $f = f(\mathbf{x})$ be a scalar valued function that has a vector $\mathbf{x}$ as its argument. We want to make sense of an expression like $\frac{d f}{d \mathbf{x}}$. Recall that:
\begin{equation}
f(\mathbf{x + h}) \approx 
f(\mathbf{x}) + \sum_{i=1}^{n} \frac{\partial f}{\partial x_i} h_i =
f(\mathbf{x}) + \mathbf{g}^T \mathbf{h}
\end{equation}
where $\mathbf{x} = (x_1,\ldots,x_n)$, $\mathbf{h} = (h_1,\ldots,h_n)$ and $\mathbf{g} = (\frac{\partial f}{\partial x_1},\ldots,\frac{\partial f}{\partial x_n})|_{\mathbf{x}}$, i.e. the gradient of $f$ evaluated at $\mathbf{x}$. ...TBC...


% https://physics.stackexchange.com/questions/88935/derivative-with-respect-to-a-vector-is-a-gradient
% https://onlinelibrary.wiley.com/doi/pdf/10.1002/0471705195.app3
% https://en.wikipedia.org/wiki/Matrix_calculus#Derivatives_with_vectors

\subsubsection{Derivatives With Respect to Matrices}  [very preliminary]
Let $f = f(\mathbf{X})$ be a scalar valued function that has a matrix $\mathbf{X}$ as its argument. We want to make sense of an expression like $\frac{d f}{d \mathbf{X}}$. In analogy with the with the derivative with respect to a vector, we can write:
\begin{equation}
f(\mathbf{X + H}) \approx 
f(\mathbf{X}) + \sum_{i=1}^{n} \sum_{j=1}^{n} \frac{\partial f}{\partial x_{ij}} h_{ij} =
f(\mathbf{X}) + \vectorize(\mathbf{D})^T \vectorize(\mathbf{H}) =
f(\mathbf{X}) + \tr(\mathbf{D}^T \mathbf{H})
\end{equation}
where $\mathbf{D}$ is the matrix with entries $d_{ij} = \frac{\partial f}{\partial x_{ij}}$. ...TBC...

%Differentiating functions of vectors and matrices
%https://www.youtube.com/watch?v=k5OFFevtGDg
%-at 30:30:




%===================================================================================================
\subsection{Composition of Multivariable Functions}

% Maybe make this more generally about building multivariable functions form other by composition, multiplication, etc. - Maybe call it "Combining Multivariable Functions" ...or just "Combining Functions" or "Building More Complex Functions"


\subsubsection{Ambiguity of the Notation}

% https://www.youtube.com/watch?v=mICbKwwHziI
% Ambiguity With Partial ∂ Notation, and How to Resolve It
% -Explains also convective and material derivative

% https://www.youtube.com/watch?v=QFHSHhpbo00
% They Use ∂ Differently in Math and Physics. Which is Better?
% -Is a follow up of the video above

% ...convective derivative, material derivative, explicit vs complete partial derivative, ...
% https://en.wikipedia.org/wiki/Material_derivative


%https://en.wikipedia.org/wiki/Generalizations_of_the_derivative




\subsubsection{The Multivariable Chain Rule}

% Maybe get rid of "Multivariable" here - it's redundant - we already know that we are in a section about multivariable functions

% The Multi-Variable Chain Rule: Derivatives of Compositions
% https://www.youtube.com/watch?v=9yCtWfI_Vjg
% -dependency graph/diagram


% https://en.wikipedia.org/wiki/Chain_rule#Multivariable_case

% https://math.libretexts.org/Bookshelves/Calculus/Calculus_(OpenStax)/14%3A_Differentiation_of_Functions_of_Several_Variables/14.05%3A_The_Chain_Rule_for_Multivariable_Functions
% -has also implicit multivar chain rule

% https://math.stackexchange.com/questions/1326429/intuition-of-multivariable-chain-rule

% https://tutorial.math.lamar.edu/classes/calciii/chainrule.aspx

% https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/differentiating-vector-valued-functions/a/multivariable-chain-rule-simple-version
% -has vector notation

% https://mathinsight.org/chain_rule_multivariable_introduction

% https://math.libretexts.org/Bookshelves/Calculus/Calculus_3e_(Apex)/12%3A_Functions_of_Several_Variables/12.05%3A_The_Multivariable_Chain_Rule


% https://en.wikipedia.org/wiki/Backpropagation
% -uses the convention of using f_1 for innermost function

% https://de.wikipedia.org/wiki/Backpropagation


% Second Derivatives Using The Multivariable Chain Rule
% https://www.youtube.com/watch?v=FSUCLGRVcXA

\subsubsection{The Multivariable Product Rule}

% Product Rule:

% https://math.jhu.edu/~brown/courses/s19/Lectures/Lecture5.pdf
% https://math.stackexchange.com/questions/3998612/how-to-prove-the-product-rule-in-multivariable-without-chain-rule
% https://en.wikipedia.org/wiki/Product_rule#In_vector_calculus

% It looks like the product rule applies to different kinds of product (inner, outer, etc.). Seems like the product just needs to be bilinear. Figure out for which kinds of product the produc rule holds (tensor? geometric? exterior?)





\begin{comment}

\subsection{TODO Notes}
It seems to be generally true that for any function $f(x)$ we have
\begin{equation}
 \frac{d}{d x} f(x) = \frac{d}{d h} f(x + h) \bigg\rvert_{h=0}
\end{equation}
which seems to generalize to the directional derivative of multivariate functions as:
\begin{equation}
 \frac{\partial f(\mathbf{x}) }{\partial \mathbf{v}} 
 = \lim_{h \rightarrow 0} \frac{f(\mathbf{x} + h \mathbf{v} ) - f(\mathbf{x})}{h}
 = \frac{d}{d h} f(\mathbf{x} + h \mathbf{v}) \bigg\rvert_{h=0}
\end{equation}
which could be used to actually evaluate the directional derivative without using the formula with the scalar product with the gradient. ...verify this! This seems to be the important observation in evaluating the Gateaux derivative by analogy later...



-maybe divergence, but maybe defer that to vector calculus
https://en.wikipedia.org/wiki/Del


For the "Composition" section:

- Explain compostion of multivariable functions in terms of a "functional dependency graph" FDG.
  That's a term that I made up myself. It means something like the directed graphs in this video:
  https://www.youtube.com/watch?v=mICbKwwHziI

- In case of univariate functions, this graph is trivial. It's juts a linear chain. For example
  z -> y -> x means: z depends on y and y depends on x. In the multivariable setting, the graph 
  can be arbitrarily complicated.
  
- Leaf nodes, i.e. nodes that have only incoming arrows, are called independent variables.
  
- For a function to be called explicit, the FDG must be acyclic (I guess). If it has at least one
  cycle, we are deling with an implicitly defined function.

- What about functions like f(x,x') where x = x(t) and x' = dx/dt? Does x' count as dependent on x
  or only dependent on t? I guess, the latter - because if we really write down x'(t), then it has
  indeed only t appearing as independent variable.
  
- Give some examples that are not too contrived, i.e. have some practical interpretation

- Suggest to draw such a "functional dependency graph" for the given problem to clarify what is
  going on

Example 1:
z = z(x,y) = sqrt(x^2 + y^2)
x = x(t)   = sin(2t)
y = y(t)   = sin(3t)
x,y is the parametric description of a Lissajous figure. z is the distance of the point from the
origin. Maybe let t = f(s) where s is an arc-length parameter, i.e. a natural parametrization of the curve. That introduces another r level of nesting. Start with just z = f(x,y) and its partial derivatives. Then let x,y themselves be given by the parametric eqaution with parameter t. The let t be a function of s. 

Example 2:
Then introduce an explicit dependency of z on t. Maybe z = z(t,x,y) = sqrt(x^2 + y^2 - t^2). This
example has some special relativity vibes. On that function, we can explain concepts like partial and total derivative of z with respect to t. The partial derivtaive would treat x and y as constants even though they are functions of t (I think)

Example 3:
Use something like spherical coordinates for
x = x(u,v), y = y(u,v), z = z(u,v) where u,v are angles. Define a vector field on the sphere - maybe representing wind velocity with northward and eastward components as function of latitude u and longitude v. Maybe introduce time as additional parameter - the wind may change. Maybe exaplain covariant derivativesas preview



https://www.youtube.com/watch?v=Hv5oUizQ4FM
-The gradient of  x^T A x  is  (A + A^T) x  where A is a matrix and x a vector. If A is symmetric,
 this can be simplified to 2 A x.


-Explain multivariable functions that can be expressed in various different coordinate systems and
 how to convert between the different representations. In some contexts (especially theormdynamics),
 it is quite common to express one physical quantity as a function of some others - but there are different possible choices for what these others are. In such cases, when expressing a partial derivative, one puts the expression in parentheses and puts the variables that are held constant into a subscript.
-See Arens, Ergänzungen, pg 128. It has the example: f: R^2 -> R^2, f(x,y) = x^2 - y^2. With
 x = r*cos(p), y = r*sin(p), r = sqrt(x^2 + y^2), p = atan2(y,x), we can express f also in terms
 of r,p as: f(r,p) = r^2(cos^2 p) - sin^2 p = r^2 cos(2 p). We have:
 (df/dx)_y = 2 x, (df/dy)_x = -2y,   (df/dr)_p = 2 r cos(2 p), (df/dp)_r = -2 r^2 sin(2 p).
 But we can also compute partial derivatives in "mixed" coordinates like (df/dx)_r = 4 x. This works
 as follows: We use r^2 = x^2 + y^2 and substitue y^2 = r^2 - x^2 into the cartesian form to get
 f(x,r) = 2 x^2 - r^2. The general procedure is to express the function f only in terms of those
 variables, whose state we know. For each variable, there are two possibilities: either: held 
 constant or: f is being differentiated with respect to it. When we have a function of more than 2
 variables, those that are held constant are seperated by a comma in te subscript.
-Using the symbol f regardless of which coordinates we use, e.g. f(x,y) or f(r,p) or f(x,r) is
 mathematically sloppy but can be justified by noting that f always denotes the same physical 
 quantity and it is widespread practice (at least in certain fields).
-Bring an actual real world example from thermodynamics
-An example that I have thought of myself is: f(x,y) = x / (x+y). The other coordinate system is:
 s = x+y, d = x-y, i.e. the sum and difference of the original coordinates. One could interpret x,y
 as kinetic and potential energy. Then s would be the total energy and d the Lagrangian and f could be
 interpreted as some sort of kinetic energy ratio (i.e. the fraction of the total energy that is 
 kinetic). See also:
 https://www.youtube.com/watch?v=_Hp11d1Z-78  Lagrangian vs Newtonian Mechanics
 Give expressions for (df/dx)_s, (df/dx)_y, (df/dx)_d, etc. I think, we should be able to
 compute 12 different partial derivatives: pick one of the 4 variables to differentiate with respect 
 to and for each, we have 3 possible variables that we can hold constant. I think, in general we will
 always have (2n)*(2n-1) possible partial derivatives when we have 2 different disjoint sets of
 coordinates to express a function of n variables. In this case, the 2 disjoint sets are 
 {x,y}, {s,d}. Maybe even more generally, we will have C*(C-1) possible partial derivatives where
 C is the cardinality of the union of the different sets of coordinates. Some coordinate systems 
 have non-disjoint coordinates - for example cartesian and cylindrical in 3D have the z-coordinate 
 in common.
-Two different sets of coordinates are equally valid if there is a bijection between both sets. This
 means that the Jacobian of the coordinate transformation must be regular. In practice, it may be the
 case that one set of coordinates is better suited than another. regularity of the Jacobian may depend
 on the current operating point - that means that two sets of coordinates may be equally valid in a
 certain partof the domain but not in another. Example: thermodynamical state variables at a phase
 transition (e.g. from gas to liquid etc.).





\end{comment} 