\section{Probability Theory}
Probability theory is the mathematical theory random events. It answers questions like "how likely is event $X$ to occur?". The answer is given in terms of a \emph{probability} which is a real number between zero and one. We can interpret this probability in the following way: We imagine an experimental situation with a random outcome such as the toss of a coin. Now we imagine to repeat the experiment $N$ times and ask about the number of times that we observed a particular outcome - say heads. Let's call that number $H$. We expect that when $N$ gets large, that the ratio $H/N$ will converge to the probability of seeing heads - in this case $\frac{1}{2}$. This interpretation of the idea of a probability is called the \emph{frequentist} interpretation. It bears this name because it interprets the idea of probability as a frequency of occurrence in the sense of how often a particular event occurs when we do a large number of experiments.  ...TBC...


%===================================================================================================
\subsection{Probability Spaces}
The setting in which probability theory takes place is formalized in terms of so called \emph{probability spaces}. A probability space is a triple $(\Omega, \mathcal{F}, P)$ made from the following 3 ingredients: 

\begin{itemize}

\item 
A set $\Omega$, called the \emph{sample space}, that represents the set of all possible \emph{outcomes} of some sort of random experiment.

\item
A set $\mathcal{F}$, called the \emph{event space}, that consists of all the events that could occur in such an experiment. Each such event is represented by a subset of $\Omega$.

\item 
A  $P: \mathcal{F} \rightarrow [0,1]$, called the \emph{probability function}, that assigns to each event $A \in \mathcal{F}$ a probability of occurrence. The probability is a real number in the closed interval $[0,1]$.

\end{itemize}

The intention of the definitions is best understood by an example. Consider the random experiment of rolling a die. The set of possible outcomes is $\Omega = \{1,2,3,4,5,6\}$. An event $A \in \mathcal{F}$ could be "the die lands on 3" represented by the singleton set $A = \{3\}$ which is a subset of $\Omega$. It could also be "the die lands on a number less than 5" represented by $B = \{1,2,3,4\}$ or "the die lands on an even number" represented by $C = \{2,4,6\}$. Assuming a fair die, the probability function $P$ would assign the following probabilities to $A,B,C$: $P(A) = \frac{1}{6}$, $P(B) = \frac{4}{6} = \frac{2}{3}$ and  $P(C) = \frac{3}{6} = \frac{1}{2}$.

\medskip
In general, ...TBC...


%(1)  The "random experiment" in this context could be, for example, something tossing a coin or rolling a die. In the former case, we would have $\Omega = \{heads, tails\}$ and in the latter case $\Omega = \{1,2,3,4,5,6\}$. 


%(2)  For example: "the die lands on a 3" or "the die lands on an even number" or "the die lands on a number less than 5", etc. This so called \emph{event space} is a particular\footnote{To be precise, the set of subsets must be a $\sigma$-algebra (as defined in measure theory), but that's not particularly important here} set of subsets of $\Omega$. It's the set of all events that we want to assign a probability to. 


%(3) The function $P$ should satisfy the following conditions: An event that is certain should get a probability of one. Formally, that means $P(\Omega) = 1$. An event that is impossible should get a probability of zero. That translates to $P(\emptyset) = 0$.

%...TBC...explain interpretation of the probability in the frequentist and Bayesian sense. Explain how probability zero means (almost) impossible and one means (almost) certain ...the "almost" part relevant only for infinite sample spaces, 

%I think. I think $P$ should also satisfy (countable) additivity: for disjoint sets $A,B$, we should have $P(A \cup B) = P(A) + P(B)$. ...verify! 

% I think, the function $P$ must be a certain kind of measure
% explain elementary events - maybe they make sense only in the context of finite Omega?

% maybe use itemize or enumerate latex environment or somrthing
% discuss frequenties vs Bayesian interpretation of probabilities



% https://en.wikipedia.org/wiki/Probability_measure

% https://en.wikipedia.org/wiki/Probability_space

% https://en.wikipedia.org/wiki/Outcome_(probability)
% Explain that term

% https://www.its.caltech.edu/~mshum/stats/lect1.pdf
% Good stuff in there!

% https://ethz.ch/content/dam/ethz/special-interest/mavt/dynamic-systems-n-control/idsc-dam/Lectures/Stochastic-Systems/Probability.pdf

% https://www.statlect.com/glossary/probability-space

% define the term "observation"


% https://en.wikipedia.org/wiki/Event_(probability_theory)
% https://en.wikipedia.org/wiki/Elementary_event

%---------------------------------------------------------------------------------------------------
%\subsubsection{Conditional Probabilities}
\subsubsection{Computing with Probabilities}
% find better name - maybe something about "complex probailities", combining propbabilites


\paragraph{Joint Probability}
A \emph{joint probability} of two events $A$ and $B$ is the probability that both events occur. Occurrence of both events $A$ and $B$ means that the event defined by the \emph{intersection set} $A \cap B$ occurs. Think again of a die and take as event $A$ the event that an even number occurs, i.e. $A = \{2,4,6\}$ and as event $B$ that the number is less than $5$, i.e. $B = \{1,2,3,4\}$. The event $A \cap B$ means that the number is even \emph{and} is less then 5. That means we are asking for the probability of $A \cap B = \{2,4\}$. The joint probability of $A$ and $B$ can be written down as $P(A \cap B)$ or in the shorter notation $P(A,B)$. ...TBC...

% P(A \cap B) is also denoted as $P(A,B)$

% https://en.wikipedia.org/wiki/Joint_probability_distribution
% https://statisticsbyjim.com/probability/joint-probability/
% https://byjus.com/maths/joint-probability/
% https://www.sciencedirect.com/topics/engineering/joint-probability


\paragraph{Conditional Probability}
A conditional probability is a probability of some event $A$ to occur when we already know that some other event $B$ definitely does occur. For example, if we already know that the die rolled an even number, the probability that it rolled the number $4$ is now $\frac{1}{3}$ and not $\frac{1}{6}$ anymore as it would be if we wouldn't have the information about the evenness. Conditional probabilities are denoted as $P(A|B)$ which we may read as "the probability of $A$ under the condition of $B$" or shorter "the probability of $A$ given $B$". The formula to compute such a conditional probability is given by:
\begin{equation}
\label{Eq:ConditionalProbability}
 P(A|B) = \frac{P(A \cap B)}{P(B)} = \frac{P(A, B)}{P(B)}
\end{equation}
...TBC...give intuition why that formula makes sense. Writing it as $P(A,B) = P(B) P(A|B)$ makes it clearer

% P(A|B) = P(A \cap B) / P(B)

% P(A) = 1/6, P(B) = 1/2, P(A|B) = 1/3

% https://en.wikipedia.org/wiki/Conditional_probability


% Conditional probability, joint probability, marginal probability,  Bayes theorem



\paragraph{Bayes Theorem}
%From $P(A \cap B) = P(A) P(B|A)$,  $P(B \cap A) = P(B) P(A|B)$ and $P(A \cap B) = P(B \cap A)$, it immediately follows that:
From $P(A, B) = P(A) P(B|A)$,  $P(B, A) = P(B) P(A|B)$ and $P(A, B) = P(B, A)$, it immediately follows that:
\begin{equation}
\label{Eq:BayesTheorem}
 P(A|B) = \frac{P(B|A) P(A)}{P(B)}
\end{equation}
You just need to plug in the right hand sides of equalities 1 and 2 into equality 3 and then solve for $ P(A|B)$. This result is known as Bayes theorem and is one of the important results in probability theory. In order to memorize it, I'd recommend to just memorize the 3 obvious equalities above from which it immediately follows. They are actually only two equalities - the second is exactly the same as first just with reversed roles of $A$ and $B$. Bayes theorem has a lot of uses....TBC...explain some use cases, give examples

%https://en.wikipedia.org/wiki/Bayes%27_theorem


% https://en.wikipedia.org/wiki/Law_of_total_probability

%===================================================================================================
\subsection{Probability Distributions}


%---------------------------------------------------------------------------------------------------
\subsubsection{Discrete Distributions}

\paragraph{Uniform Distribution}

\paragraph{Triangular Distribution}

\paragraph{Convolution} TODO: explain how adding two independent random variables corresponds to the convolution of their distributions, the triangular distribution arising from summing tow uniform distributions is an example, mention the Irwin-Hall distribution

%\paragraph{Irwin-Hall Distribution}


\paragraph{Binomial Distribution}

\paragraph{Poisson Distribution}
% https://en.wikipedia.org/wiki/Poisson_distribution


%---------------------------------------------------------------------------------------------------
\subsubsection{Continuous Distributions}
% akak provbaility density function pdf

\paragraph{Irwin-Hall Distributions} TODO: uniform, triangular, piecewsie parabolic, etc., B-splines

\paragraph{Gaussian Distribution}

\paragraph{Exponential Distribution}

\paragraph{Cauchy Distribution}

\paragraph{Student t-Distribution}


\paragraph{The Central Limit Theorem}
One of the important theorems in probability theory is the \emph{central limit theorem}. It states that when we add more and more independent random variables, the distribution of the sum will, under mild conditions, always approach a Gaussian distribution. That's a justification for why in statistical models, the random variables that occur within it, are often assumed to follow a Gaussian distribution. Assuming a Gaussian distribution also happens to be convenient in curve fitting because it means that a maximum likelihood fit simplifies to a least-squares fit [VERIFY!] ...TBC...

% it's also convenient because it implies that a least-squares fit to some data is a maximum likelihood fit



% central limit theorem

\begin{comment}

Probability is just...really weird
https://www.youtube.com/watch?v=zczGnnM05TQ

- Probability distiributions
  Discrete
  Continuous

\end{comment}

