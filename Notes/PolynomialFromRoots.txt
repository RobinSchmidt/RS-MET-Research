Let's assume we have a degree N polynomial p(x) given in terms of its roots as:

  p(x) = k * (x-r1) * (x-r2*) * ... * (x-rN)

and we want to evaluate it together with its derivative at some given number x. The idea is to 
recursively split it into two polynomials of half the degree, evaluate their values and derivatives
and combine them using the product rule (which requires 2 muls and 1 add). Let's take a degree 8 
polynomial as example and assume k = 1, so we have:

  p(x) = (x-r1)*(x-r2) * (x-r3)*(x-r4)  *  (x-r5)*(x-r6*) * (x-r7)*(x-r8)

where the spacing already indicates how we intend to organize the evaluation. The values of all the
linear factors are just given by x-rK and the derivatives by 1. We denote by v[i..j] the value
(x-ri)*...*(x-rj), i.e. the evaluation of a partial product involving the roots i to j. We denote
the corresponding derivative as d[i..j]. We first compute values and derivatives of pairs of linear
factors:

  v[1..2] =   (x-r1) *   (x-r2)
  d[1..2] = 1*(x-r1) + 1*(x-r2)                            product rule with f' = g' = 1
  v[3..4] =   (x-r3) *   (x-r4)
  d[3..4] = 1*(x-r3) + 1*(x-r4)
  v[5..6] =   (x-r5) *   (x-r6)
  d[5..6] = 1*(x-r5) + 1*(x-r6)
  v[7..8] =   (x-r7) *   (x-r8)
  d[7..8] = 1*(x-r7) + 1*(x-r8)

In the next stage, we combine v[1..2], d[1..2], v[3..4], d[3..4] into v[1..4], d[1..4] via simple
multiplication and the product rule respectively. Similarly we compute v[5..8], d[5..8]:

  v[1..4] = v[1..2] * v[3..4]                              simple multiplication
  d[1..4] = v[1..2] * d[3..4] + v[3..4] * d[1..2]          product rule
  v[5..8] = v[5..6] * v[7..8]
  d[5..8] = v[5..6] * d[7..8] + v[7..8] * d[5..6] 

And in the last stage, we compute v[1..8], d[1..8] by combining these 4 just computed values 
appropriately:

  v[1..8] = v[1..4] * v[5..8]
  d[1..8] = v[1..4] * d[5..8] + v[5..8] * d[1..4]

These our desired final results. This leads to an O(N*log(N)) algorithm. That's not as nice as an 
O(N) algorithm which is clearly also possible - well, at least when the coefficients are also 
available (computing them from the roots is an O(N^2) task but it may often assumed to be done once
and for all). We could also try to use automatic differentiation which should also result in an 
O(N) algorithm. We should compare the numerical accuracy of the various algorithms. If the 
O(N*log(N)) algo is numerically more stable, it may be worth it.

Questions:
-What if the degree is not a power of 2? Maybe it's most convenient to just pad the array up to
 the next power of two? Maybe the values should be padded by 1 and the derivatives by 0?
-Can it be generalized to higher derivatives?

----------------------------------------------------------------------------------------------------

Multiplying two polynomials p(x) = A * (x-r1) * (x-r2) * ... and q(x) = B * (x-s1) * (x-s2) * ...
in their product form is easy: the overall scale factor C is just the product of the two scale 
factors C = A*B and the arrays of roots r1,r1,... and s1,s2,... are just concatenated. But 
what about the sum p(x) + q(x)? Can we compute the scale factor and its roots t1,t2,... from the 
given data without converting to sum form first? The expression p(x) + q(x) is zero iff 
p(x) = -q(x). Let's try it for the example:

  p(x) = 1*(x+2)(x-1) = x^2 +   x - 2
  q(x) = 2*(x-1/2)    =       2*x - 1

  See: https://www.desmos.com/calculator/vyyvwxlddq

We need to find all solutions of:

  1*(x+2)(x-1) = -2*(x-1/2)    or    1*(x+2)(x-1) - 2*(x-1/2) = 0

Maybe it could help to apply the exp or log function to both sides? Let's try log (aka ln):

  ln(1) + ln(x+2) + ln(x-1) = ln(-2) + ln(x-1/2)
  ln(1) + ln(x+2) + ln(x-1) - ln(-2) - ln(x-1/2) = 0  ...eww! ln(-2) is complex!

Other idea: for an example, let's assume, p(x) and q(x) are both of degree 2. Their sum 
r(x) = p(x) + q(x) will also be of (at most) degree 2. Let's denote the roots of p by p1,p2, those 
of q by q1,q2 and those of r by r1,r2 and the scale factors P,Q,R. So, we have:

  p(x) = P * (x-p1) * (x-p2)
  q(x) = Q * (x-q1) * (x-q2)
  r(x) = R * (x-r1) * (x-r2)

We make the ansatz: r(x) = p(x) + q(x) which gives:

  R * (x-r1) * (x-r2) = P * (x-p1) * (x-p2)  +  Q * (x-q1) * (x-q2)

We may directly compute R as:

  R = P + Q

Because that's how leading coefficients behave (like all other coeffs as well). So that unknown is 
already out of the way. Let's now plug in the known values p1,p2,q1,q2 for x. We obtain the system 
of 4 equations:

  R * (p1-r1) * (p1-r2)  =  Q * (p1-q1) * (p1-q2)  =  Q(p1)
  R * (p2-r1) * (p2-r2)  =  Q * (p2-q1) * (p2-q2)  =  Q(p2)
  R * (q1-r1) * (q1-r2)  =  P * (q1-p1) * (q1-p2)  =  P(q1)
  R * (q2-r1) * (q2-r2)  =  P * (q2-p1) * (q2-p2)  =  P(q2)

The right hand sides are numbers which we can directly compute. They are knowns. On the left, we 
have a product of factors involving our unknowns r1,r2. Let's now take the logarithm of both sides.
That transforms the products into sums:

  ln(R) + ln(p1-r1) + ln(p1-r2)  =  ln(Q(p1))
  ln(R) + ln(p2-r1) + ln(p2-r2)  =  ln(Q(p2))
  ln(R) + ln(q1-r1) + ln(q1-r2)  =  ln(P(q1))
  ln(R) + ln(q2-r1) + ln(q2-r2)  =  ln(P(q2))

This is now a linear(!) system of 4 equations in the 8 unknowns ln(p1-r1), ln(p1-r2), ...hmm...4 
equations are not enough for 8 unknowns. Let's try
 
  ln(p1-r1) + ln(p1-r2)  =  ln(Q(p1)) - ln(R)
  ln(p2-r1) + ln(p2-r2)  =  ln(Q(p2)) - ln(R)
  ln(q1-r1) + ln(q1-r2)  =  ln(P(q1)) - ln(R)
  ln(q2-r1) + ln(q2-r2)  =  ln(P(q2)) - ln(R)

Exponentiate the 1st equation:

    exp(ln(p1-r1) + ln(p1-r2))  =  exp(ln(Q(p1))-ln(R))  
    exp(ln(p1-r1)) * exp(ln(p1-r2)) =  exp(ln(Q(p1))-ln(R))  
    (p1-r1) * (p1-r2) =  exp(ln(Q(p1))-ln(R)) 

...hmm...not sure, if that leads anywhere...

Maybe we can obtain more equations by plugging in r1,r2. These are unknowns, but maybe it 
nevertheless makes sense to do it? Let's try it:

  R * (r1-r1) * (r1-r2)  =  Q * (r1-q1) * (r1-q2)  +  P * (r1-p1) * (r1-p2)
  R * (r2-r1) * (r2-r2)  =  Q * (r2-q1) * (r2-q2)  +  P * (r2-p1) * (r2-p2)

The left hand sides vanish:

  0  =  Q * (r1-q1) * (r1-q2)  +  P * (r1-p1) * (r1-p2)
  0  =  Q * (r2-q1) * (r2-q2)  +  P * (r2-p1) * (r2-p2)

Let's bring the Q-terms to the left:

  -Q * (r1-q1) * (r1-q2)  =  P * (r1-p1) * (r1-p2)                                               (1)
  -Q * (r2-q1) * (r2-q2)  =  P * (r2-p1) * (r2-p2)

Take the logarithm:

 ...TBC...


Another idea: Take the ansatz:

  r(x) = p(x) + q(x) = 0    iff    p(x) = -q(x)

So, we require for our example:

  P * (x-p1) * (x-p2) = -Q * (x-q1) * (x-q2)

Now into this equation, we plug in the unknonw(1) roots r1,r2 of r(x) to obtain two equations:

  P * (r1-p1) * (r1-p2) = -Q * (r1-q1) * (r1-q2)
  P * (r2-p1) * (r2-p2) = -Q * (r2-q1) * (r2-q2)

Ah! That the same equation that we obtained above as (1)! OK - now take the natural logarithm of 
both sides to transform the products into sums:

  ln(P) + ln(r1-p1) + ln(r1-p2) = ln(-Q) + ln(r1-q1) + ln(r1-q2)
  ln(P) + ln(r2-p1) + ln(r2-p2) = ln(-Q) + ln(r2-q1) + ln(r2-q2)

Bring all terms to the left:

  ln(P) + ln(r1-p1) + ln(r1-p2) - ln(-Q) - ln(r1-q1) - ln(r1-q2) = 0
  ln(P) + ln(r2-p1) + ln(r2-p2) - ln(-Q) - ln(r2-q1) - ln(r2-q2) = 0

Re-arrange:

  ln(P) - ln(-Q)  +  ln(r1-p1) - ln(r1-q1)  +  ln(r1-p2) - ln(r1-q2) = 0
  ln(P) - ln(-Q)  +  ln(r2-p1) - ln(r2-q1)  +  ln(r2-p2) - ln(r2-q2) = 0

Hmm - we actually again have 8 unknowns: ln(r1-p1), ln(r1-q1), ... and only two equations. But we 
already obtained 4 equations above by pluggin in p1,p2,q1,q2 into our first ansatz. So, that is 6 in 
total. Can we somehow obtain 2 more? What about plugging r1,r2 into the 1st ansatz?

  R * (x-r1) * (x-r2) = P * (x-p1) * (x-p2)  +  Q * (x-q1) * (x-q2)
  0 = P * (r1-p1) * (r1-p2)  +  Q * (r1-q1) * (r1-q2) = Q(r1) + P(r1)
  0 = P * (r2-p2) * (r2-p2)  +  Q * (r2-q1) * (r2-q2) = Q(r2) + P(r2)

...hmm...no - that seems to give the same equations, we already have. Maybe we can reduce the number 
of unknowns by combining the terms that involve the same unknown root. Then we shift the burden to 
solve a nonlinear equation involving sums of logarithms of the type ln(r1-p1) + ln(r1-p2) + ...

Other idea: Maybe just take the ansatz:

  P * (r1-p1) * (r1-p2)  -  Q * (r1-q1) * (r1-q2) = 0
  P * (r2-p1) * (r2-p2)  -  Q * (r2-q1) * (r2-q2) = 0

This is a decoupled(!) nonlinear system of 2 equations in the two unknowns r1,r2. We may go ahead 
and just try to solve the 1st equation via (complex valued) Newton iteration to find the 1st root 
r1. But what then? Just applying Newton iteration two the 2nd equation will just converge to the 
same root if we take the same initial value. But maybe we can tweak the function in the initial 
phase to drive the solution away from r1 - for example by introduing a pole at r1 by adding 1/r1, 
i.e. try initially applying Newton iteration to:

    P * (r2-p1) * (r2-p2)  -  Q * (r2-q1) * (r2-q2)  + 1/r1 = 0

and when this is (roughly) converged, scrap the 1/r1 term and converge to the actual solution? For 
a 3rd root, we would initially add 1/r1 + 1/r2, etc. Or maybe ther could be some more clever way to
"remove" the root at r1 from the left hand side without affecting the locations of the other roots?
Maybe we could cancel it by dividing the whole expression by (x-r1)?

Maybe we could try to obtain a set of strategically placed points of the polynomial 
r(x) = p(x) + q(x) and then find an interpolant via Newtons interpolation formula? We could choose
the roots of p, i.e. p1, p2, ... as x-values. The y values would be q(p1), q(p2), ... This is 
because p(x) vanishes at x = p1, x = p2, ... so p(x) + q(x) would be just q(x). Or we could choose 
the roots of q as x values and the corresponding y-values would p(q1), p(q2), ...

Maybe we could consider a family of polynomials r_t(x) = p(x) + t * q(x) where t is a parameter in 
[0,1]. We could start at t = 0 where the roots of r_t(x) would be the same as the roots of p(x). 
Then we could slowly ramp up t and (somehow) let and algorithm follow the trajectories of the roots.
At t = 1, they would be our desired roots of r(x) = p(x) + q(x). It would require that for each t,
we would have to compute the roots of r_t - but maybe that could be done fast - maybe with one nD 
Newton step?


Another problem might be to evaluate the derivative of the polynomial in product form. Maybe we need
to apply a generalized product rule? See .tex files for the math book - there I have some notes 
about that rule. Maybe we should have a class rsFactoredPolynomial for implementing such operations 
on factored polynomials (i.e. polynomials in product form)













