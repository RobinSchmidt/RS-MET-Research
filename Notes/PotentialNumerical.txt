Assume that we have numerical data for a vector field U(x,y), V(x,y) and we know that this data 
represents a potential field. How can we find a corresponding potential numerically? Let's assume we 
have 2 2D data arrays U(i,j), U(i,j) representing the functions U(x,y), V(x,y) where the x,y are 
equidistant with stepsize dx,dy respectively. In a 4x5 toy scenario, the situation could look like 
this:

                U(i,j)                      V(i,j)                         P(i,j)
     i                           i                              i
  j:     0   1   2   3   4    j:     0   1   2   3   4       j:     0   1   2   3   4 
     0  U00 U01 U02 U03 U04      0  V00 V01 V02 V03 V04         0  P00 P01 P02 P03 P04
     1  U10 U11 U12 U13 U14      1  V10 V11 V12 V13 V14         1  P10 P11 P12 P13 P14
     2  U20 U21 U22 U23 U24      2  V20 V21 V22 V23 V24         2  P20 P21 P22 P23 P24
     3  U30 U31 U32 U33 U34      3  V30 V31 V32 V33 V34         3  P30 P31 P32 P33 P34

where the U,V-matrices are known and the P-matrix is to be computed. P should become the potential
of U,V. Note that the visual depiction is misleading in what is x and what is y: x or i goes down 
vertically/row-wise while y or j goes horizontally or column-wise. But that's just the visual 
interpretation of the arrays and doesn't matter conceptually.

Let's assume the U,V data matrices have arisen from p via numerical (partial) differentiation via 
central differencing. That means, we can make the ansatz:

  U(i,j) = (P(i+1,j) - P(i-1,j)) / (2*dx)    and    V(i,j) = (P(i,j+1) - P(i,j-1)) / (2*dy)
 
This formula applies only to inner points. That is, if the index ranges are i = 0,...,I-1 and 
j = 0,...,J-1, then the formula above applies only to i = 1,..,I-2, j = 1,...,J-2. For the boundary 
points at the edges, we may either use special formulas based on forward or backward differences:

  U(i,j) = (P(i+1,j) - P(i,  j)) / dx      i = 0
  U(i,j) = (P(i,  j) - P(i-1,j)) / dx      i = I-1
  V(i,j) = (P(i,j+1) - P(i,  j)) / dy      j = 0        left
  V(i,j) = (P(i,j  ) - P(i,j-1)) / dy      j = J-1
 
...or just leave them out for the moment and just compute the potential only for the inner points. 
We could tell the user to pad the matrices at the boundaries (by repitition of the last value or 
(better) by linear extrapolation) or do that ourselves in a convenience function. We want to write 
the set of equations in the form:

  M * vec(P) = vec(U,V)

where M is a coefficient matrix and vec(P), vec(U,V) are appropriate vectorizations of the 
matrices. Let's rewrite the ansatz for the inner points as:

  a*P(i+1, j  ) + b*P(i-1, j  ) = U(i,j)
  c*P(i,   j+1) + d*P(i,   j-1) = V(i,j)

where 

  a = 1/(2*dx), b = -1/(2*dx), c = 1/(2*dy), d = -1/(2*dy)
  A = 1/dx,     B = -1/dx,     C = 1/dy,     D = -1/dy
  
Let's assume, vectorizing a matrix just means re-interpreting it as vector without re-ordering it in 
memory. That means, we just concatenate all the rows, one after another, into one big vector (I 
assume a row-major memory layout here). For our example with the 4x5 matrices, we would get a linear 
system of equations that looks as follows:

Abbreviations in the Ansatz column: L: left, I: inner, R: right, T: top, B: bottom, CD: central 
difference, FD: forward difference, BD: backward difference

                                                                 What the line means      Ansatz

  B _ _ _ _ A _ _ _ _ _ _ _ _ _ _ _ _ _ _    P00      U00        U00 = (P10-P00)/dx      L,FD
  _ B _ _ _ _ A _ _ _ _ _ _ _ _ _ _ _ _ _    P01      U01        U01 = (P11-P01)/dx      L,FD
  _ _ B _ _ _ _ A _ _ _ _ _ _ _ _ _ _ _ _    P02      U02        U02 = (P12-P02)/dx      L,FD
  _ _ _ B _ _ _ _ A _ _ _ _ _ _ _ _ _ _ _    P03      U03        U03 = (P13-P03)/dx      L,FD
  _ _ _ _ B _ _ _ _ A _ _ _ _ _ _ _ _ _ _    P04      U04        U04 = (P14-P04)/dx      L,FD
  b _ _ _ _ _ _ _ _ _ a _ _ _ _ _ _ _ _ _    P10      U10        U10 = (P20-P00)/(2dx)     I,CD
  _ b _ _ _ _ _ _ _ _ _ a _ _ _ _ _ _ _ _    P11      U11        U11 = (P21-P01)/(2dx)     I,CD
  _ _ b _ _ _ _ _ _ _ _ _ a _ _ _ _ _ _ _    P12      U12        U12 = (P22-P02)/(2dx)     I,CD
  _ _ _ b _ _ _ _ _ _ _ _ _ a _ _ _ _ _ _    P13      U13        U13 = (P23-P03)/(2dx)     I,CD
  _ _ _ _ b _ _ _ _ _ _ _ _ _ a _ _ _ _ _    P14      U14        U14 = (P24-P04)/(2dx)     I,CD
  _ _ _ _ _ b _ _ _ _ _ _ _ _ _ a _ _ _ _    P20      U20        U20 = (P30-P10)/(2dx)     I,CD
  _ _ _ _ _ _ b _ _ _ _ _ _ _ _ _ a _ _ _    P21      U21        U21 = (P31-P11)/(2dx)     I,CD
  _ _ _ _ _ _ _ b _ _ _ _ _ _ _ _ _ a _ _    P22      U22        U22 = (P32-P12)/(2dx)     I,CD
  _ _ _ _ _ _ _ _ b _ _ _ _ _ _ _ _ _ a _    P23      U23        U23 = (P33-P13)/(2dx)     I,CD
  _ _ _ _ _ _ _ _ _ b _ _ _ _ _ _ _ _ _ a    P24      U24        U24 = (P34-P14)/(2dx)     I,CD
  _ _ _ _ _ _ _ _ _ _ B _ _ _ _ A _ _ _ _    P30      U30        U30 = (P30-P20)/dx          R,BD
  _ _ _ _ _ _ _ _ _ _ _ B _ _ _ _ A _ _ _    P31      U31        U31 = (P31-P21)/dx          R,BD
  _ _ _ _ _ _ _ _ _ _ _ _ B _ _ _ _ A _ _    P32      U32        U32 = (P32-P22)/dx          R,BD
  _ _ _ _ _ _ _ _ _ _ _ _ _ B _ _ _ _ A _    P33      U33        U33 = (P33-P23)/dx          R,BD
  _ _ _ _ _ _ _ _ _ _ _ _ _ _ B _ _ _ _ A    P34  =   U34        U34 = (P34-P24)/dx          R,BD
  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _             V00
  d _ c _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _             V01        V01 = (P02-P00)/(2dy)     I,CD
  _ d _ c _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _             V02        V02 = (P03-P01)/(2dy)     I,CD
  _ _ d _ c _ _ _ _ _ _ _ _ _ _ _ _ _ _ _             V03        V03 = (P04-P02)/(2dy)     I,CD
  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _             V04
  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _             V10  
  _ _ _ _ _ d _ c _ _ _ _ _ _ _ _ _ _ _ _             V11        V11 = (P12-P10)/(2dy)     I,CD
  _ _ _ _ _ _ d _ c _ _ _ _ _ _ _ _ _ _ _             V12        V12 = (P13-P11)/(2dy)     I,CD
  _ _ _ _ _ _ _ d _ c _ _ _ _ _ _ _ _ _ _             V13        V13 = (P14-P12)/(2dy)     I,CD
  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _             V14   
  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _             V20      
  _ _ _ _ _ _ _ _ _ _ d _ c _ _ _ _ _ _ _             V21        V21 = (P22-P20)/(2dy)     I,CD
  _ _ _ _ _ _ _ _ _ _ _ d _ c _ _ _ _ _ _             V22        V22 = (P23-P21)/(2dy)     I,CD
  _ _ _ _ _ _ _ _ _ _ _ _ d _ c _ _ _ _ _             V23        V23 = (P24-P22)/(2dy)     I,CD
  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _             V24   
  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _             V30  
  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ d _ c _ _             V31        V31 = (P32-P30)/(2dy)     I,CD
  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ d _ c _             V32        V32 = (P33-P31)/(2dy)     I,CD
  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ d _ c             V33        V33 = (P34-P32)/(2dy)     I,CD
  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _             V34  
  
-Distances: 
 b,a: 2*numCols = 2*5 = 10
 B,A:   numCols = 5
 d,c: 2
 D,C: 1

ToDo (partially done):
The matrix needs to be filled appropriately. It will be sparse. Each row will have two nonzero
entries which can be either (mostly) a or b in the upper half or (mostly) c or d in the lower half. 
All rows and columns of the matrix that involve boundary points of P, will need special coefficients 
based on the forward or backward difference ansatz for the boundary points [ToDo: figure out the 
details!]. W'ell use the underscore _ to indicate zero entries. Use A=2a, B=2b, C=2c, D=2d in the 
matrix for the rows/cols that involve boundary points

We can interpret this as a linear system of equations of the form:

  M * p = vertcat(u,v) = w
     
where p,u,v are the vectorizations of P,U,V and w = vertcat(u,v) means vertical concatenation of u 
and v (I think, vertcat is the Matlab name for this operation, IIRC). If N = I*J = 4*5 = 20, we will 
get 2*N = 40 equations for our 20 unknowns. That's an overdetermined system which we may solve as a 
least squares problem by premultiplying both sides with M^T.

  M^T * M * p = M^T * w

which will reduce the number of equations to 20. ...TBC...






Notes:
-The matrix is sparse but unstructured. Maybe with some clever re-ordering of the vectors, we could
 bring it into a more structured sparse form, like - say - pentadiagonal?
-We could make a different ansatz based on a different formula to compute numerical derivatives. A 
 higher order finite difference approximation would give rise to more nonzero coefficients in the 
 matrix. The result might be more accurate at the cost of more computations due to a less sparse 
 matrix. We could perhaps also use formulas for numerical integration (i.e. trapezoidal et al) for 
 the ansatz (not sure, if that makes sense, though).
-I think, if we numerically differentiate our so obtained potential (using the same differencing 
 formula as was used in the ansatz), we will obtain some sort of best curl-free approximation of our
 original vector field. If it has been (numerically) curl-free in the first place, we should get it 
 back as it was. By "numerically curl-free", I mean a curl-free condition in which derivatives have 
 been replaced by numeric approximations via finite differences.
-When we use the best curl-free approximation algorithm with a negated V, we might obtain a best
 (numerically) analytic approximation to an arbitrary given complex function that is represented
 by U,V. By "numerically analytic", I mean a function that satisfies the numerical pendants of the
 Cauchy-Riemann equations where the derivatives are replaced by finite differences.
 




----------------------------------------------------------------------------------------------------
If we make an ansatz based on a forward difference:

  u(i,j) = (p(i+1,j) - p(i,j)) / dx,   v(i,j) = (p(i,j+1) - p(i,j)) / dy

we could actually solve both equations for p(i,j). Setting them equal would give one equation for
the two values p(i+1,j) and p(i,j+1). I don't know, if that leads anywhere.

----------------------------------------------------------------------------------------------------
Other Idea (may be obsolete because it doesn't work?):
-Integrate u with respect to x using trapezoidal integration row-wise. Call the result U.
-Integrate v with respect to y using trapezoidal integration column-wise. Call the result V.
-They should match up to functions only in the other variable, i.e. the real potential is a function
 p(x,y) = U(x,y) + f(y) = V(x,y) + g(x). I think, to find f(y) we can use V - U or likewise to find 
 g(x) we can use U - V. U contain components of p that depend on x, V contains only components that 
 depend on y. In U-V and V-U, the terms that depend on both x and y will cancel and it remains only
 the missing part that depends on the other variable. ..I'm totally not sure about that - it's just 
 an idea. Ah - no: U - V = g(x) - f(y) and V - U = f(y) - g(x)
 
Let's take an example. The 2D potential is given by:

  p(x,y) = 3x^3 + 2y^4 + 5xy
  
The vector field u(x,y), v(x,y) is obtained by taking partial derivatives:

  u(x,y) = p_x(x,y) = 9x^2 + 5y
  v(x,y) = p_y(x,y) = 8y^3 + 5x

To get back p, we integrate u with respect to x and call it U and integrate v with respect to y and 
call it V:

  U = U(x,y) = 3x^3 + 5xy = g(x) + h(x,y)
  V = V(x,y) = 2y^4 + 5xy = f(y) + h(x,y)
  
Take the sum, call it W:
    
  W := U+V = 3x^3 + 2y^4 + 10xy  = g(x) + f(y) + 2 h(x,y)

This a linear system of 3 equations for g,f,h which we can solve for either of the 3. U,V,U+V=W are 
the known right hand sides, g,f,h are the variables. Let's try to solve for the common part 
h = h(x,y):

  U =  h + g
  V =  h + f
  W = 2h + g + f
  
...ah..no...the last line is linearly dependent on the first two (its their sum), so the system is 
singular
  




Now take the differences:

  U-V = (3x^3 + 5xy) - (2y^4 + 5xy) = 3x^3 - 2y^4         = g(x) - f(y)
  V-U = (2y^4 + 5xy) - (3x^3 + 5xy) = 2y^4 - 3x^3         = f(y) - g(x)
  U+V = (3x^3 + 5xy) + (2y^4 + 5xy) = 3x^3 + 2y^4 + 10xy  = g(x) + f(y) + 2 h(x,y)

where h(x,y) is the cross-part, the common terms that appear in both integrals which is the 5xy term 
here in this example.

...hmm... don't know, if that leads anywhere


...maybe another way:

   U = U(x,y) = 3x^3 + 5xy + f(y)
   V = V(x,y) = 2y^4 + 5xy + g(x)
  
The numerical integration will assume f(y) = g(x) = 0. But that's wrong. We need to figure out what 
the actual f(y) and/or g(x) was.

  1: U - V = (3x^3 + 5xy + f(y)) - (2y^4 + 5xy + g(x)) = (3x^3 + f(y)) - (2y^4 + g(x))
  2: V - U = (2y^4 + 5xy + g(x)) - (3x^3 + 5xy + f(y)) = (2y^4 + g(x)) - (3x^3 + f(y))
  
Solve 1  

----------------------------------------------------------------------------------------------------
Resources:

https://math.stackexchange.com/questions/1340719/numerically-find-a-potential-field-from-gradient
The answer suggests to make an ansatz based on the formula for trapezoidal integration but seems 
similar to my idea of the ansatz using a central difference approximation