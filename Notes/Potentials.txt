Given a vector field:

  f(x_1,...,x_n) = (f_1(x_1,..,x_n), ..., f_n(x_1,..,x_n))
  
we want to find a scalar field F(x_1,..,x_n) whose gradient is the given vector field f. To find it,
we may proceed as follows (I think):

(1) Integrate f_1 wrt x_1, call the result F ("wrt" = "with respect to")
(2) Integrate f_2 wrt x_2, add those terms to F that don't depend on x_1
(3) Integrate f_3 wrt x_3, add those terms to F that don't depend on x_1, x_2
(4) Integrate f_4 wrt x_4, add those terms to F that don't depend on x_1, x_2, x_3
(5) Integrate f_5 wrt x_5, add those terms to F that don't depend on x_1, x_2, x_3, x_4
...
(n) Integrate f_n wrt x_n, add those terms to F that don't depend on x_1, ..., x_{n-1}

Before excuting this algo, it may make sense to verify that a potential exists (by checking the 
symmetry of the Jacobian, I think). After the potential has been found, it may make sense to verify 
that the so found F is indeed a potential by taking all the partial derivatives of F (i.e. dF/dx_1,
..., df/dx_n) and comparing them with the given f_1,...,f_n. They should match. At each step of the 
algorithm, the terms that *do* depend on previous integration variables should match those of the
previously computed expressions. For example, in step (3), those terms that do depend on x_1 and/or 
x_2, should match corresponding terms that have already been computed in steps (1), (2). They are 
already accumulated into our final F, so we should not add them again. In all the integrations, we 
use an integration constant of 0. At every step, the integration constant may actually be a function 
of the remaining variables. That's precisely the stuff, we add in the subsequent steps.

Example:

  f_x(x,y,z) = 2yz + 3y + 5z + 11
  f_y(x,y,z) = 2xz + 3x + 7z + 13
  f_z(x,y,z) = 2xy + 5x + 7y + 17

(1) F  = integral of f_x wrt x
       = 2yzx + 3yx + 5zx + 11x
(2) F += terms of integral of f_y wrt y that don't depend on x, the integral is:
         I = 2xzy + 3xy + 7zy + 13y  ->  select 7zy + 13y, add to F
	F  = 2yzx + 3yx + 5zx + 11x + 7zy + 13y
(3) F += terms of integral of f_z wrt z that don't depend on x and/or y, the integral is:
         I = 2xyz + 5xz + 7yz + 17z  ->  select 17z, add to F
    F  = 2yzx + 3yx + 5zx + 11x + 7zy + 13y + 17z
	
So the end result is (with a little reordering):
   
   F  = 2xyz + 3xy + 5xz + 7yz + 11x + 13y + 17z
  	
Forming the partial derivatives of F wrt to x,y,z, we'll get back our f_x,f_y,f_z above, so F is 
indeed a valid potential for our vector field.

ToDo:
-Try the algorithm with some more complicated functions. I'm not yet totally sure, if it will always
 work. Baerwolff has a slightly more complicated algorithm on page 562.
 
----------------------------------------------------------------------------------------------------
Under construction:

Assume that we have numerical data for a vector field v(x,y), u(x,y) and we know that this data 
represents a potential field. How can we find a corresponding potential numerically? Let's assume we 
have a 2D data arrays u(i,j),v(i,j) representing the functions u(x,y),v(x,y) where the x,y are 
equidistant with stepsize dx,dy respectively. The situation could look like this:

     j                               j                                  j
  i:     0   1   2   3   4   5    i:     0   1   2   3   4   5       i:     0   1   2   3   4   5
     0  u00 u01 u02 u03 u04 u05      0  v00 v01 v02 v03 v04 v05         0  p00 p01 p02 p03 p04 p05
     1  u10 u11 u12 u13 u14 u15      1  v10 v11 v12 v13 v14 v15         1  p10 p11 p12 p13 p14 p15
     2  u20 u21 u22 u23 u24 u25      2  v20 v21 v22 v23 v24 v25         2  p20 p21 p22 p23 p24 p25
     3  u30 u31 u32 u33 u34 u35      3  v30 v31 v32 v33 v34 v35         3  p30 p31 p32 p33 p34 p35

where the u,v-matrices are known and the p-matrix is to be computed. p should become the potential
of u,v.

Idea:

Let's assume the u,v have arisen from p via numerical differentiation via central differencing. That
means, we can make the ansatz:

  u(i,j) = (p(i+1,j) - p(i-1,j)) / (2*dx),   v(i,j) = (p(i,j+1) - p(i,j-1)) / (2*dy)

Maybe such an ansatz can lead to a (sparse) linear system for the p(i,j). Maybe, if we cleverly 
vectorize the matrices, it could even tridiaogonal or maybe pentadiagonal? If we make an ansatz 
based on a forward difference:

  u(i,j) = (p(i+1,j) - p(i,j)) / dx,   v(i,j) = (p(i,j+1) - p(i,j)) / dy

we could actually solve both equations for p(i,j). Setting them equal would give one equation for
the two values p(i+1,j) and p(i,j+1). I don't know, if that leads anywhere.


Other Idea (may be obsolete because it doesn't work?):
-Integrate u with respect to x using trapezoidal integration row-wise. Call the result U.
-Integrate v with respect to y using trapezoidal integration column-wise. Call the result V.
-They should match up to functions only in the other variable, i.e. the real potential is a function
 p(x,y) = U(x,y) + f(y) = V(x,y) + g(x). I think, to find f(y) we can use V - U or likewise to find 
 g(x) we can use U - V. U contain components of p that depend on x, V contains only components that 
 depend on y. In U-V and V-U, the terms that depend on both x and y will cancel and it remains only
 the missing part that depends on the other variable. ..I'm totally not sure about that - it's just 
 an idea. Ah - no: U - V = g(x) - f(y) and V - U = f(y) - g(x)
 
Let's take an example. The 2D potential is given by:

  p(x,y) = 3x^3 + 2y^4 + 5xy
  
The vector field u(x,y), v(x,y) is obtained by taking partial derivatives:

  u(x,y) = p_x(x,y) = 9x^2 + 5y
  v(x,y) = p_y(x,y) = 8y^3 + 5x

To get back p, we integrate u with respect to x and call it U and integrate v with respect to y and 
call it V:

  U = U(x,y) = 3x^3 + 5xy = g(x) + h(x,y)
  V = V(x,y) = 2y^4 + 5xy = f(y) + h(x,y)
  
Take the sum, call it W:
    
  W := U+V = 3x^3 + 2y^4 + 10xy  = g(x) + f(y) + 2 h(x,y)

This a linear system of 3 equations for g,f,h which we can solve for either of the 3. U,V,U+V=W are 
the known right hand sides, g,f,h are the variables. Let's try to solve for the common part 
h = h(x,y):

  U =  h + g
  V =  h + f
  W = 2h + g + f
  
...ah..no...the last line is linearly dependent on the first two (its their sum), so the system is 
singular
  




Now take the differences:

  U-V = (3x^3 + 5xy) - (2y^4 + 5xy) = 3x^3 - 2y^4         = g(x) - f(y)
  V-U = (2y^4 + 5xy) - (3x^3 + 5xy) = 2y^4 - 3x^3         = f(y) - g(x)
  U+V = (3x^3 + 5xy) + (2y^4 + 5xy) = 3x^3 + 2y^4 + 10xy  = g(x) + f(y) + 2 h(x,y)

where h(x,y) is the cross-part, the common terms that appear in both integrals which is the 5xy term 
here in this example.

...hmm... don't know, if that leads anywhere


...maybe another way:

   U = U(x,y) = 3x^3 + 5xy + f(y)
   V = V(x,y) = 2y^4 + 5xy + g(x)
  
The numerical integration will assume f(y) = g(x) = 0. But that's wrong. We need to figure out what 
the actual f(y) and/or g(x) was.

  1: U - V = (3x^3 + 5xy + f(y)) - (2y^4 + 5xy + g(x)) = (3x^3 + f(y)) - (2y^4 + g(x))
  2: V - U = (2y^4 + 5xy + g(x)) - (3x^3 + 5xy + f(y)) = (2y^4 + g(x)) - (3x^3 + f(y))
  
Solve 1  